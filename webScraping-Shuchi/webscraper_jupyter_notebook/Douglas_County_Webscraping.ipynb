{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: pandas in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://apps.douglas.co.us/assessor/web#/\")\n",
    "\n",
    "# Wait for the search box to be visible and locate it\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'app-input-debounce input[type=\"text\"]'))\n",
    ")\n",
    "\n",
    "# Send search query\n",
    "search_box.send_keys(\"2719 Castle Glen Dr\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load (you may need to adjust this depending on the page)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Wait until the table rows are loaded (anchor tags with 'table-row' class)\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.table-row'))\n",
    ")\n",
    "\n",
    "# Locate the first row (anchor tag with class 'table-row') and click it\n",
    "first_row = driver.find_element(By.CSS_SELECTOR, 'a.table-row')\n",
    "first_row.click()\n",
    "\n",
    "# Get page source to parse the HTML after clicking the first row\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup to parse the HTML for further scraping\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closes the pop-up that appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the pop-up dialog to appear and then click the \"Close\" button\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Wait for the \"Close\" button to be clickable\n",
    "close_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button/span[text()='Close']\")))\n",
    "\n",
    "# Click the \"Close\" button to dismiss the pop-up\n",
    "close_button.click()\n",
    "\n",
    "# Wait for the account summary section to be loaded\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account Summary\n",
    "* TODO: Section PDF Map Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Summary:\n",
      "Account #:: R0396965\n",
      "State Parcel #:: 2351-163-01-115\n",
      "Account Type:: Residential\n",
      "Tax District:: 3473\n",
      "Neighborhood-Ext:: 410-I\n",
      "Building Count:: 1\n",
      "Building Permit Authority:: Douglas County (website )\n",
      "Phone:: 303-660-7497\n",
      "Name:: CASTLE PINES\n",
      "Reception No:: 9607889\n",
      "\n",
      "Location Description: LOT 19A CASTLE PINES # 1A 16TH AMENDMENT    0.23 AM/L\n",
      "\n",
      "Owner Info:\n",
      "Owner Name: DENNIS R HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST & JENNIE M HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST\n",
      "Owner Address: 2719 CASTLE GLEN DRCASTLE ROCK, CO 80108\n",
      "\n",
      "Public Land Survey System (PLSS) Location: \n",
      "Quarter: SW; \n",
      "Section: 16; \n",
      "Township: 7; \n",
      "Range: 67\n",
      "\n",
      "Section PDF Map Link: /realware/SectionMaps/TWP2351/DC_2351_16.pdf\n"
     ]
    }
   ],
   "source": [
    "# Extract Toggle Button and Links before Account Summary\n",
    "html_content = driver.page_source\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize a dictionary to store toggle button and links\n",
    "key_value_pairs = {}\n",
    "\n",
    "# Extract the toggle button text (key) and status (value)\n",
    "toggle_button = soup.find('span', class_='ui-button-text')\n",
    "if toggle_button:\n",
    "    key_value_pairs[\"Toggle Button\"] = toggle_button.text.strip()\n",
    "\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "links = soup.find_all('a', href=True)\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    key_value_pairs[link_text] = f'<a href=\"{link_url}\">{link_text}</a>'\n",
    "\n",
    "# Now proceed with the Account Summary logic\n",
    "# Target the dropdown for Account Summary by using its ID\n",
    "dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@id='SummaryAccountInfo']//span[@class='bar faux-button']\")))\n",
    "\n",
    "# Click the dropdown to expand it\n",
    "dropdown_button.click()\n",
    "\n",
    "# Wait for the Account Summary content to load\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@id='SummaryAccountInfo']//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content again after the dropdown is expanded\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the dropdown content specifically under the 'SummaryAccountInfo' ID\n",
    "dropdown_content = soup.find('div', id='SummaryAccountInfo').find('div', class_='dropdown-content')\n",
    "\n",
    "# Extract the key-value pairs from Account Summary\n",
    "account_summary_pairs = {}\n",
    "\n",
    "# Find all the rows with the class 'skinny-row' which contain the label and value pairs\n",
    "rows = dropdown_content.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in rows:\n",
    "    # Extract the label (key) and value (value)\n",
    "    label = row.find('div', class_='col-xs-4').text.strip() if row.find('div', class_='col-xs-4') else None\n",
    "    value = row.find('div', class_='col-xs-8').text.strip() if row.find('div', class_='col-xs-8') else None\n",
    "    \n",
    "    # Add to dictionary if both label and value exist\n",
    "    if label and value:\n",
    "        account_summary_pairs[label] = value\n",
    "\n",
    "# Print the Account Summary key-value pairs\n",
    "print(f\"Account Summary:\")\n",
    "for key, value in account_summary_pairs.items():\n",
    "    # Skip the \"Update Mailing Address\" entry\n",
    "    if key != 'Update Mailing Address':\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Extract additional data (Location Description, Owner Info, PLSS Location)\n",
    "location_description = soup.find('div', string='Location Description').find_next('div').text.strip()\n",
    "\n",
    "# For Owner Info, we need to extract and clean it\n",
    "owner_info_div = soup.find('div', string='Owner Info').find_next('div')\n",
    "\n",
    "# Extract owner name and address\n",
    "owner_info_raw = owner_info_div.text.strip()\n",
    "\n",
    "# Split owner info into lines\n",
    "owner_info_parts = owner_info_raw.split(\"\\n\")\n",
    "\n",
    "# Clean up and extract the name and address properly\n",
    "owner_name = owner_info_parts[0].strip() \n",
    "owner_address = \" \".join(owner_info_parts[1:]).strip()  \n",
    "\n",
    "# If \"Update Mailing Address\" appears in the address, remove it\n",
    "if \"Update Mailing Address\" in owner_address:\n",
    "    owner_address = owner_address.split(\"Update Mailing Address\")[0].strip()\n",
    "\n",
    "# Extract PLSS Location\n",
    "plss_location = soup.find('div', string='Public Land Survey System (PLSS) Location').find_next('div').text.strip()\n",
    "\n",
    "# Clean the PLSS Location\n",
    "plss_location_cleaned = ' '.join(plss_location.split())\n",
    "\n",
    "# Optionally, reformat for better readability (if you want to format it neatly)\n",
    "plss_location_cleaned = plss_location_cleaned.replace(\"Quarter:\", \"\\nQuarter:\").replace(\"Section:\", \"\\nSection:\").replace(\"Township:\", \"\\nTownship:\").replace(\"Range:\", \"\\nRange:\")\n",
    "\n",
    "# Extract the Section PDF Map link (if it exists)\n",
    "section_pdf_map = None\n",
    "\n",
    "# Find all the div elements with class 'skinny-row'\n",
    "pdf_map_rows = soup.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in pdf_map_rows:\n",
    "    # Look for an anchor tag within the row\n",
    "    link = row.find('a', href=True)\n",
    "    if link and \"SectionMap\" in link['href']:  # Check if the href contains \"SectionMap\"\n",
    "        section_pdf_map = link['href']\n",
    "        break \n",
    "\n",
    "# Print other extracted information\n",
    "print(f\"\\nLocation Description: {location_description}\")\n",
    "print(f\"\\nOwner Info:\")\n",
    "print(f\"Owner Name: {owner_name}\")\n",
    "print(f\"Owner Address: {owner_address}\")\n",
    "print(f\"\\nPublic Land Survey System (PLSS) Location: {plss_location_cleaned}\")\n",
    "print(f\"\\nSection PDF Map Link: {section_pdf_map}\")\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valuation Information\n",
    "* TODO: Show graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show graphs\n",
      "Get Taxes Due: http://apps.douglas.co.us/treasurer/treasurerweb/account.jsp?account=R0396965&guest=true\n",
      "Property Tax Calculation: https://www.douglas.co.us/assessor/residential-property-tax-calculations\n",
      "\n",
      "\n",
      "Year: 2024\n",
      "Actual Value: $1,502,829\n",
      "Assessed Value: $100,690\n",
      "Tax Rate: 11.6982%\n",
      "Est. Tax Amount: Tax Calculation\n",
      "\n",
      "\n",
      "Year: 2023\n",
      "Actual Value: $1,502,829\n",
      "Assessed Value: $100,690\n",
      "Tax Rate: 11.7909%\n",
      "Est. Tax Amount: Tax Calculation\n",
      "\n",
      "\n",
      "Year: 2022\n",
      "Actual Value: $1,082,358\n",
      "Assessed Value: $75,220\n",
      "Tax Rate: 11.4115%\n",
      "Est. Tax Amount: $8,584\n",
      "\n",
      "\n",
      "Year: 2021\n",
      "Actual Value: $1,082,358\n",
      "Assessed Value: $77,390\n",
      "Tax Rate: 11.5119%\n",
      "Est. Tax Amount: $8,909\n",
      "\n",
      "\n",
      "Year: 2020\n",
      "Actual Value: $1,263,238\n",
      "Assessed Value: $90,320\n",
      "Tax Rate: 11.5502%\n",
      "Est. Tax Amount: $10,432\n",
      "\n",
      "\n",
      "Year: 2019\n",
      "Actual Value: $1,263,238\n",
      "Assessed Value: $90,320\n",
      "Tax Rate: 11.5845%\n",
      "Est. Tax Amount: $10,463\n",
      "\n",
      "\n",
      "Year: 2018\n",
      "Actual Value: $1,373,919\n",
      "Assessed Value: $98,920\n",
      "Tax Rate: 11.7284%\n",
      "Est. Tax Amount: $11,602\n",
      "\n",
      "\n",
      "Year: 2017\n",
      "Actual Value: $1,373,919\n",
      "Assessed Value: $98,920\n",
      "Tax Rate: 11.1080%\n",
      "Est. Tax Amount: $10,988\n",
      "\n",
      "\n",
      "Year: 2016\n",
      "Actual Value: $1,040,473\n",
      "Assessed Value: $82,820\n",
      "Tax Rate: 11.2720%\n",
      "Est. Tax Amount: $9,335\n",
      "\n",
      "\n",
      "Year: 2015\n",
      "Actual Value: $1,040,473\n",
      "Assessed Value: $82,820\n",
      "Tax Rate: 11.4697%\n",
      "Est. Tax Amount: $9,499\n",
      "\n",
      "\n",
      "Year: 2014\n",
      "Actual Value: $926,755\n",
      "Assessed Value: $73,770\n",
      "Tax Rate: 12.0623%\n",
      "Est. Tax Amount: $8,898\n",
      "\n",
      "\n",
      "Year: 2013\n",
      "Actual Value: $926,755\n",
      "Assessed Value: $73,770\n",
      "Tax Rate: 12.0717%\n",
      "Est. Tax Amount: $8,905\n",
      "\n",
      "\n",
      "Year: 2012\n",
      "Actual Value: $1,031,011\n",
      "Assessed Value: $82,070\n",
      "Tax Rate: 12.1247%\n",
      "Est. Tax Amount: $9,951\n",
      "\n",
      "\n",
      "Year: 2011\n",
      "Actual Value: $1,031,011\n",
      "Assessed Value: $82,070\n",
      "Tax Rate: 12.1369%\n",
      "Est. Tax Amount: $9,961\n",
      "\n",
      "\n",
      "Year: 2010\n",
      "Actual Value: $1,300,000\n",
      "Assessed Value: $103,480\n",
      "Tax Rate: 11.9306%\n",
      "Est. Tax Amount: $12,346\n",
      "\n",
      "\n",
      "Year: 2009\n",
      "Actual Value: $1,300,000\n",
      "Assessed Value: $103,480\n",
      "Tax Rate: 11.8969%\n",
      "Est. Tax Amount: $12,311\n",
      "\n",
      "\n",
      "Year: 2008\n",
      "Actual Value: $1,263,286\n",
      "Assessed Value: $100,560\n",
      "Tax Rate: 11.9420%\n",
      "Est. Tax Amount: $12,009\n",
      "\n",
      "\n",
      "Year: 2007\n",
      "Actual Value: $1,263,286\n",
      "Assessed Value: $100,560\n",
      "Tax Rate: 11.8764%\n",
      "Est. Tax Amount: $11,943\n",
      "\n",
      "\n",
      "Year: 2006\n",
      "Actual Value: $1,277,673\n",
      "Assessed Value: $101,700\n",
      "Tax Rate: 11.8862%\n",
      "Est. Tax Amount: $12,088\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store toggle button and links\n",
    "key_value_pairs = {}\n",
    "\n",
    "# Extract the toggle button text (Show Graphs)\n",
    "toggle_button = soup.find('span', class_='ui-button-text')\n",
    "if toggle_button:\n",
    "    print(toggle_button.text.strip())  # Print 'Show Graphs'\n",
    "\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "links = soup.find_all('a', href=True)\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    \n",
    "    # Print specific links that we are interested in\n",
    "    if link_text == \"Get Taxes Due\":\n",
    "        print(f'{link_text}: {link_url}')  # Hyperlink Get Taxes Due\n",
    "    elif link_text == \"Property Tax Calculation\":\n",
    "        print(f'{link_text}: {link_url}')  # Hyperlink Property Tax Calculation\n",
    "\n",
    "# Now continue with the part for finding and processing the table data\n",
    "# Find the table with class 'value-data-table'\n",
    "table = soup.find('table', class_='value-data-table')\n",
    "if table:\n",
    "    # print(\"Table found\")  \n",
    "\n",
    "    # Find all tbody elements inside the table with the 'sales-info' class, without specifying the dynamic part\n",
    "    rows = table.find_all('tbody', class_='value-row')  \n",
    "\n",
    "    # Check how many rows are found\n",
    "    # print(f\"Found {len(rows)} tbody elements.\")  \n",
    "\n",
    "    # Iterate over each row and extract data\n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract Year, Actual Value, Assessed Value, Tax Rate, Est. Tax Amount\n",
    "        year = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        actual_value = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        assesssed_value = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        tax_rate = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        est_tax_amount = row.find_all('td')[4].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "    \n",
    "        # Store row data in a dictionary\n",
    "        row_data = {\n",
    "            'Year': year,\n",
    "            'Actual Value': actual_value,\n",
    "            'Assessed Value': assesssed_value,\n",
    "            'Tax Rate': tax_rate,\n",
    "            'Est. Tax Amount': est_tax_amount\n",
    "        }\n",
    "        \n",
    "        sales_data.append(row_data)\n",
    "\n",
    "    # Print extracted data\n",
    "    for row in sales_data:\n",
    "        print(\"\\n\")\n",
    "        for key, value in row.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "else:\n",
    "    print(\"Table not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales History\n",
    "* Show graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Neighborhood Sales: https://co-douglas-residential.comper.info/template.aspx?propertyID=R0396965\n",
      "Recorded Document Search: https://apps.douglas.co.us/LandMarkWeb\n",
      "\n",
      "\n",
      "Reception No: 2020118714\n",
      "Sale Date: 11/30/2020\n",
      "Sale Price: $0\n",
      "Deed Type: Bargain & Sale Common\n",
      "Grantor: HENDRIX 2006 FAMILY TRUST\n",
      "Grantee: DENNIS R HENDRIX & JENNIE M HENDRIX\n",
      "\n",
      "\n",
      "Reception No: 2020118716\n",
      "Sale Date: 11/30/2020\n",
      "Sale Price: $0\n",
      "Deed Type: Bargain & Sale\n",
      "Grantor: DENNIS R HENDRIX\n",
      "Grantee: DENNIS R HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST\n",
      "\n",
      "\n",
      "Reception No: 2020118717\n",
      "Sale Date: 11/30/2020\n",
      "Sale Price: $0\n",
      "Deed Type: Bargain & Sale\n",
      "Grantor: JENNIE M HENDRIX\n",
      "Grantee: JENNIE M HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST\n",
      "\n",
      "\n",
      "Reception No: 2018058752\n",
      "Sale Date: 09/25/2018\n",
      "Sale Price: $1,290,000\n",
      "Deed Type: Warranty Deed\n",
      "Grantor: BRIAN J HUBBELL & SUSAN A HUBBELL\n",
      "Grantee: HENDRIX 2006 FAMILY TRUST\n",
      "\n",
      "\n",
      "Reception No: 2015045662\n",
      "Sale Date: 06/30/2015\n",
      "Sale Price: $1,300,000\n",
      "Deed Type: Warranty Deed Joint\n",
      "Grantor: SIMONS LIVING TRUST\n",
      "Grantee: BRIAN J HUBBELL & SUSAN A HUBBELL\n",
      "\n",
      "\n",
      "Reception No: 2007028472\n",
      "Sale Date: 03/07/2007\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim\n",
      "Grantor: ROBERT E SIMONS & ANNE M SIMONS\n",
      "Grantee: SIMONS LIVING TRUST\n",
      "\n",
      "\n",
      "Reception No: 2005079717\n",
      "Sale Date: 07/25/2005\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim Joint\n",
      "Grantor: ROBERT E SIMONS\n",
      "Grantee: ROBERT E SIMONS & ANNE M SIMONS\n",
      "\n",
      "\n",
      "Reception No: 2005071549\n",
      "Sale Date: 07/11/2005\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim\n",
      "Grantor: ROBERT E SIMONS & ANNE M SIMONS\n",
      "Grantee: ROBERT E SIMONS\n",
      "\n",
      "\n",
      "Reception No: 01079973\n",
      "Sale Date: 08/28/2001\n",
      "Sale Price: $1,655,000\n",
      "Deed Type: Warranty Deed Joint\n",
      "Grantor: IRWIN S FISHMAN & MURIEL P FISHMAN\n",
      "Grantee: ROBERT E SIMONS & ANNE M SIMONS\n",
      "\n",
      "\n",
      "Reception No: 99062109\n",
      "Sale Date: 07/09/1999\n",
      "Sale Price: $908,000\n",
      "Deed Type: Warranty Deed\n",
      "Grantor: PETRY DEVELOPMENT CO\n",
      "Grantee: IRWIN S FISHMAN & MURIEL P FISHMAN\n",
      "\n",
      "\n",
      "Reception No: 99062108\n",
      "Sale Date: 06/30/1999\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim\n",
      "Grantor: GLEN CASTLE PINES HOA\n",
      "Grantee: CP GLEN CO\n",
      "\n",
      "\n",
      "Reception No: 9774761\n",
      "Sale Date: 12/23/1997\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim\n",
      "Grantor: CP GLEN CO\n",
      "Grantee: PETRY DEV CO\n",
      "\n",
      "\n",
      "Reception No: 9611295\n",
      "Sale Date: 02/09/1996\n",
      "Sale Price: $0\n",
      "Deed Type: Quit Claim\n",
      "Grantor: GLEN AT CASTLE PINES HOA\n",
      "Grantee: CP GLEN\n"
     ]
    }
   ],
   "source": [
    "# Find the table with class 'sales-data-table table'\n",
    "table = soup.find('table', class_='sales-data-table table')\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "\n",
    "links = soup.find_all('a', href=True)\n",
    "# Use a set to track printed links, avoid duplications\n",
    "printed_links = set()  \n",
    "\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    \n",
    "    # Print specific links that we are interested in, only if not already printed\n",
    "    if link_text == \"View Neighborhood Sales\" and link_url not in printed_links:\n",
    "        print(f'{link_text}: {link_url}')\n",
    "        printed_links.add(link_url)  # Mark this link as printed\n",
    "    elif link_text == \"Recorded Document Search\" and link_url not in printed_links:\n",
    "        print(f'{link_text}: {link_url}')\n",
    "        printed_links.add(link_url)\n",
    "\n",
    "        \n",
    "if table:\n",
    "    # print(\"Table found\")  \n",
    "    \n",
    "    # Find all tbody elements inside the table with the 'sales-info' class, without specifying the dynamic part\n",
    "    rows = table.find_all('tbody', class_='sales-info')  \n",
    "    # print(f\"Found {len(rows)} tbody elements.\")  \n",
    "    \n",
    "    # Iterate over each row and extract data\n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract Reception No, Sale Date, Sale Price, Deed Type, etc.\n",
    "        reception_no = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 0 else None\n",
    "        \n",
    "        sale_date = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        sale_price = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        deed_type = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 2 else None\n",
    "        \n",
    "        # Extract Grantor and Grantee\n",
    "        sales_details_row = row.find_next('tr', class_='sales-details')\n",
    "        if sales_details_row:\n",
    "            grantor_grantee_div = sales_details_row.find('div', class_='col-sm-9 col-xs-12')\n",
    "            if grantor_grantee_div:\n",
    "                grantor = grantor_grantee_div.find_all('span', class_='ng-star-inserted')[0].text.strip().replace('Grantor:', '').strip()\n",
    "                grantee = grantor_grantee_div.find_all('span', class_='ng-star-inserted')[1].text.strip().replace('Grantee:', '').strip()\n",
    "            else:\n",
    "                grantor, grantee = None, None\n",
    "        else:\n",
    "            grantor, grantee = None, None\n",
    "        \n",
    "        # Store row data in a dictionary\n",
    "        row_data = {\n",
    "            'Reception No': reception_no,\n",
    "            'Sale Date': sale_date,\n",
    "            'Sale Price': sale_price,\n",
    "            'Deed Type': deed_type,\n",
    "            'Grantor': grantor,\n",
    "            'Grantee': grantee\n",
    "        }\n",
    "        \n",
    "        sales_data.append(row_data)\n",
    "\n",
    "    # Print extracted data\n",
    "    for row in sales_data:\n",
    "        print(\"\\n\")\n",
    "        for key, value in row.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "\n",
    "else:\n",
    "    print(\"Table not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Details\n",
    "\n",
    "* <span style=\"color: red;\">having trouble formatting Primary Info section</span>\n",
    "\n",
    "* picture (x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images:\n",
      "  /realware/PHOTOS/R0396965/2009_IMP_1_WEBafront.jpg\n",
      "  /realware/SKETCHES/R0396965/2023_IMP_1_Page 1 - Apex R0396965 Imp No - 1.00.JPG\n",
      "\n",
      "Primary Info:\n",
      "  Property Type:                                  Residential Year Built:1997\n",
      "  Square Footage:                                  3,463 sqft Style:Ranch 1 Story\n",
      "\n",
      "Additional Features:\n",
      "  Quality: Excellent\n",
      "  Quality: Excellent\n",
      "  % Complete: 100%\n",
      "  Stories: 1\n",
      "  Bedrooms (above ground): 1\n",
      "  Bathrooms (above ground): 2\n",
      "  Basement Area: 3,379 sqft\n",
      "  Finished Bsmt. Area: 2,710 sqft (80%)\n",
      "  Total Finished Area: 6,173 sqft\n",
      "  Walkout: Y\n",
      "  Fireplaces: 3\n",
      "  Porch/Deck Area: 1,384 sqft\n",
      "  Garage Type Garage Area\n",
      "  Attached: 1,078 sqft\n",
      "  Detached: 0 sqft\n",
      "  Assessor's Building ID: 1\n"
     ]
    }
   ],
   "source": [
    "building_data = {}\n",
    "\n",
    "# Find the building details section using its ID\n",
    "building_details = soup.find('div', {'id': 'BuildingDetails'})\n",
    "\n",
    "if building_details:\n",
    "    # Scrape building images\n",
    "    images = building_details.find_all('img', class_='bordered')\n",
    "    image_urls = [img['src'] for img in images if img.has_attr('src')]\n",
    "    building_data['Images'] = image_urls\n",
    "    \n",
    "    # Scrape building primary info (property type, year built, etc.)\n",
    "    building_info = building_details.find_all('div', class_='smart-table')\n",
    "    primary_info = {}\n",
    "\n",
    "    for info in building_info:\n",
    "        # Find the label and value pairs for each group\n",
    "        label_elements = info.find_all('div', recursive=False)\n",
    "        \n",
    "        # Ensure there are exactly two divs, one for the label and one for the value\n",
    "        if len(label_elements) == 2:\n",
    "            label = label_elements[0].text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            value = label_elements[1].text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            \n",
    "            # Add the pair to the primary info dictionary\n",
    "            primary_info[label] = value\n",
    "\n",
    "    building_data['\\nPrimary Info'] = primary_info\n",
    "\n",
    "    \n",
    "    # Scrape additional features and fixtures\n",
    "    additional_features = []\n",
    "    more_details = building_details.find_all('div', class_='skinny-row')\n",
    "    for detail in more_details:\n",
    "        name = detail.find('span', class_='name')\n",
    "        value = detail.find('span', class_='value')\n",
    "        if name and value:\n",
    "            name_text = name.text.strip().replace('\\n', ' ')\n",
    "            value_text = value.text.strip().replace('\\n', ' ')\n",
    "            additional_features.append({name_text: value_text})\n",
    "    \n",
    "    building_data['\\nAdditional Features'] = additional_features\n",
    "\n",
    "else:\n",
    "    print(\"Building details section not found.\")\n",
    "\n",
    "# Print the scraped data, each key-value pair on its own line\n",
    "for key, value in building_data.items():\n",
    "    print(f\"{key}:\")\n",
    "    if isinstance(value, list):\n",
    "        for item in value:\n",
    "            # If the value is a dictionary (for additional features)\n",
    "            if isinstance(item, dict): \n",
    "                for sub_key, sub_value in item.items():\n",
    "                    print(f\"  {sub_key} {sub_value}\")\n",
    "            else:\n",
    "                print(f\"  {item}\")\n",
    "    else:\n",
    "        # For primary info, print each label-value pair on a new line\n",
    "        if key == '\\nPrimary Info': \n",
    "            for label, value in value.items():\n",
    "                print(f\"  {label} {value}\")\n",
    "        else:\n",
    "            print(f\"  {value}\")\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Type: Residential\n",
      "Class Code: 1112\n",
      "Class Code Descr.: IMPROVED RESIDENTIAL LAND\n",
      "Acreage: 0.230 acres\n",
      "LEA Code: 4AA\n",
      "Actual Value $350,855\n"
     ]
    }
   ],
   "source": [
    "land_info = {}\n",
    "\n",
    "# Find the \"LandInfoAndValue\" section\n",
    "land_info_section = soup.find('div', {'id': 'LandInfoAndValue'})\n",
    "\n",
    "if land_info_section:\n",
    "    # Scrape Land Details (Land Type, Class Code, etc.)\n",
    "    land_details = land_info_section.find_all('div', class_='row')\n",
    "    \n",
    "    for detail in land_details:\n",
    "        label = detail.find('div', class_='col-xs-3')\n",
    "        value = detail.find('div', class_='col-xs-9')\n",
    "        \n",
    "        if label and value:\n",
    "            # Clean up label and value text\n",
    "            label_text = label.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            value_text = value.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            \n",
    "            # Add label-value pair to the dictionary\n",
    "            land_info[label_text] = value_text\n",
    "    \n",
    "    # Scrape Land Valuation (Actual Value)\n",
    "    valuation_section = land_info_section.find('div', class_='header')\n",
    "    if valuation_section and 'Land Valuation' in valuation_section.text:\n",
    "        # Last row is the valuation row\n",
    "        valuation_row = land_info_section.find_all('div', class_='row')[-1]  \n",
    "        actual_value_label = valuation_row.find('div', class_='col-sm-3')\n",
    "        actual_value = valuation_row.find('div', class_='col-sm-9')\n",
    "        \n",
    "        if actual_value_label and actual_value:\n",
    "            land_info['Actual Value'] = actual_value.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "# Print the scraped land info\n",
    "for key, value in land_info.items():\n",
    "    print(f\"{key} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tax Authorities\n",
    "* Show graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ID: 2001\n",
      "Authority Name: Douglas County Re-1 School District\n",
      "Mills: 40.324\n",
      "Tax Rate: 4.0324%\n",
      "Est. Tax Amount: $4,060\n",
      "\n",
      "\n",
      "ID: 4016\n",
      "Authority Name: Castle Pines Metro District\n",
      "Mills: 33.834\n",
      "Tax Rate: 3.3834%\n",
      "Est. Tax Amount: $3,407\n",
      "\n",
      "\n",
      "ID: 0001\n",
      "Authority Name: Douglas County Government\n",
      "Mills: 18.726\n",
      "Tax Rate: 1.8726%\n",
      "Est. Tax Amount: $1,886\n",
      "\n",
      "\n",
      "ID: 4014\n",
      "Authority Name: South Metro Fire Rescue Fire Protection District\n",
      "Mills: 9.290\n",
      "Tax Rate: 0.9290%\n",
      "Est. Tax Amount: $935\n",
      "\n",
      "\n",
      "ID: 2004\n",
      "Authority Name: Douglas County Schools - Debt Service\n",
      "Mills: 5.204\n",
      "Tax Rate: 0.5204%\n",
      "Est. Tax Amount: $524\n",
      "\n",
      "\n",
      "ID: 0002\n",
      "Authority Name: Douglas County Law Enforcement\n",
      "Mills: 4.500\n",
      "Tax Rate: 0.4500%\n",
      "Est. Tax Amount: $453\n",
      "\n",
      "\n",
      "ID: 4390\n",
      "Authority Name: Douglas Public Library District\n",
      "Mills: 4.000\n",
      "Tax Rate: 0.4000%\n",
      "Est. Tax Amount: $403\n",
      "\n",
      "\n",
      "ID: 4002\n",
      "Authority Name: Urban Drainage & Flood Control District\n",
      "Mills: 0.900\n",
      "Tax Rate: 0.0900%\n",
      "Est. Tax Amount: $91\n",
      "\n",
      "\n",
      "ID: 4012\n",
      "Authority Name: Cedar Hill Cemetery Association\n",
      "Mills: 0.104\n",
      "Tax Rate: 0.0104%\n",
      "Est. Tax Amount: $10\n",
      "\n",
      "\n",
      "ID: 4392\n",
      "Authority Name: Urban Drainage & Flood South Platte\n",
      "Mills: 0.100\n",
      "Tax Rate: 0.0100%\n",
      "Est. Tax Amount: $10\n",
      "\n",
      "\n",
      "ID: 2002\n",
      "Authority Name: Douglas County Schools - Cap Reserve\n",
      "Mills: 0.000\n",
      "Tax Rate: 0.0000%\n",
      "Est. Tax Amount: $0\n",
      "\n",
      "\n",
      "ID: 2003\n",
      "Authority Name: Douglas County Schools - Insurance Reserve\n",
      "Mills: 0.000\n",
      "Tax Rate: 0.0000%\n",
      "Est. Tax Amount: $0\n",
      "\n",
      "\n",
      "ID: 4077\n",
      "Authority Name: Douglas County Soil Conservation District\n",
      "Mills: 0.000\n",
      "Tax Rate: 0.0000%\n",
      "Est. Tax Amount: $0\n"
     ]
    }
   ],
   "source": [
    "# Find the table with class 'tax-data-table table'\n",
    "table = soup.find('table', class_='tax-data-table table')\n",
    "\n",
    "if table:\n",
    "    # Find all tbody elements inside the table with the 'tax-info' class (except the last 'total-row')\n",
    "    rows = table.find_all('tbody', class_='tax-info')  \n",
    "    \n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract data from the first row\n",
    "        tax_id = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 0 else None\n",
    "        authority_name = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        mills = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 2 else None\n",
    "        tax_rate = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 3 else None\n",
    "        tax_amount = row.find_all('td')[4].text.strip() if len(row.find_all('td')) > 4 else None\n",
    "        \n",
    "        # Store row data in a dictionary\n",
    "        row_data = {\n",
    "            'ID': tax_id,\n",
    "            'Authority Name': authority_name,\n",
    "            'Mills': mills,\n",
    "            'Tax Rate': tax_rate,\n",
    "            'Est. Tax Amount': tax_amount\n",
    "        }\n",
    "        \n",
    "        sales_data.append(row_data)\n",
    "\n",
    "    # Print extracted data\n",
    "    for row in sales_data:\n",
    "        print(\"\\n\")\n",
    "        for key, value in row.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        # print('---' * 50)\n",
    "\n",
    "else:\n",
    "    print(\"Table not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Authorities: 13 Authorities\n",
      "Total Mills: 116.982\n",
      "Total Tax Rate: 11.6982%\n",
      "Total Tax Amount: $11,779\n"
     ]
    }
   ],
   "source": [
    "all_total_data = []\n",
    "\n",
    "total_row = table.find_all('tbody')[-1] \n",
    "\n",
    "if total_row:\n",
    "    total_cells = total_row.find_all('td')\n",
    "    if len(total_cells) >= 5:\n",
    "        total_data = {\n",
    "            'Total Authorities': total_cells[1].text.strip(),\n",
    "            'Total Mills': total_cells[2].text.strip(),\n",
    "            'Total Tax Rate': total_cells[3].text.strip(),\n",
    "            'Total Tax Amount': total_cells[4].text.strip()\n",
    "        }\n",
    "        all_total_data.append(total_data)\n",
    "\n",
    "# Print extracted data\n",
    "for row in all_total_data:\n",
    "    for key, value in row.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents \n",
    "* actual pull pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Name: R0396965_NOV_2024.pdf\n",
      "  Size: 138.9kb\n",
      "  Last Modified Date: Apr 23, 2024\n",
      "\n",
      "Document Name: R0396965_NOV_2023.pdf\n",
      "  Size: 129.7kb\n",
      "  Last Modified Date: May 1, 2023\n",
      "\n",
      "Document Name: R0396965_NOV_2022.pdf\n",
      "  Size: 120.2kb\n",
      "  Last Modified Date: Apr 21, 2022\n",
      "\n",
      "Document Name: R0396965_NOV_2021.pdf\n",
      "  Size: 322.8kb\n",
      "  Last Modified Date: Jul 7, 2021\n",
      "\n",
      "Document Name: R0396965_NOV_2020.pdf\n",
      "  Size: 324kb\n",
      "  Last Modified Date: Jun 11, 2020\n",
      "\n",
      "Document Name: R0396965_NOV_2019.pdf\n",
      "  Size: 324kb\n",
      "  Last Modified Date: Jun 15, 2020\n",
      "\n",
      "Document Name: R0396965_NOV_2018.pdf\n",
      "  Size: 324.9kb\n",
      "  Last Modified Date: Jun 17, 2020\n",
      "\n",
      "Document Name: R0396965_NOV_2017.pdf\n",
      "  Size: 323.7kb\n",
      "  Last Modified Date: Jun 18, 2020\n"
     ]
    }
   ],
   "source": [
    "dropdown_content = soup.find('div', id='Documents').find('div', class_='dropdown-content')\n",
    "\n",
    "# Find the list of documents inside the dropdown\n",
    "documents_list = dropdown_content.find_all('li', class_='ng-star-inserted') if dropdown_content else []\n",
    "\n",
    "if documents_list:\n",
    "    # Initialize an empty dictionary to store document data\n",
    "    document_data = {}\n",
    "\n",
    "    # Iterate through each document item and extract the desired data\n",
    "    for doc in documents_list:\n",
    "        # Get document name (PDF filename)\n",
    "        doc_name = doc.find('a').text.strip() if doc.find('a') else None\n",
    "        \n",
    "        # Get file size\n",
    "        size = doc.find('div', class_='col-sm-2')\n",
    "        size = size.text.strip().replace('Size:', '').strip() if size else None\n",
    "        \n",
    "        # Get last modified date\n",
    "        last_modified = doc.find('div', class_='col-sm-4')\n",
    "        last_modified = last_modified.text.strip().replace('Last Modified Date:', '').strip() if last_modified else None\n",
    "        \n",
    "        # Store the extracted data in the dictionary with document name as the key\n",
    "        document_data[doc_name] = {\n",
    "            'Size': size,\n",
    "            'Last Modified Date': last_modified\n",
    "        }\n",
    "\n",
    "    # Print the document data dictionary\n",
    "    for doc_name, details in document_data.items():\n",
    "        print(f\"\\nDocument Name: {doc_name}\")\n",
    "        for key, value in details.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        # print('---' * 50)\n",
    "\n",
    "else:\n",
    "    print(\"No documents found \")\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notification 1. The 2024 Actual Value for this parcel is reflective of the statutory Appraisal Date of June 30, 2022. Sale transactions that occurred after that date will be considered in the 2025 reassessment.\n",
      "\n",
      "Notification 2. In compliance with Senate Bill 24-233, the 2024 Taxable Actual Value on this property will be reduced by $55,000, which only applies to certain residential property, and will be reflected on next year’s tax bill.\n",
      "\n",
      "Notification 3. This property was eligible for a property tax relief payment from Douglas County Government, which are equal to the 2023 Adjusted Assessed Value times the 3.679 Reserve Mill Levy approved by the Board of County Commissioners.\n"
     ]
    }
   ],
   "source": [
    "dropdown_content = soup.find('div', id='TaxInformation').find('div', class_='dropdown-content')\n",
    "\n",
    "# Find the list of notifications inside the dropdown (each notification is wrapped in a <div> with the 'ng-star-inserted' class)\n",
    "notifications_list = dropdown_content.find_all('div', class_='ng-star-inserted') if dropdown_content else []\n",
    "\n",
    "if notifications_list:\n",
    "    # Initialize a list to store notification data\n",
    "    notifications_data = []\n",
    "\n",
    "    # Iterate through each notification item and extract the desired data\n",
    "    for notification in notifications_list:\n",
    "        notification_text = notification.find('span').text.strip() if notification.find('span') else None\n",
    "        \n",
    "        # Add each notification text to the list\n",
    "        notifications_data.append(notification_text)\n",
    "\n",
    "    # Print the notifications data\n",
    "    for index, notification in enumerate(notifications_data):\n",
    "        print(f\"\\nNotification {notification}\")\n",
    "        # print('---' * 50)\n",
    "else:\n",
    "    print(\"No notifications found in the dropdown.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
