{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://gisapp.adcogov.org/PropertySearch\")\n",
    "\n",
    "# Wait for the search box to be visible and locate it\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, \"search-text\"))\n",
    ")\n",
    "\n",
    "# Send search query\n",
    "search_box.send_keys(\"7471 E 157th Ave\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the table row containing the Parcel Number to be visible and clickable\n",
    "parcel_link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//table[@class='table']//tr[2]//td[1]//a\"))\n",
    ")\n",
    "\n",
    "# Click the Parcel Number link which opens a new tab\n",
    "parcel_link.click()\n",
    "\n",
    "# Wait for the new tab to open (wait until the number of windows (tabs) becomes 2)\n",
    "WebDriverWait(driver, 3).until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "# Get all window handles (tabs)\n",
    "windows = driver.window_handles\n",
    "\n",
    "# Switch to the new tab (the last window handle)\n",
    "driver.switch_to.window(windows[-1])\n",
    "\n",
    "# Extract the parcel number from the new page (you can adjust the XPath as needed)\n",
    "parcel_number = driver.current_url.split('pid=')[1]\n",
    "\n",
    "# Construct the new URL for scraping\n",
    "new_url = f\"https://gisapp.adcogov.org/QuickSearch/doreport.aspx?pid={parcel_number}\"\n",
    "\n",
    "# Now, go to the new URL and scrape the data\n",
    "driver.get(new_url)\n",
    "\n",
    "# Wait for the page to load fully\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    ")\n",
    "\n",
    "# Extract page source for scraping\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parcel ID And Owner Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcel Number: 0157109207009\n",
      "Owner Name: MAQUEDA ARMANDO\n",
      "Property Address: 7471 E 157TH AVE  THORNTON CO\n"
     ]
    }
   ],
   "source": [
    "# Extract the Parcel Number using regex (13 digits)\n",
    "parcel_number_text = None\n",
    "parcel_number = soup.find('span', {'class': 'ParcelIDAndOwnerInformation'})\n",
    "if parcel_number:\n",
    "    # Search for a 13-digit number in the text\n",
    "    match = re.search(r'\\d{13}', parcel_number.text.strip())\n",
    "    if match:\n",
    "        parcel_number_text = match.group(0)  # Extract the matched 13-digit number\n",
    "    else:\n",
    "        parcel_number_text = \"Parcel Number Not Found\"\n",
    "else:\n",
    "    parcel_number_text = \"Parcel Number Not Found\"\n",
    "\n",
    "# Extract Owner's Name\n",
    "owner_name = soup.find('span', {'id': 'ownerNameLabel'}).text.strip()\n",
    "\n",
    "# Extract Property Address\n",
    "property_address = soup.find('td', {'id': 'propertyContentCell'}).text.strip()\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "property_data = {\n",
    "    \"Parcel Number\": parcel_number_text,\n",
    "    \"Owner Name\": owner_name,\n",
    "    \"Property Address\": property_address\n",
    "}\n",
    "\n",
    "# Output the dictionary\n",
    "for key, value in property_data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal Description: TALON VIEW SUBDIVISION BLK 11 LOT 16\n",
      "Subdivision Plat: TALON VIEW\n",
      "Account Summary:\n",
      "  Account Number: R0179391\n",
      "  Date Added: 07/19/2010\n",
      "  Tax District: 528\n",
      "  Mill Levy: 199.526\n"
     ]
    }
   ],
   "source": [
    "account_summary_data = {}\n",
    "\n",
    "# Extract Legal Description\n",
    "legal_description_section = soup.find('div', {'id': 'Panel'})\n",
    "if legal_description_section:\n",
    "    legal_description = legal_description_section.find_next('div', {'class': 'SingleValueBoxElement'})\n",
    "    if legal_description:\n",
    "        legal_description = legal_description.text.strip()\n",
    "\n",
    "# Extract Subdivision Plat\n",
    "subdivision_plat_section = soup.find('span', string=\"Subdivision Plat\")\n",
    "if subdivision_plat_section:\n",
    "    subdivision_plat = subdivision_plat_section.find_next('div', {'class': 'SingleValueBoxElement'})\n",
    "    if subdivision_plat:\n",
    "        subdivision_plat = subdivision_plat.text.strip()\n",
    "\n",
    "# Extract Account Summary Table\n",
    "account_summary_table = soup.find('div', {'class': 'TaxAccountSummary'}).find('table')\n",
    "\n",
    "if account_summary_table:\n",
    "    # Extract row data from the table\n",
    "    rows = account_summary_table.find_all('tr')[1:]\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        account_summary_data[\"Account Number\"] = columns[0].text.strip()\n",
    "        account_summary_data[\"Date Added\"] = columns[1].text.strip()\n",
    "        account_summary_data[\"Tax District\"] = columns[2].text.strip()\n",
    "        account_summary_data[\"Mill Levy\"] = columns[3].text.strip()\n",
    "\n",
    "# Create a dictionary to store all the data\n",
    "property_data = {\n",
    "    \"Legal Description\": legal_description if legal_description else \"\",\n",
    "    \"Subdivision Plat\": subdivision_plat if subdivision_plat else \"\",\n",
    "    \"Account Summary\": account_summary_data if account_summary_data else \"\"\n",
    "}\n",
    "\n",
    "# Output the dictionary, printing each item on a new line\n",
    "for key, value in property_data.items():\n",
    "    if isinstance(value, dict): \n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permit Cases: N/A\n"
     ]
    }
   ],
   "source": [
    "permits = {}\n",
    "\n",
    "permit_cases_section = soup.find('span', string=\"Permit Cases\")\n",
    "permit_cases_value = \"Not Available\"  # Default value\n",
    "\n",
    "if permit_cases_section:\n",
    "    permit_cases_value = permit_cases_section.find_next('div', {'class': 'MultiValueBoxElement'})\n",
    "    if permit_cases_value:\n",
    "        permit_cases_value = permit_cases_value.text.strip()\n",
    "\n",
    "\n",
    "permits[\"Permit Cases\"] = permit_cases_value\n",
    "\n",
    "# Output the dictionary\n",
    "for key, value in permits.items():\n",
    "    if isinstance(value, dict): \n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sale Date: 10/23/2014\n",
      "Sale Price: $0\n",
      "Deed Type: BLK\n",
      "Reception Number: 2014000078597\n",
      "Book: 2014\n",
      "Page: \n",
      "Grantor: COLORADO PROPERTY INVESTMENTS INC\n",
      "Grantee: ELG INVESTORS LLC\n",
      "Doc. Fee: $0\n",
      "Doc. Date: 11/07/2014\n",
      "\n",
      "Sale Date: 05/26/2017\n",
      "Sale Price: $4,039,000.00\n",
      "Deed Type: BLK\n",
      "Reception Number: 2017000046039\n",
      "Book: \n",
      "Page: \n",
      "Grantor: ELG INVESTORS LLC\n",
      "Grantee: EQUINOX DEVELOPMENT LLC\n",
      "Doc. Fee: $403.9\n",
      "Doc. Date: 05/30/2017\n",
      "\n",
      "Sale Date: 05/26/2017\n",
      "Sale Price: $4,824,000.00\n",
      "Deed Type: BLK\n",
      "Reception Number: 2017000046079\n",
      "Book: \n",
      "Page: \n",
      "Grantor: EQUINOX DEVELOPMENT LLC\n",
      "Grantee: MELODY HOMES INC\n",
      "Doc. Fee: $482.4\n",
      "Doc. Date: 05/30/2017\n",
      "\n",
      "Sale Date: 04/27/2020\n",
      "Sale Price: $452,940.00\n",
      "Deed Type: SWD\n",
      "Reception Number: 2020000038465\n",
      "Book: \n",
      "Page: \n",
      "Grantor: MELODY HOMES INC\n",
      "Grantee: CALLISON MARC MAX AND, CALLISON RACHEL MICHELLE\n",
      "Doc. Fee: $45.29\n",
      "Doc. Date: 04/28/2020\n",
      "\n",
      "Sale Date: 11/08/2024\n",
      "Sale Price: $570,000.00\n",
      "Deed Type: SWD\n",
      "Reception Number: 2024000062692\n",
      "Book: \n",
      "Page: \n",
      "Grantor: CALLISON MARC MAX AND, CALLISON RACHEL MICHELLE\n",
      "Grantee: MAQUEDA ARMANDO\n",
      "Doc. Fee: $57\n",
      "Doc. Date: 11/12/2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_table = soup.find('table', rules='all', border=\"2\", style=\"border-width:2px;border-style:Double;width:100%;page-break-inside:avoid;\")  # Or use 'class_' or 'id' based on the HTML structure\n",
    "\n",
    "rows = sales_table.find_all('tr')[1:]  # Skipping the header row\n",
    "\n",
    "\n",
    "sale_data = []\n",
    "for row in rows:\n",
    "    # Find all table data (td) cells within the row\n",
    "    cells = row.find_all('td')\n",
    "    \n",
    "    # Check if the row has the correct number of columns (10 in this case)\n",
    "    if len(cells) == 10:\n",
    "        sale_dict = {\n",
    "            'Sale Date': cells[0].find('span').get_text(strip=True) if cells[0].find('span') else '',\n",
    "            'Sale Price': cells[1].find('span').get_text(strip=True) if cells[1].find('span') else '',\n",
    "            'Deed Type': cells[2].find('span').get_text(strip=True) if cells[2].find('span') else '',\n",
    "            'Reception Number': cells[3].find('span').get_text(strip=True) if cells[3].find('span') else '',\n",
    "            'Book': cells[4].find('span').get_text(strip=True) if cells[4].find('span') else '',\n",
    "            'Page': cells[5].find('span').get_text(strip=True) if cells[5].find('span') else '',\n",
    "            'Grantor': cells[6].find('span').get_text(strip=True) if cells[6].find('span') else '',\n",
    "            'Grantee': cells[7].find('span').get_text(strip=True) if cells[7].find('span') else '',\n",
    "            'Doc. Fee': cells[8].find('span').get_text(strip=True) if cells[8].find('span') else '',\n",
    "            'Doc. Date': cells[9].find('span').get_text(strip=True) if cells[9].find('span') else ''\n",
    "        }\n",
    "        \n",
    "        sale_data.append(sale_dict)\n",
    "\n",
    "if sale_data:\n",
    "    for sale in sale_data:\n",
    "        for key, value in sale.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        # add blank line between sales\n",
    "        print()\n",
    "else:\n",
    "    print(\"No sale data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valuation Summary\n",
    "* <span style=\"color: red;\">missing Total Property Value & *Total Adjusted Value</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Land Valuation Summary:\n",
      "  Account Number: R0179391\n",
      "  Land Type: Residential\n",
      "  Unit of Measure: Acres\n",
      "  Number of Units: 0.2403\n",
      "  Fire District: \n",
      "  School District: School District 27J-Brighton\n",
      "  Vacant/Improved: I\n",
      "  Actual Value: $105,000.00\n",
      "  Assessed Value: $7,040.00\n",
      "\n",
      "Improvements Valuation Summary:\n",
      "  Account Number: R0179391\n",
      "  Actual Value: $472,000.00\n",
      "  Assessed Value: $31,620.00\n"
     ]
    }
   ],
   "source": [
    "land_valuation_data = {}\n",
    "land_valuation_section = soup.find('span', string=\"Land Valuation Summary\")\n",
    "\n",
    "if land_valuation_section:\n",
    "    land_valuation_table = land_valuation_section.find_next('table', {'rules': 'all'})\n",
    "    if land_valuation_table:\n",
    "        rows = land_valuation_table.find_all('tr')[1:]  # Skip header row\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            if len(columns) > 0:\n",
    "                if columns[0].text.strip() and columns[0].text.strip() != \"Land Subtotal:\":\n",
    "                    land_valuation_data[\"Account Number\"] = columns[0].text.strip()\n",
    "                    land_valuation_data[\"Land Type\"] = columns[1].text.strip()\n",
    "                    land_valuation_data[\"Unit of Measure\"] = columns[2].text.strip()\n",
    "                    land_valuation_data[\"Number of Units\"] = columns[3].text.strip()\n",
    "                    land_valuation_data[\"Fire District\"] = columns[4].text.strip()\n",
    "                    land_valuation_data[\"School District\"] = columns[5].text.strip()\n",
    "                    land_valuation_data[\"Vacant/Improved\"] = columns[6].text.strip()\n",
    "                    land_valuation_data[\"Actual Value\"] = columns[7].text.strip()\n",
    "                    land_valuation_data[\"Assessed Value\"] = columns[8].text.strip()\n",
    "\n",
    "# Extract Improvements Valuation Summary\n",
    "improvements_valuation_data = {}\n",
    "improvements_valuation_section = soup.find('span', string=\"Improvements Valuation Summary\")\n",
    "\n",
    "if improvements_valuation_section:\n",
    "    improvements_valuation_table = improvements_valuation_section.find_next('table', {'rules': 'all'})\n",
    "    if improvements_valuation_table:\n",
    "        rows = improvements_valuation_table.find_all('tr')[1:]  # Skip header row\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            if len(columns) > 1:\n",
    "                # Only extract from valid rows with data (skip empty rows)\n",
    "                if columns[0].text.strip() and columns[0].text.strip() != \"Improvements Subtotal:\":\n",
    "                    improvements_valuation_data[\"Account Number\"] = columns[0].text.strip()\n",
    "                    improvements_valuation_data[\"Actual Value\"] = columns[1].text.strip()\n",
    "                    improvements_valuation_data[\"Assessed Value\"] = columns[2].text.strip()\n",
    "\n",
    "# # Extract Property Values (Total Property Value and Total Assessed Value)\n",
    "# total_property_values = {}\n",
    "# property_value_section = soup.find('span', string=\"Total Property Value\")\n",
    "\n",
    "# if property_value_section:\n",
    "#     property_value_table = property_value_section.find_next('table')\n",
    "#     if property_value_table:\n",
    "#         rows = property_value_table.find_all('tr')\n",
    "#         for row in rows:\n",
    "#             columns = row.find_all('td')\n",
    "            \n",
    "#             if len(columns) > 1:\n",
    "#                 if 'Total Property Value' in columns[0].text:\n",
    "#                     total_property_values[\"Total Property Value\"] = columns[1].text.strip()\n",
    "#                     total_property_values[\"Total Assessed Value\"] = columns[2].text.strip()\n",
    "\n",
    "# # Extract Adjusted Actual and Assessed Values (if separate section exists)\n",
    "# adjusted_values = {}\n",
    "# adjusted_value_section = soup.find('span', string=\"Adjusted Actual Value\")\n",
    "\n",
    "# if adjusted_value_section:\n",
    "#     adjusted_value_table = adjusted_value_section.find_next('table')\n",
    "#     if adjusted_value_table:\n",
    "#         rows = adjusted_value_table.find_all('tr')\n",
    "#         for row in rows:\n",
    "#             columns = row.find_all('td')\n",
    "            \n",
    "#             if len(columns) > 1:  # Ensure there are enough columns\n",
    "#                 if \"*Total Adjusted Value\" in columns[0].text:\n",
    "#                     adjusted_values[\"Adjusted Actual Value\"] = columns[1].text.strip()\n",
    "#                 if \"*Total Adjusted Assessed Value\" in columns[0].text:\n",
    "#                     adjusted_values[\"Adjusted Assessed Value\"] = columns[2].text.strip() if len(columns) > 2 else \"Not Available\"\n",
    "\n",
    "\n",
    "valuation_data = {\n",
    "    \"Land Valuation Summary\": land_valuation_data,\n",
    "    \"Improvements Valuation Summary\": improvements_valuation_data,\n",
    "    # \"Total Property Value\t\": total_property_values,\n",
    "    # \"Adjusted Values\": adjusted_values\n",
    "}\n",
    "\n",
    "\n",
    "for key, value in valuation_data.items():\n",
    "    print()\n",
    "    print(f\"{key}:\")\n",
    "    if isinstance(value, dict):  # Check if the value is a dictionary\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"  {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built As: Ranch 1 Story\n",
      "Year Built: 2019\n",
      "Building Type: Residential\n",
      "Construction Type: Frame Siding\n",
      "Built As SQ Ft: 1889\n",
      "Number of Rooms: 5\n",
      "Number of Baths: 2.00\n",
      "Number of Bedrooms: 3\n",
      "Attached Garage SQ Ft: 651\n",
      "Detached Garage Square Ft: \n",
      "Basement SQ Ft: \n",
      "Finished Basement SQ Ft: \n"
     ]
    }
   ],
   "source": [
    "building_section = soup.find('span', {'class': 'BuildingSummary'})\n",
    "\n",
    "building_data = {}\n",
    "\n",
    "# Extract the table with the building details\n",
    "table = building_section.find('table')\n",
    "\n",
    "# Loop through each row in the table to extract key-value pairs\n",
    "if table:\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 1:\n",
    "            label = cells[0].get_text(strip=True)\n",
    "            value = cells[1].get_text(strip=True)\n",
    "            building_data[label] = value\n",
    "\n",
    "\n",
    "for key, value in building_data.items():\n",
    "    print(f\"{key} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tax Summary\n",
    "* <span style=\"color: red;\">need to combine with https://adcotax.com/</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enterprise Zone Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property within Enterprise Zone: False\n"
     ]
    }
   ],
   "source": [
    "# Find the div containing the \"Property within Enterprise Zone\" section\n",
    "enterprise_zone_section = soup.find('span', {'class': 'EnterpriseZoneSection'})\n",
    "\n",
    "enterprise_zone_data = {}\n",
    "\n",
    "# Extract the title of the section (e.g., \"Property within Enterprise Zone\")\n",
    "title = enterprise_zone_section.find('span', {'id': 'Label'}).get_text(strip=True)\n",
    "\n",
    "# Extract the value (True/False) from the \"SingleValueBoxElement\" div\n",
    "value = enterprise_zone_section.find('div', {'class': 'SingleValueBoxElement'}).find('span').get_text(strip=True)\n",
    "\n",
    "# Store the key-value pair in the dictionary\n",
    "enterprise_zone_data[title] = value\n",
    "\n",
    "# Output the results\n",
    "for key, value in enterprise_zone_data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precincts and Legislative Representatives Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precinct:\n",
      "  Precinct: 161\n",
      "\n",
      "Commissioner Representative:\n",
      "  District: 1, Link: https://gisportal.adcogov.org/rdr/comm_district1.htm\n",
      "\n",
      "State House Representative:\n",
      "  District: 33, Link: https://leg.colorado.gov/legislators/william-lindstedt\n",
      "\n",
      "State Senate Representative:\n",
      "  District: 24, Link: https://leg.colorado.gov/legislators/kyle-mullica\n",
      "\n",
      "US Congress Representative:\n",
      "  District: 8, Link: https://gabeevans.house.gov/\n"
     ]
    }
   ],
   "source": [
    "representatives_data = {}\n",
    "\n",
    "# Find all sections related to each representative type (Commissioner, State House, State Senate, US Congress)\n",
    "representative_sections = soup.find_all('span', class_='PrecinctsLegislativeRepresentatives')\n",
    "\n",
    "# Loop through each section and extract relevant data\n",
    "for section in representative_sections:\n",
    "    # Check if a title (span with id='Label') exists\n",
    "    label_span = section.find('span', id='Label')\n",
    "    if label_span:\n",
    "        title = label_span.text.strip()  # Extract the title (e.g., \"Commissioner Representative\")\n",
    "    else:\n",
    "        title = \"Unknown Representative\"  # Default value if no title is found\n",
    "\n",
    "    # Find the corresponding table within the section\n",
    "    table = section.find('table')\n",
    "\n",
    "    if table:  # Only proceed if the table exists\n",
    "        # Loop through each row (skipping the header row)\n",
    "        for row in table.find_all('tr')[1:]:  # Skipping the first header row\n",
    "            columns = row.find_all('td')\n",
    "            if len(columns) > 1:\n",
    "                district = columns[0].text.strip()  # District number (or ID)\n",
    "                link_to_rep = columns[1].find('a')['href']  # Representative's link\n",
    "\n",
    "                # Store the data in the dictionary\n",
    "                if title not in representatives_data:\n",
    "                    representatives_data[title] = []\n",
    "                representatives_data[title].append({\n",
    "                    'District': district,\n",
    "                    'Link': link_to_rep\n",
    "                })\n",
    "\n",
    "    # Check for the Precinct section and extract its value\n",
    "    precinct_section = section.find('span', style=\"font-family:VERDANA, ARIAL, HELVETICA, SANS-SERIF;font-size:10pt;font-weight:normal;color:#000000;\")\n",
    "    if precinct_section:\n",
    "        precinct_value = precinct_section.text.strip()\n",
    "        if title not in representatives_data:\n",
    "            representatives_data[title] = []\n",
    "        representatives_data[title].append({\n",
    "            'Precinct': precinct_value\n",
    "        })\n",
    "\n",
    "# Output the results\n",
    "for title, reps in representatives_data.items():\n",
    "    if title == \"Unknown Representative\":  # Skip the unknown representative section\n",
    "        continue\n",
    "    print(f\"\\n{title}:\")\n",
    "    for rep in reps:\n",
    "        if 'District' in rep:  # Print district and link\n",
    "            print(f\"  District: {rep['District']}, Link: {rep['Link']}\")\n",
    "        if 'Precinct' in rep:  # Print precinct data\n",
    "            print(f\"  Precinct: {rep['Precinct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoning Authority: THORNTON\n",
      "Zoning: THORNTON\n"
     ]
    }
   ],
   "source": [
    "zoning_section = soup.find('div', {'class': 'ZoningSummary'})\n",
    "\n",
    "# Create an empty dictionary to store key-value pairs\n",
    "zoning_data = {}\n",
    "\n",
    "# Find the first table inside the zoning section\n",
    "zoning_table = zoning_section.find('table')\n",
    "\n",
    "# Iterate through the table rows to extract the zoning information\n",
    "rows = zoning_table.find_all('tr')\n",
    "\n",
    "# Skip the header row (first row), starting from the second row (index 1)\n",
    "for row in rows[1:]:  # Skips the first row (index 0) which contains the headers\n",
    "    # Find all columns (td tags) in the current row\n",
    "    cols = row.find_all('td')\n",
    "    \n",
    "    # Ensure the row has exactly two columns (Zoning Authority and Zoning)\n",
    "    if len(cols) == 2:\n",
    "        # Extract the text from each column\n",
    "        zoning_authority = cols[0].get_text(strip=True)  # Zoning Authority\n",
    "        zoning = cols[1].get_text(strip=True)  # Zoning\n",
    "        \n",
    "        # Store the key-value pair in the dictionary\n",
    "        zoning_data[\"Zoning Authority\"] = zoning_authority\n",
    "        zoning_data[\"Zoning\"] = zoning\n",
    "\n",
    "# Output the results as key-value pairs\n",
    "for key, value in zoning_data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
