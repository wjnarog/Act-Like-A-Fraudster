{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m         last_height \u001b[38;5;241m=\u001b[39m new_height\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Call the scroll function to load more results if applicable\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mscroll_to_load_more\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Now capture the page source after the search has resulted in new content\u001b[39;00m\n\u001b[1;32m     61\u001b[0m page_source \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n",
      "Cell \u001b[0;32mIn[27], line 49\u001b[0m, in \u001b[0;36mscroll_to_load_more\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Wait for new content to load\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust sleep time if necessary\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Calculate new scroll height and compare with the last height\u001b[39;00m\n\u001b[1;32m     52\u001b[0m new_height \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn document.body.scrollHeight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize the browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Go to the website\n",
    "driver.get(\"https://www.homes.com/\")\n",
    "\n",
    "# Wait for the body tag to load to ensure the page is ready\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    ")\n",
    "\n",
    "# Locate the search box using the class name\n",
    "search_box = WebDriverWait(driver, 20).until(\n",
    "    EC.element_to_be_clickable((By.CLASS_NAME, \"multiselect-search\"))  # Adjust if needed\n",
    ")\n",
    "\n",
    "# Ensure the input is in view and interactable\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", search_box)\n",
    "\n",
    "# Send search query\n",
    "search_box.send_keys(\"577 N 96th St\")\n",
    "# search_box.send_keys(\" 937 Sanctuary Cir\")\n",
    "# search_box.send_keys(\"2212 Pine St\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the initial results container to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"placard-container\"))  # Adjust as necessary\n",
    ")\n",
    "\n",
    "# Scroll to trigger more content loading if necessary\n",
    "def scroll_to_load_more():\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        # Scroll down to the bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # Wait for new content to load\n",
    "        time.sleep(3)  # Adjust sleep time if necessary\n",
    "        \n",
    "        # Calculate new scroll height and compare with the last height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break  # No more content to load\n",
    "        last_height = new_height\n",
    "\n",
    "# Call the scroll function to load more results if applicable\n",
    "scroll_to_load_more()\n",
    "\n",
    "# Now capture the page source after the search has resulted in new content\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "print(soup.title.text)\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the property information\n",
    "property_info = {}\n",
    "\n",
    "# Extract price\n",
    "# price_element = soup.find('span', {'class': 'property-info-price'})\n",
    "price_element = soup.find('span', {'id': 'price'})\n",
    "if price_element:\n",
    "    property_info['price'] = price_element.text.strip()\n",
    "else:\n",
    "    property_info['price'] = \"Not listed for sale\"\n",
    "\n",
    "# Extract address\n",
    "address_element = soup.find('span', {'class': 'property-info-address-main'})\n",
    "if address_element:\n",
    "    property_info['address'] = address_element.text.strip()\n",
    "else:\n",
    "    property_info['address'] = \"Address not available\"\n",
    "\n",
    "# Extract city, state, and zip code\n",
    "city_state_zip_element = soup.find('span', {'class': 'property-info-address-citystatezip'})\n",
    "if city_state_zip_element:\n",
    "    property_info['city_state_zip'] = city_state_zip_element.text.strip()\n",
    "else:\n",
    "    property_info['city_state_zip'] = \"City, State, Zip not available\"\n",
    "\n",
    "# Extract estimated payment\n",
    "estimated_payment_element = soup.find('p', {'class': 'property-estimated-info'})\n",
    "if estimated_payment_element:\n",
    "    property_info['estimated_payment'] = estimated_payment_element.text.strip()\n",
    "else:\n",
    "    property_info['estimated_payment'] = \"Estimated payment not available\"\n",
    "\n",
    "# Extract total views\n",
    "total_views_element = soup.find('span', {'class': 'total-views'})\n",
    "if total_views_element:\n",
    "    property_info['total_views'] = total_views_element.text.strip()\n",
    "else:\n",
    "    property_info['total_views'] = \"Total views not available\"\n",
    "\n",
    "# Extract property features (beds, baths, sqft, price per sqft)\n",
    "# Find all features (since there's a divider, we can use this approach)\n",
    "features = soup.find_all('span', {'class': 'property-info-feature-detail'})\n",
    "for feature in features:\n",
    "    feature_value = feature.text.strip()\n",
    "    feature_label = feature.find_previous('span', {'class': 'property-info-feature'}).text if feature.find_previous('span', {'class': 'property-info-feature'}) else \"\"\n",
    "\n",
    "    if 'Beds' in feature_label:\n",
    "        property_info['beds'] = feature_value\n",
    "    elif 'Baths' in feature_label:\n",
    "        property_info['baths'] = feature_value\n",
    "    elif 'Sq Ft' in feature_label:\n",
    "        property_info['sqft'] = feature_value\n",
    "    elif 'Price per Sq Ft' in feature_label:\n",
    "        property_info['price_per_sqft'] = feature_value\n",
    "\n",
    "# Print the extracted information on new lines\n",
    "for key, value in property_info.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the highlights section\n",
    "highlights_section = soup.find('section', {'id': 'highlights-section'})\n",
    "\n",
    "if highlights_section:\n",
    "    highlights_info = {}\n",
    "\n",
    "    # Extract the highlight features\n",
    "    highlights_list = highlights_section.find_all('li', class_='highlight')\n",
    "    for highlight in highlights_list:\n",
    "        feature = highlight.find('span', class_='highlight-value').text.strip()  # Get the feature name\n",
    "        highlights_info[feature] = feature  # The value can be the same as the key or customized if needed\n",
    "\n",
    "    for key, value in highlights_info.items():\n",
    "        # print(f\"{key}: {value}\")\n",
    "        print(f\"{key}\")\n",
    "else:\n",
    "    print(\"Highlight section not found on Homes.com for this property.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the About This Home section\n",
    "about_section = soup.find('section', {'id': 'about'})\n",
    "\n",
    "if about_section:\n",
    "    # Extract the property description\n",
    "    property_description = about_section.find('p', {'id': 'ldp-description-text'}).text.strip() if about_section.find('p', {'id': 'ldp-description-text'}) else \"No description available\"\n",
    "\n",
    "    # Initialize the agent_info dictionary\n",
    "    agent_info = {}\n",
    "\n",
    "    # Extract agent name (if available)\n",
    "    agent_name_element = about_section.find('a', {'class': 'agent-information-fullname'})\n",
    "    if agent_name_element:\n",
    "        agent_name = agent_name_element.text.strip()\n",
    "        agent_info['Agent Name'] = agent_name\n",
    "    else:\n",
    "        agent_info['Agent Name'] = \"No agent information available\"\n",
    "\n",
    "    # Extract agency name (if available)\n",
    "    agency_name_element = about_section.find('span', {'class': 'agent-information-agency-name'})\n",
    "    if agency_name_element:\n",
    "        agency_name = agency_name_element.text.strip()\n",
    "        agent_info['Agency'] = agency_name\n",
    "    else:\n",
    "        agent_info['Agency'] = \"No agency information available\"\n",
    "\n",
    "    # Extract contact info (if available)\n",
    "    contact_info_element = about_section.find('span', {'class': 'agent-information-idx-contact'})\n",
    "    if contact_info_element:\n",
    "        contact_info = contact_info_element.text.strip()\n",
    "        agent_info['Contact Info'] = contact_info\n",
    "    else:\n",
    "        agent_info['Contact Info'] = \"No contact info available\"\n",
    "\n",
    "    # Extract license number (if available)\n",
    "    license_number_element = about_section.find('span', {'class': 'agent-information-license-number'})\n",
    "    if license_number_element:\n",
    "        license_number = license_number_element.text.strip()\n",
    "        agent_info['License Number'] = license_number\n",
    "    else:\n",
    "        agent_info['License Number'] = \"No license number available\"\n",
    "\n",
    "    # Extract agent image URL (if available)\n",
    "    agent_image_element = about_section.find('img', {'class': 'agent-brand-img'})\n",
    "    agent_image_url = agent_image_element['src'] if agent_image_element else \"No agent image available\"\n",
    "\n",
    "    print(\"Property Description:\")\n",
    "    print(property_description)\n",
    "\n",
    "    print(\"\\nAgent Information:\")\n",
    "    for key, value in agent_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print(\"\\nAgent Image URL:\")\n",
    "    print(agent_image_url)\n",
    "    \n",
    "else:\n",
    "    print(\"About this home section not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find the amenities section\n",
    "amenities_section = soup.find('section', {'id': 'amenities-container'})\n",
    "\n",
    "if amenities_section:\n",
    "    amenities_data = {}\n",
    "\n",
    "    # Extract \"Property Details\" (inside the first feature-category)\n",
    "    property_details_section = amenities_section.find_all('div', {'class': 'feature-category feature-0'})[0]\n",
    "    if property_details_section:\n",
    "        # Find each subcategory within the \"Property Details\" section\n",
    "        subcategories = property_details_section.find_all('div', {'class': 'subcategory-container'})\n",
    "        for subcategory in subcategories:\n",
    "            amenity_name = subcategory.find('p', {'class': 'amenity-name'}).text.strip()\n",
    "            amenities = subcategory.find('ul', {'class': 'amenities-list'}).find_all('li', {'class': 'amenities-detail'})\n",
    "            amenity_details = [amenity.text.strip() for amenity in amenities]\n",
    "            amenities_data[amenity_name] = amenity_details\n",
    "\n",
    "    for key, value in amenities_data.items():\n",
    "        print(f\"{key}:\")\n",
    "        for item in value:\n",
    "            print(f\"   {item}\")\n",
    "else:\n",
    "    print(\"Amenities section not found on Homes.com for this property.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Nieghborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find the \"About South Littleton\" section\n",
    "neighborhood_section = soup.find('section', {'id': 'neighborhood-container'})\n",
    "\n",
    "if neighborhood_section:\n",
    "    # Extract the Neighborhood Description\n",
    "    description = neighborhood_section.find('div', {'id': 'neighborhood-description'})\n",
    "    neighborhood_description = description.text.strip() if description else \"No description available.\"\n",
    "\n",
    "    # Extract the Neighborhood KPI\n",
    "    neighborhood_kpi_cards = neighborhood_section.find_all('div', {'class': 'neighborhood-kpi-card'})\n",
    "    kpi_data = {}\n",
    "    for card in neighborhood_kpi_cards:\n",
    "        title = card.find('p', {'class': 'neighborhood-kpi-card-title'}).text.strip()\n",
    "        value = card.find('p', {'class': 'neighborhood-kpi-card-text'}).text.strip()\n",
    "        kpi_data[title] = value\n",
    "    \n",
    "    # Print the Neighborhood KPI\n",
    "    print(\"Neighborhood Key Performance Indicators:\")\n",
    "    for key, value in kpi_data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Extract Neighborhood Image URLs\n",
    "    neighborhood_images = neighborhood_section.find_all('div', {'class': 'neighborhood-image-container'})\n",
    "    image_urls = []\n",
    "    for image_container in neighborhood_images:\n",
    "        # Use Selenium to get the actual image URLs from the 'src' attribute\n",
    "        img_tag = image_container.find('img', {'class': 'neighborhood-image'})\n",
    "        if img_tag:\n",
    "            image_urls.append(img_tag['src'])\n",
    "    \n",
    "    # Print the Neighborhood Image URLs\n",
    "    print(\"\\nNeighborhood Image URLs:\")\n",
    "    for i, url in enumerate(image_urls, start=1):\n",
    "        print(f\"Image {i}: {url}\")\n",
    "\n",
    "else:\n",
    "    print(\"Neighborhood details not found on Homes.com for this property.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the property history table\n",
    "price_history_table = soup.find('table', {'class': 'price-table'})\n",
    "\n",
    "# Check if the property history table exists\n",
    "if price_history_table:\n",
    "    # Initialize an empty list to store the property history data as key:value pairs\n",
    "    property_history_data = []\n",
    "    # Find all rows in the table body\n",
    "    rows = price_history_table.find_all('tr', {'class': 'table-body-row'})\n",
    "\n",
    "    # Iterate over each row and extract the relevant data\n",
    "    for row in rows:\n",
    "        # Extracting each cell's content\n",
    "        date = row.find('th', {'scope': 'row'})\n",
    "        event = row.find('td', {'class': 'price-event'})\n",
    "        price = row.find('td', {'class': 'price-price'})\n",
    "        change = row.find('td', {'class': 'price-change'})\n",
    "        sq_ft_price = row.find('td', {'class': 'price-sq-ft'})\n",
    "        \n",
    "        # Create a dictionary to store the key:value pairs for this row\n",
    "        history_entry = {\n",
    "            \"Date\": date.text.strip() if date else \"N/A\",\n",
    "            \"Event\": event.text.strip() if event else \"N/A\",\n",
    "            \"Price\": price.text.strip() if price else \"N/A\",\n",
    "            \"Change\": change.text.strip() if change else \"N/A\",\n",
    "            \"Sq Ft Price\": sq_ft_price.text.strip() if sq_ft_price else \"N/A\"\n",
    "        }\n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        property_history_data.append(history_entry)\n",
    "\n",
    "    for entry in property_history_data:\n",
    "        for key, value in entry.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print()  \n",
    "\n",
    "else:\n",
    "    print(\"Property history not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Listing Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract agent's name\n",
    "agent_name = soup.find('a', {'class': 'agent-name'})\n",
    "if agent_name:\n",
    "    agent_info = {}\n",
    "    \n",
    "    agent_info[\"Agent Name\"] = agent_name.text.strip() if agent_name else None\n",
    "\n",
    "    # Extract the brokerage information\n",
    "    brokerage_info = soup.find('p', {'class': 'brokerage-info'})\n",
    "    agent_info[\"Brokerage\"] = brokerage_info.text.strip() if brokerage_info else None\n",
    "\n",
    "    # Extract the phone number\n",
    "    phone_number = soup.find('a', {'class': 'agent-phone'})\n",
    "    agent_info[\"Phone Number\"] = phone_number.text.strip() if phone_number else None\n",
    "\n",
    "    # Extract the agent's bio\n",
    "    agent_bio = soup.find('p', {'class': 'agent-bio'})\n",
    "    agent_info[\"Bio\"] = agent_bio.text.strip() if agent_bio else None\n",
    "\n",
    "    # Extract the agent's profile image URL\n",
    "    agent_image = soup.find('img', {'class': 'agent-bio-image'})\n",
    "    agent_info[\"Profile Image URL\"] = agent_image['src'] if agent_image else None\n",
    "\n",
    "    # Extract the agent's profile link\n",
    "    profile_link = soup.find('a', {'class': 'view-agent-profile-btn'})\n",
    "    agent_info[\"Profile Link\"] = profile_link['href'] if profile_link else None\n",
    "\n",
    "    # Output the results as key:value pairs in the desired format\n",
    "    for key, value in agent_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "else:\n",
    "    print(\"Agent information not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchase History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the deed history section\n",
    "deed_history_section = soup.find('section', {'id': 'deed-history-container'})\n",
    "if deed_history_section:\n",
    "    deed_history = {}\n",
    "    \n",
    "    # Find the deed table\n",
    "    deed_table = deed_history_section.find('table', {'class': 'deed-table'})\n",
    "    if deed_table:\n",
    "        # Find all rows in the deed table body\n",
    "        rows = deed_table.find_all('tr', {'class': 'table-body-row deed-table-body-row'})\n",
    "        \n",
    "        for row in rows:\n",
    "            # Extract date\n",
    "            date = row.find('th', {'scope': 'row'})\n",
    "            if date:\n",
    "                deed_history['Date'] = date.text.strip()\n",
    "            \n",
    "            # Extract buyer\n",
    "            buyer = row.find('td', {'class': 'deed-buyer'})\n",
    "            if buyer:\n",
    "                deed_history['Buyer'] = buyer.text.strip()\n",
    "\n",
    "            # Extract sale price\n",
    "            sale_price = row.find('td', {'class': 'deed-sale-price'})\n",
    "            if sale_price:\n",
    "                deed_history['Sale Price'] = sale_price.text.strip()\n",
    "\n",
    "            # Extract title company\n",
    "            title_company = row.find('td', {'class': 'deed-title-company'})\n",
    "            if title_company:\n",
    "                deed_history['Title Company'] = title_company.text.strip()\n",
    "\n",
    "# Print the deed history information\n",
    "if deed_history:\n",
    "    print(\"\\nDeed History:\")\n",
    "    for key, value in deed_history.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"\\nDeed History not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortgage History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all mortgage rows (each <tr> with class \"table-body-row\")\n",
    "mortgage_rows = soup.find_all('tr', class_='table-body-row')\n",
    "\n",
    "# Initialize an empty list to store mortgage data\n",
    "all_mortgage_data = []\n",
    "\n",
    "# Loop through each mortgage row and extract the details\n",
    "for mortgage_row in mortgage_rows:\n",
    "    mortgage_data = {}\n",
    "\n",
    "    # Extract Date (from the button with class 'shorter-date')\n",
    "    date = mortgage_row.find('span', class_='shorter-date')\n",
    "    if date:\n",
    "        mortgage_data['Date'] = date.text.strip()\n",
    "\n",
    "    # Extract Status (from <td> with class 'mortgage-status')\n",
    "    status = mortgage_row.find('td', class_='mortgage-status')\n",
    "    if status:\n",
    "        mortgage_data['Status'] = status.text.strip()\n",
    "\n",
    "    # Extract Borrower(s) (from <td> with class 'mortgage-borrower')\n",
    "    borrower = mortgage_row.find('td', class_='mortgage-borrower')\n",
    "    if borrower:\n",
    "        mortgage_data['Borrowers'] = borrower.text.strip()\n",
    "\n",
    "    # Extract Total Amount (from <td> with class 'mortgage-amount')\n",
    "    amount = mortgage_row.find('td', class_='mortgage-amount')\n",
    "    if amount:\n",
    "        mortgage_data['Total Amount'] = amount.text.strip()\n",
    "\n",
    "    # Extract detailed information from the property-history-drawer\n",
    "    mortgage_detail = mortgage_row.find('div', class_='property-history-drawer')\n",
    "\n",
    "    if mortgage_detail:\n",
    "        # Extract Outstanding Balance\n",
    "        outstanding_balance = mortgage_detail.find('p', string=\"Outstanding Balance\")\n",
    "        if outstanding_balance:\n",
    "            mortgage_data['Outstanding Balance'] = outstanding_balance.find_next('p').text.strip()\n",
    "\n",
    "        # Extract Lender(s)\n",
    "        lenders = mortgage_detail.find('p', string=\"Lender(s)\")\n",
    "        if lenders:\n",
    "            mortgage_data['Lenders'] = lenders.find_next('p').text.strip()\n",
    "\n",
    "        # Extract Loan Type\n",
    "        loan_type = mortgage_detail.find('p', string=\"Loan Type\")\n",
    "        if loan_type:\n",
    "            mortgage_data['Loan Type'] = loan_type.find_next('p').text.strip()\n",
    "\n",
    "        # Extract Loan Term\n",
    "        loan_term = mortgage_detail.find('p', string=\"Loan Term\")\n",
    "        if loan_term:\n",
    "            mortgage_data['Loan Term'] = loan_term.find_next('p').text.strip()\n",
    "\n",
    "        # Extract Interest Rate\n",
    "        interest_rate = mortgage_detail.find('p', string=\"Interest Rate\")\n",
    "        if interest_rate:\n",
    "            mortgage_data['Interest Rate'] = interest_rate.find_next('p').text.strip()\n",
    "\n",
    "        # Extract Borrower(s) (if they are listed in the subtable)\n",
    "        borrowers_in_subtable = mortgage_detail.find('p', string=\"Borrower(s)\")\n",
    "        if borrowers_in_subtable:\n",
    "            mortgage_data['Borrowers in Subtable'] = borrowers_in_subtable.find_next('p').text.strip()\n",
    "\n",
    "    # Append the extracted data for each row\n",
    "    all_mortgage_data.append(mortgage_data)\n",
    "\n",
    "# Output the list of all mortgage data, skipping the first one\n",
    "for mortgage in all_mortgage_data[1:]:\n",
    "    if mortgage:  # Make sure there's data to print\n",
    "        print(\"Mortgage Data:\")\n",
    "        for key, value in mortgage.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the tax history table body\n",
    "tax_table_body = soup.find('tbody', class_='tax-table-body')\n",
    "\n",
    "if tax_table_body :\n",
    "    # Find all the rows in the tax history table\n",
    "    tax_rows = tax_table_body.find_all('tr', class_='table-body-row')\n",
    "\n",
    "    # Initialize a list to store tax data\n",
    "    tax_data = []\n",
    "    # Loop through each row and extract data\n",
    "    for row in tax_rows:\n",
    "        # Initialize a dictionary to store the row's data\n",
    "        tax_info = {}\n",
    "\n",
    "        # Extract Year\n",
    "        year = row.find('th', class_='tax-year')\n",
    "        if year:\n",
    "            tax_info['Year'] = year.text.strip()\n",
    "\n",
    "        # Extract Tax Paid\n",
    "        tax_paid = row.find('td', class_='tax-amount')\n",
    "        if tax_paid:\n",
    "            tax_info['Tax Paid'] = tax_paid.text.strip()\n",
    "\n",
    "        # Extract Tax Assessment\n",
    "        tax_assessment = row.find('td', class_='tax-assessment')\n",
    "        if tax_assessment:\n",
    "            tax_info['Tax Assessment'] = tax_assessment.text.strip()\n",
    "\n",
    "        # Extract Land value\n",
    "        tax_land = row.find('td', class_='tax-land')\n",
    "        if tax_land:\n",
    "            tax_info['Land'] = tax_land.text.strip()\n",
    "\n",
    "        # Extract Improvement value\n",
    "        tax_improvement = row.find('td', class_='tax-improvement')\n",
    "        if tax_improvement:\n",
    "            tax_info['Improvement'] = tax_improvement.text.strip()\n",
    "\n",
    "        # Only add to list if the data is complete (not empty)\n",
    "        if tax_info:\n",
    "            tax_data.append(tax_info)\n",
    "\n",
    "    # Print the extracted tax data\n",
    "    print(\"Tax Data:\")\n",
    "    for tax in tax_data:\n",
    "        for key, value in tax.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Tax history not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ownership_history = soup.find('section', id='ownership-history-container')\n",
    "\n",
    "    if ownership_history:\n",
    "        # Find all the accordion wrappers containing the ownership data\n",
    "        accordion_wrappers = ownership_history.find_all('div', class_='accordion-wrapper')\n",
    "\n",
    "        # Loop through each accordion-wrapper to extract the relevant ownership data\n",
    "        for accordion_wrapper in accordion_wrappers:\n",
    "            # Find the accordion button inside the current accordion-wrapper\n",
    "            accordion_button = accordion_wrapper.find('div', class_='accordion-button')\n",
    "\n",
    "            if accordion_button:\n",
    "                # Extract basic ownership information (Date, Name, Owned For, Owner Type)\n",
    "                date = accordion_button.find_all('span')[0].text.strip() if accordion_button.find_all('span') else \"N/A\"\n",
    "                name = accordion_button.find_all('span')[1].text.strip() if len(accordion_button.find_all('span')) > 1 else \"N/A\"\n",
    "                owned_for = accordion_button.find_all('span')[2].text.strip() if len(accordion_button.find_all('span')) > 2 else \"N/A\"\n",
    "                owner_type = accordion_button.find_all('span')[3].text.strip() if len(accordion_button.find_all('span')) > 3 else \"N/A\"\n",
    "\n",
    "                # Print basic ownership information\n",
    "                print(\"Basic Ownership Information:\")\n",
    "                print(f\"Date: {date}\")\n",
    "                print(f\"Name: {name}\")\n",
    "                print(f\"Owned For: {owned_for}\")\n",
    "                print(f\"Owner Type: {owner_type}\")\n",
    "                print()\n",
    "                \n",
    "\n",
    "                # Extract Purchase Details\n",
    "                purchase_details_section = accordion_wrapper.find('div', id='purchase-details-ownership')\n",
    "                purchase_details = {}\n",
    "\n",
    "                if purchase_details_section:\n",
    "                    # Extract individual purchase details\n",
    "                    listed_on = purchase_details_section.find('div', string='Listed on')\n",
    "                    closed_on = purchase_details_section.find('div', string='Closed on')\n",
    "                    sold_by = purchase_details_section.find('div', string='Sold by')\n",
    "                    bought_by = purchase_details_section.find('div', string='Bought by')\n",
    "                    sellers_agent = purchase_details_section.find('div', string=\"Seller's Agent\")\n",
    "                    buyers_agent = purchase_details_section.find('div', string=\"Buyer's Agent\")\n",
    "                    list_price = purchase_details_section.find('div', string='List Price')\n",
    "                    sold_price = purchase_details_section.find('div', string='Sold Price')\n",
    "                    premium_discount = purchase_details_section.find('div', string='Premium/Discount to List')\n",
    "                    total_days_on_market = purchase_details_section.find('div', string='Total Days on Market')\n",
    "                    views = purchase_details_section.find('div', string='Views')\n",
    "                    current_estimated_value = purchase_details_section.find('div', string='Current Estimated Value')\n",
    "\n",
    "                    purchase_details['Listed on'] = listed_on.find_next('div', class_='ownership-category-value').text.strip() if listed_on else \"N/A\"\n",
    "                    purchase_details['Closed on'] = closed_on.find_next('div', class_='ownership-category-value').text.strip() if closed_on else \"N/A\"\n",
    "                    purchase_details['Sold by'] = sold_by.find_next('div', class_='ownership-category-value').text.strip() if sold_by else \"N/A\"\n",
    "                    purchase_details['Bought by'] = bought_by.find_next('div', class_='ownership-category-value').text.strip() if bought_by else \"N/A\"\n",
    "                    purchase_details['Seller\\'s Agent'] = sellers_agent.find_next('div', class_='ownership-category-value').text.strip() if sellers_agent else \"N/A\"\n",
    "                    purchase_details['Buyer\\'s Agent'] = buyers_agent.find_next('div', class_='ownership-category-value').text.strip() if buyers_agent else \"N/A\"\n",
    "                    purchase_details['List Price'] = list_price.find_next('div', class_='ownership-category-value').text.strip() if list_price else \"N/A\"\n",
    "                    purchase_details['Sold Price'] = sold_price.find_next('div', class_='ownership-category-value').text.strip() if sold_price else \"N/A\"\n",
    "                    purchase_details['Premium/Discount to List'] = premium_discount.find_next('div', class_='ownership-category-value').text.strip() if premium_discount else \"N/A\"\n",
    "                    purchase_details['Total Days on Market'] = total_days_on_market.find_next('div', class_='ownership-category-value').text.strip() if total_days_on_market else \"N/A\"\n",
    "                    purchase_details['Views'] = views.find_next('div', class_='ownership-category-value').text.strip() if views else \"N/A\"\n",
    "                    purchase_details['Current Estimated Value'] = current_estimated_value.find_next('div', class_='ownership-category-value').text.strip() if current_estimated_value else \"N/A\"\n",
    "\n",
    "                    # Print Purchase Details\n",
    "                    print(\"Purchase Details:\")\n",
    "                    for key, value in purchase_details.items():\n",
    "                        # if value != \"N/A\":\n",
    "                        print(f\"{key}: {value}\")\n",
    "                    print(\"\")\n",
    "\n",
    "                # Extract Home Financials\n",
    "                home_financials_section = accordion_wrapper.find('div', id='home-financials-ownership')\n",
    "                home_financials = {}\n",
    "\n",
    "                if home_financials_section:\n",
    "                    original_mortgage = home_financials_section.find('div', string='Original Mortgage')\n",
    "                    interest_rate = home_financials_section.find('div', string='Interest Rate')\n",
    "\n",
    "                    home_financials['Original Mortgage'] = original_mortgage.find_next('div', class_='ownership-category-value').text.strip() if original_mortgage else \"N/A\"\n",
    "                    home_financials['Interest Rate'] = interest_rate.find_next('div', class_='ownership-category-value').text.strip() if interest_rate else \"N/A\"\n",
    "\n",
    "                    # Print Home Financials\n",
    "                    print(\"Home Financials:\")\n",
    "                    for key, value in home_financials.items():\n",
    "                        # if value != \"N/A\":\n",
    "                        print(f\"{key}: {value}\")\n",
    "                    print(\"\")\n",
    "\n",
    "            else:\n",
    "                print(\"No ownership data found in this accordion wrapper.\")\n",
    "    else:\n",
    "        print(\"Ownership history not found on Homes.com for this property.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLS Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MLS Source\n",
    "mls_source = soup.find('span', {'class': 'heavy'})\n",
    "\n",
    "if mls_source:\n",
    "    mls_info = {}\n",
    "    mls_info[\"MLS Source\"] = mls_source.find_next('span').text.strip() if mls_source else None\n",
    "\n",
    "    # Extract MLS Number\n",
    "    mls_number = soup.find('p', {'class': 'mls-number'})\n",
    "    mls_info[\"MLS Number\"] = mls_number.find('span').find_next('span').text.strip() if mls_number else None\n",
    "\n",
    "    # Extract MLS Image URL\n",
    "    mls_image = soup.find('img', {'class': 'mls-image'})\n",
    "    mls_info[\"MLS Image URL\"] = mls_image['src'] if mls_image else None\n",
    "\n",
    "    # Output the results as key:value pairs in the desired format\n",
    "    for key, value in mls_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"MLS information not found on Homes.com for this property.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
