{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/shuchi/.venvs/myenv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://property.spatialest.com/co/elpaso/#/\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.ID, \"primary_search\"))\n",
    ")\n",
    "\n",
    "# Wait for the search box (address input field) to be visible\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'primary_search'))\n",
    ")\n",
    "\n",
    "# Send the address to the search box (e.g., \"1234 Main St\")\n",
    "search_box.send_keys(\"16275 Eaglenest Dr\")\n",
    "\n",
    "# Simulate hitting the Enter key to trigger the search\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait explicitly for the data list section to be visible\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"data-list-section\"))\n",
    ")\n",
    "\n",
    "# Grab the page source after the search results load\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Use BeautifulSoup to parse the page\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "# soup.prettify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owner: MARTIN ROBERT GUY\n",
      "Mailing Address: 16275 EAGLENEST DR COLORADO SPRINGS CO, 80930-9415\n",
      "Location: 16275 EAGLENEST DR\n",
      "Tax Status: Taxable\n",
      "Zoning: RR-5\n",
      "Plat No: -\n",
      "Legal Description: TRACT IN S2 SEC 11-14-64 AS FOLS, COM AT E4 OF SD SEC, TH N 89<51' W ON E-W C/L 2370.07 FT, S 0<31' E 1313.60 FT FOR POB, CONT SLY ON LAST COURSE 660.0 FT, S 89<57' W 640.0 FT, N 56<33' W 712.63 FT, N 0<31' W 581.48 FT, S 74<33' E 1080.0 FT, TH ON A CUR TO L HAVING A RAD OF 720.0 FT + C/A OF 15<30' AN ARC DIST OF 194.78 FT, TH N 89<57' E 0.48 FT TO POB TOG WITH EASEMENT FOR INGRESS + EGRESS AS DES IN BK 2629-779\n"
     ]
    }
   ],
   "source": [
    "# Find the 'data-list-section' that contains the relevant data\n",
    "data_list_section = soup.find('div', class_='data-list-section')\n",
    "\n",
    "# Find all the list items (li) within this section\n",
    "data_rows = data_list_section.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "property_details = {}\n",
    "\n",
    "# Iterate over each data row to extract the title and value\n",
    "for row in data_rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    # If the value is a dropdown (select), extract the selected option\n",
    "    if not value:\n",
    "        value = row.find('select')\n",
    "        if value:\n",
    "            value = value.find('option').text.strip()\n",
    "    else:\n",
    "        value = value.text.strip()\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        property_details[title_text] = value\n",
    "\n",
    "# Print out the extracted data\n",
    "for key, value in property_details.items():\n",
    "    print(f\"{key} {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market & Assessment Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Value:\n",
      "Land: $171,700\n",
      "Improvement: $612,655\n",
      "Total: $784,355\n",
      "\n",
      "Assessed Value:\n",
      "Land: $171,700\n",
      "Improvement: $612,655\n",
      "Total: $784,355\n"
     ]
    }
   ],
   "source": [
    "# Find the \"Market & Assessment Details\" section\n",
    "assessment_section = soup.find('div', class_='assessment')\n",
    "\n",
    "# Find the data list containing market and assessed values\n",
    "data_list = assessment_section.find('ul', class_='data-list')\n",
    "\n",
    "# Extract the rows for the market and assessed values\n",
    "rows = data_list.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "market_value = {}\n",
    "assessed_value = {}\n",
    "\n",
    "for row in rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        value_text = value.text.strip()\n",
    "\n",
    "        # Checking if the title matches categories and storing the respective values\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            market_value[title_text] = value_text\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            assessed_value[title_text] = value_text\n",
    "\n",
    "# Print the results for Market and Assessed Values\n",
    "print(\"Market Value:\")\n",
    "for key, val in market_value.items():\n",
    "    print(f\"{key}: {val}\")\n",
    "\n",
    "print(\"\\nAssessed Value:\")\n",
    "for key, val in assessed_value.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Number: 1\n",
      "Land Use: SINGLE FAMILY RESIDENTIAL\n",
      "Assessment Rate: 6.700\n",
      "Area: 20.09 Acres\n",
      "Market Value: $166,700\n",
      "\n",
      "Sequence Number: 2\n",
      "Land Use: WELL AND SEPTIC CONVERSION VALUE\n",
      "Assessment Rate: 6.700\n",
      "Area: 0 SQFT\n",
      "Market Value: $5,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the table containing the land details\n",
    "table = soup.find('table', class_='table-striped')\n",
    "\n",
    "# Extract the headers (columns) from the table\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "# Extract the rows of the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each row\n",
    "data = []\n",
    "\n",
    "# Loop through each row (skipping the header row)\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if columns:\n",
    "        row_data = {}\n",
    "        for i, col in enumerate(columns):\n",
    "            # Assign the header as the key and the column value as the value\n",
    "            row_data[headers[i]] = col.text.strip()\n",
    "        data.append(row_data)\n",
    "\n",
    "# Now print the scraped land info in the format you requested\n",
    "for land_info in data:\n",
    "    for key, value in land_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BI LEVEL 2 STORY (1) Details:\n",
      "Assessment Rate: 6.700\n",
      "Above Grade Area: 2,765\n",
      "Bldg #: 1\n",
      "First Floor Area: 1,965\n",
      "Style Description: BI LEVEL 2 STORY\n",
      "Above First Floor Area: 800\n",
      "Property Description: SINGLE FAMILY RESIDENTIAL\n",
      "Lower Level Living Area: 0\n",
      "Year Built: 1978\n",
      "Total Basement Area: 876\n",
      "Dwelling Units: 1\n",
      "Finished Basement Area: 876\n",
      "Number of Rooms: 7\n",
      "Garage Description: Attached\n",
      "Number of Bedrooms: 3\n",
      "Garage Area: 744\n",
      "Number of Baths: 1.75\n",
      "Carport Area: -\n",
      "Market Value: $612,655\n",
      "\n",
      "RESIDENTIAL OUTBUILDINGS (2) Details:\n",
      "Assessment Rate: 6.700\n",
      "Sprinkler: N\n",
      "Bldg #: 2\n",
      "Elevator: -\n",
      "Use: RESIDENTIAL OUTBUILDINGS\n",
      "Occup 1: 430\n",
      "Year Built: 2020\n",
      "Occup 2: -\n",
      "Area: 576\n",
      "HVA 1: Electric Baseboard\n",
      "Class: D\n",
      "HVA 2: -\n",
      "Quality: Average\n",
      "Wall Height: 8\n",
      "Stories: -\n",
      "Land Size: -\n",
      "Perimeter: -\n",
      "Neigh #: 97\n",
      "# Units: -\n",
      "Market Value: $0\n"
     ]
    }
   ],
   "source": [
    "sections = soup.find_all('div', class_='panel panel-default')\n",
    "\n",
    "# Loop through each section and extract the details\n",
    "for section in sections:\n",
    "    # Extract title for identification (either BI LEVEL 2 STORY or RESIDENTIAL OUTBUILDINGS)\n",
    "    section_title = section.find('h4', class_='panel-title').get_text(strip=True)\n",
    "\n",
    "    # Extract building details for each section\n",
    "    market_value = section.find('div', class_='building-value').find_all('span')[1].get_text(strip=True)\n",
    "    data_list = section.find('ul', class_='data-list')\n",
    "    building_details = {}\n",
    "\n",
    "    # Loop through each row and extract the title and value for each <p> tag\n",
    "    for item in data_list.find_all('li', class_='data-list-row'):\n",
    "        data_items = item.find_all('p', class_='data-list-item')\n",
    "        for data_item in data_items:\n",
    "            title_span = data_item.find('span', class_='title')\n",
    "            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "            if title_span:\n",
    "                title = title_span.get_text(strip=True)\n",
    "                value = value_span.get_text(strip=True) if value_span else \"-\"\n",
    "                building_details[title] = value\n",
    "    \n",
    "    # Add the market value to the building details dictionary\n",
    "    building_details['Market Value'] = market_value\n",
    "\n",
    "    # Print out the details for each section\n",
    "    print(f\"\\n{section_title} Details:\")\n",
    "    for key, value in building_details.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sale Date: 12/01/2016\n",
      "Sale Price: $177,000\n",
      "Sale Type: Arms-Length Sale\n",
      "Reception: 216139263\n",
      "Schedule No: 4411000017\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: Average\n",
      "Term: Month(s): 360\n",
      "Financing: New 3.25% Fixed\n",
      "Amt. Financed: $182,828\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: WEBB RONALD D\n",
      "Grantee: MARTIN ROBERT GUY\n",
      "\n",
      "Sale Date: 01/03/2001\n",
      "Sale Price: $0\n",
      "Sale Type: -\n",
      "Reception: 216139263\n",
      "Schedule No: 4411000017\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: Average\n",
      "Term: Month(s): 360\n",
      "Financing: New 3.25% Fixed\n",
      "Amt. Financed: $182,828\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: WEBB RONALD D\n",
      "Grantee: MARTIN ROBERT GUY\n",
      "\n",
      "Sale Date: 05/01/1979\n",
      "Sale Price: $0\n",
      "Sale Type: -\n",
      "Reception: -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the sales table\n",
    "sales_history = soup.find('div', id='sales')\n",
    "sales_table = sales_history.find_all('tr')\n",
    "\n",
    "# Initialize a list to store the sales data\n",
    "sales_data = []\n",
    "\n",
    "# Loop through each row in the sales table\n",
    "for row in sales_table:\n",
    "    sale_info = {}\n",
    "    \n",
    "    # Extract the sale date, price, type, and reception from the main row\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 1:\n",
    "        sale_date = columns[1].get_text(strip=True)\n",
    "        sale_price = columns[2].get_text(strip=True)\n",
    "        sale_type = columns[3].get_text(strip=True)\n",
    "        reception = columns[4].get_text(strip=True)\n",
    "        \n",
    "        # Store the extracted information in the dictionary\n",
    "        sale_info['Sale Date'] = sale_date\n",
    "        sale_info['Sale Price'] = sale_price\n",
    "        sale_info['Sale Type'] = sale_type\n",
    "        sale_info['Reception'] = reception\n",
    "        \n",
    "        # Check for additional sale details if available (expand row button +)\n",
    "        expand_row = columns[0].find('button')\n",
    "        if expand_row:\n",
    "            # Simulate a click to reveal additional information\n",
    "            expand_button = driver.find_element(By.XPATH, f\"//button[text()='+']\")\n",
    "            expand_button.click()\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"table-row-subdata-content\"))\n",
    "            )\n",
    "            \n",
    "            # Refresh the page source after expanding\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Re-locate the expanded data in the DOM\n",
    "            expanded_row = soup.find_all('tr', class_='hide table-row-subdata')\n",
    "\n",
    "            # Extract subdata for each expanded row\n",
    "            if expanded_row:\n",
    "                subdata = expanded_row[0].find('ul', class_='data-list')\n",
    "                if subdata:\n",
    "                    for item in subdata.find_all('li', class_='data-list-row'):\n",
    "                        # Extract the title and value from each <p> tag\n",
    "                        data_items = item.find_all('p', class_='data-list-item')\n",
    "                        for data_item in data_items:\n",
    "                            title_span = data_item.find('span', class_='title')\n",
    "                            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "                            if title_span and value_span:\n",
    "                                title = title_span.get_text(strip=True)\n",
    "                                value = value_span.get_text(strip=True)\n",
    "                                sale_info[title] = value\n",
    "                    \n",
    "                    # Now, handle the Grantee field (dropdown)\n",
    "                    grantee_select = subdata.find('select', class_='value')\n",
    "                    if grantee_select:\n",
    "                        # Get the first option in the dropdown, which is visible\n",
    "                        selected_grantee = grantee_select.find('option')\n",
    "                        if selected_grantee:\n",
    "                            sale_info['Grantee'] = selected_grantee.get_text(strip=True)\n",
    "        \n",
    "        # Append the sale data to the list\n",
    "        sales_data.append(sale_info)\n",
    "\n",
    "# Print the sales data in a cleaner format\n",
    "for sale in sales_data:\n",
    "    for key, value in sale.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax Entity and Levy Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tax Information: \n",
      "   Tax Area Code:KB4Levy Year:2024Mill Levy:56.668 \n",
      "\n",
      "Taxing Entity: EL PASO COUNTY\n",
      "Levy: 6.985\n",
      "Contact Name/Organization: FINANCIAL SERVICES\n",
      "Contact Phone: (719)520-6400\n",
      "\n",
      "Taxing Entity: EPC ROAD & BRIDGE (UNSHARED)\n",
      "Levy: 0.330\n",
      "Contact Name/Organization: -\n",
      "Contact Phone: (719)520-6498\n",
      "\n",
      "Taxing Entity: ELLICOTT SCHOOL DISTRICT #22\n",
      "Levy: 29.901\n",
      "Contact Name/Organization: AMANDA KOBILAN\n",
      "Contact Phone: (719)683-2700\n",
      "\n",
      "Taxing Entity: PIKES PEAK LIBRARY DISTRICT\n",
      "Levy: 3.140\n",
      "Contact Name/Organization: RANDALL A GREEN\n",
      "Contact Phone: (719)531-6333\n",
      "\n",
      "Taxing Entity: ELLICOTT FIRE PROTECTION DISTRICT\n",
      "Levy: 15.230\n",
      "Contact Name/Organization: MICHAEL HENLEY\n",
      "Contact Phone: (719)683-7211\n",
      "\n",
      "Taxing Entity: UPPER BLK SQUIRREL CRK GROUND WATER DISTRICT\n",
      "Levy: 1.082\n",
      "Contact Name/Organization: TRACY DORAN\n",
      "Contact Phone: (719)510-0780\n",
      "\n",
      "Taxing Entity: ELLICOTT METRO DISTRICT\n",
      "Levy: 0.000\n",
      "Contact Name/Organization: GEORGIA MCREA\n",
      "Contact Phone: (719)683-4190\n",
      "\n",
      "Taxing Entity: EL PASO COUNTY CONSERVATION DISTRICT\n",
      "Levy: 0.000\n",
      "Contact Name/Organization: MARIAH HUDSON\n",
      "Contact Phone: (719)600-4706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the Tax Entity and Levy Information section\n",
    "tax_levy_section = soup.find('div', {'id': 'taxandlevytab'})\n",
    "\n",
    "# Extract the tax area code, levy year, and mill levy from the paragraph\n",
    "tax_info = tax_levy_section.find_all('p')[1].get_text(strip=True)\n",
    "print(f\"Tax Information: \\n   {tax_info} \\n\")\n",
    "\n",
    "# Extract all rows from the Taxing Entity table\n",
    "table_rows = tax_levy_section.find_all('tr')\n",
    "\n",
    "# Initialize a list to store sales data\n",
    "sales_data = []\n",
    "\n",
    "# Extract and store the table data for each row\n",
    "for row in table_rows:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) > 0:  # Skip empty rows\n",
    "        sale = {\n",
    "            \"Taxing Entity\": cols[0].get_text(strip=True),\n",
    "            \"Levy\": cols[1].get_text(strip=True),\n",
    "            \"Contact Name/Organization\": cols[2].get_text(strip=True),\n",
    "            \"Contact Phone\": cols[3].get_text(strip=True)\n",
    "        }\n",
    "        sales_data.append(sale)\n",
    "\n",
    "# Print the sales data in the requested format\n",
    "for sale in sales_data:\n",
    "    for key, value in sale.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map URL: https://image-cdn.spatialest.com/file/view/co-elpaso-images/ASRMap/44110.tif?v=210622\n"
     ]
    }
   ],
   "source": [
    "# Find the MapSheet div\n",
    "map_sheet_div = soup.find('div', {'id': 'MapSheet'})\n",
    "\n",
    "# Find the <a> tag within the MapSheet div\n",
    "map_link = map_sheet_div.find('a')\n",
    "\n",
    "# Extract the href (link) and text from the <a> tag\n",
    "if map_link:\n",
    "    map_url = map_link.get('href')\n",
    "    map_text = map_link.get_text(strip=True)\n",
    "    print(f\"Map URL: {map_url}\")\n",
    "    # print(f\"Map Text: {map_text}\")\n",
    "else:\n",
    "    print(\"Map link not found.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
