{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\walker narog\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get (\"https://maps.boco.solutions/legacyps/\")\n",
    "\n",
    "# Wait to allow the page to load\n",
    "time.sleep(2)\n",
    "# print(driver.page_source) \n",
    "\n",
    "# enter desired address here\n",
    "search_term = \"1831 Lefthand Circle Longmont\"\n",
    "\n",
    "search_input = driver.find_element(By.ID, \"searchField\")\n",
    "search_input.clear()\n",
    "search_input.send_keys(search_term)\n",
    "time.sleep(10)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total:': '3100000', 'Structure:': '2440000', 'Land:': '660000'}\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "\n",
    "property_details = {}\n",
    "\n",
    "\n",
    "account_num_elem = soup.find('span', class_='labelme', string=\"Account Number:\")\n",
    "if account_num_elem:\n",
    "        account_number = account_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details['Account Number'] = account_number\n",
    "else:\n",
    "        property_details['Account Number'] = \"Not Found\"\n",
    "\n",
    "owner_elem = soup.find('span', class_='labelme', string=\"Owner:\")\n",
    "if owner_elem:\n",
    "        owner = owner_elem.find_next_sibling('span').text.strip()\n",
    "        property_details['Owner'] = owner\n",
    "else:\n",
    "        property_details['Owner'] = \"Not Found\"\n",
    "\n",
    "mailing_addr_elem = soup.find('span', class_='labelme', string=\"Mailing Address:\")\n",
    "if mailing_addr_elem:\n",
    "        mailing_addr = mailing_addr_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Owner's Mailing Address\"] = mailing_addr\n",
    "else:\n",
    "        property_details[\"Owner's Mailing Address\"] = \"Not Found\"\n",
    "\n",
    "property_addr_elem = soup.find('span', class_='labelme', string=\"Property Address:\")\n",
    "if property_addr_elem:\n",
    "        property_addr = property_addr_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Property Address\"] = property_addr\n",
    "else:\n",
    "        property_details[\"Property Address\"] = \"Not Found\"\n",
    "        \n",
    "city_elem = soup.find('span', class_='labelme', string=\"City:\")\n",
    "if city_elem:\n",
    "        city = city_elem.find_next_sibling('span').text.strip()\n",
    "        state = city_elem.find_next_sibling('span').find_next_sibling('span').find_next_sibling('span').text.strip()\n",
    "        property_details[\"City\"] = city\n",
    "        property_details[\"State\"] = state\n",
    "else:\n",
    "        property_details[\"City\"] = \"Not Found\"\n",
    "        property_details[\"State\"] = \"Not Found\"\n",
    "        \n",
    "zip_elem = soup.find('span', class_='labelme', string=\"Zip:\")\n",
    "if zip_elem:\n",
    "        zip_code = zip_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Zip Code\"] = zip_code\n",
    "else:\n",
    "        property_details[\"Zip Code\"] = \"Not Found\"\n",
    "\n",
    "parcel_num_elem = soup.find('span', class_='labelme', string=\"Parcel Number:\")\n",
    "if parcel_num_elem:\n",
    "        parcel_number = parcel_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Parcel Number\"] = parcel_number\n",
    "else:\n",
    "        property_details[\"Parcel Number\"] = \"Not Found\"\n",
    "\n",
    "subdivison_elem = soup.find('span', class_='labelme', string=\"Subdivision:\")\n",
    "if subdivison_elem:\n",
    "        subdivison = subdivison_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Subdivision\"] = subdivison\n",
    "else:\n",
    "        property_details[\"Subdivision\"] = \"Not Found\"\n",
    "        \n",
    "market_area_elem = soup.find('span', class_='labelme', string=\"Market Area:\")\n",
    "if market_area_elem:\n",
    "        market_area = market_area_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Market Area\"] = market_area\n",
    "else:\n",
    "        property_details[\"Market Area\"] = \"Not Found\"\n",
    "        \n",
    "sqft_elem = soup.find('span', class_='labelme', string=\"Square Feet:\")\n",
    "if sqft_elem:\n",
    "        sqft = sqft_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Square Feet\"] = sqft\n",
    "else:\n",
    "        property_details[\"Square Feet\"] = \"Not Found\"\n",
    "        \n",
    "acres_elem = soup.find('span', class_='labelme', string=\"Acres:\")\n",
    "if acres_elem:\n",
    "        acres = acres_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Acres\"] = acres\n",
    "else:\n",
    "        property_details[\"Acres\"] = \"Not Found\"\n",
    "        \n",
    "# Tax records could easily be found from this method in 'Assessments' tab\n",
    "property_values = {}\n",
    "\n",
    "rows1 = soup.find('tbody').find_all('tr')\n",
    "\n",
    "# Loop through the rows and extract values for Total, Structure, and Land\n",
    "for row_i in rows1:\n",
    "    label = row_i.find('span', class_='embolden').text.strip()\n",
    "    \n",
    "    # Find the \"Actual\" value in the second <td>\n",
    "    actual_value = row_i.find_all('td')[1].find('span', class_='ng-binding').text.strip()\n",
    "    \n",
    "    if label in [\"Total:\", \"Structure:\", \"Land:\"]:\n",
    "        property_values[label] = actual_value\n",
    "  \n",
    "print(property_values)      \n",
    "property_details[\"Total Value\"] = property_values['Total:']\n",
    "property_details[\"Structure Value\"] = property_values['Structure:']\n",
    "property_details[\"Land Value\"] = property_values['Land:']\n",
    "\n",
    "\n",
    "#Estimate of taxes\n",
    "for row in soup.find_all('tr'):\n",
    "    if row.find('td') and \"Estimate of taxes\" in row.find('td').text:\n",
    "        tax_row = row\n",
    "        break\n",
    "# Extract the tax value from the second <td>\n",
    "if tax_row:\n",
    "    tax_estimate = tax_row.find_all('td')[1].text.strip()\n",
    "else:\n",
    "    tax_estimate = \"Estimate of taxes not found\"\n",
    "\n",
    "property_details[\"Property tax estimate\"] = tax_estimate\n",
    "\n",
    "\n",
    "\n",
    "class_elem = soup.find('span', class_='labelme', string=\"Class:\")\n",
    "if class_elem:\n",
    "        class_data = class_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Class\"] = class_data\n",
    "else:\n",
    "        property_details[\"Class\"] = \"Not Found\"\n",
    "        \n",
    "build_year_elem = soup.find('span', class_='labelme', string=\"Built:\")\n",
    "if build_year_elem:\n",
    "        build_year = build_year_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Built\"] = build_year\n",
    "else:\n",
    "        property_details[\"Built\"] = \"Not Found\"\n",
    "\n",
    "tot_room_num_elem = soup.find('span', class_='labelme', string=\"Total:\")\n",
    "if tot_room_num_elem:\n",
    "        tot_room_num = tot_room_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Number of rooms\"] = tot_room_num\n",
    "else:\n",
    "        property_details[\"Number of rooms\"] = \"Not Found\"\n",
    "        \n",
    "bedroom_num_elem = soup.find('span', class_='labelme', string=\"Bedrooms:\")\n",
    "if bedroom_num_elem:\n",
    "        bedroom_num = bedroom_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Bedrooms\"] = bedroom_num\n",
    "else:\n",
    "        property_details[\"Bedrooms\"] = \"Not Found\"\n",
    "\n",
    "full_bath_num_elem = soup.find('span', class_='labelme', string=\"Full Bath:\")\n",
    "if full_bath_num_elem:\n",
    "        full_bath_num = full_bath_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Full Bath\"] = full_bath_num\n",
    "else:\n",
    "        property_details[\"Full Bath\"] = \"Not Found\"\n",
    "\n",
    "three_qtr_bath_num_elem = soup.find('span', class_='labelme', string=\"3/4 Bath:\")\n",
    "if three_qtr_bath_num_elem:\n",
    "        three_qtr_bath_num = three_qtr_bath_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"3/4 Bath\"] = three_qtr_bath_num\n",
    "else:\n",
    "        property_details[\"3/4 Bath\"] = \"Not Found\"\n",
    "        \n",
    "half_bath_num_elem = soup.find('span', class_='labelme', string=\"Half Bath:\")\n",
    "if half_bath_num_elem:\n",
    "        half_bath_num = half_bath_num_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Half Bath\"] = half_bath_num\n",
    "else:\n",
    "        property_details[\"Half Bath\"] = \"Not Found\"\n",
    "        \n",
    "# can grab sqft of each floor of the home\n",
    "\n",
    "\n",
    "#can find previous deed info on 'Deeds and Sales' tab\n",
    "#then use the following link to search up the deed by 'Reception Number'\n",
    "#https://boulder.co.publicsearch.us/search/advanced\n",
    "\n",
    "\n",
    "rows2 = soup.find_all('tr', attrs={\"ng-repeat\": \"deed in deeds\"})\n",
    "deed_numbers = []\n",
    "for row_j in rows2:\n",
    "    deed_number = row_j.find('span', class_='ng-binding').text.strip()\n",
    "    deed_numbers.append(deed_number)\n",
    "    \n",
    "property_details[\"Deed Numbers\"] = deed_numbers\n",
    "\n",
    "\n",
    "zoning_elem = soup.find('span', class_='labelme', string=\"Zoning:\")\n",
    "if zoning_elem:\n",
    "        zoning = zoning_elem.find_next_sibling('span').text.strip()\n",
    "        property_details[\"Zoning\"] = zoning\n",
    "else:\n",
    "        property_details[\"Zoning\"] = \"Not Found\"\n",
    "        \n",
    "# survey_num_elem = soup.find('span', class_='labelme', string=\"Survey Number:\")\n",
    "# if survey_num_elem:\n",
    "#         survey_num_select = survey_num_elem.find_next('select')\n",
    "#         survey_num_option = survey_num_select.find('option', attrs={'selected': 'selected'})\n",
    "#         if survey_num_option:\n",
    "#                 survey_num = survey_num_option.text.strip()\n",
    "#                 property_details[\"Survey Number\"] = survey_num\n",
    "#         else:\n",
    "#                 property_details[\"Survey Number\"] = \"No selected option found\"\n",
    "# else:\n",
    "#         property_details[\"Survey Number\"] = \"Not Found\"\n",
    "\n",
    "# surveyor_elem = soup.find('span', class_='labelme', string=\"Surveyor:\")\n",
    "# if surveyor_elem:\n",
    "#         surveyor = surveyor_elem.find_next_sibling('span').text.strip()\n",
    "#         property_details[\"Surveyor\"] = surveyor\n",
    "# else:\n",
    "#         property_details[\"Surveyor\"] = \"Not Found\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Number: R0082374\n",
      "Owner: CB 1831 LEFTHAND LLC\n",
      "Owner's Mailing Address: 6525 GUNPARK DR 370-249\n",
      "Property Address: 1831     LEFTHAND CIR\n",
      "City: BOULDER\n",
      "State: CO\n",
      "Zip Code: 80301\n",
      "Parcel Number: 131516215001\n",
      "Subdivision: LONGS PEAK INDUST PARK RPLT E - LG\n",
      "Market Area: 620\n",
      "Square Feet: 94,339\n",
      "Acres: 2.17\n",
      "Total Value: 3100000\n",
      "Structure Value: 2440000\n",
      "Land Value: 660000\n",
      "Property tax estimate: $82,732.00\n",
      "Class: MANUFACTURING/PROCESSING IMPROVEMENTS\n",
      "Built: 1984\n",
      "Number of rooms: 0\n",
      "Bedrooms: 0\n",
      "Full Bath: 0\n",
      "3/4 Bath: 0\n",
      "Half Bath: 0\n",
      "Deed Numbers: ['03933800', '3723141', '3594109', '3259039', '3259040', '2682119', '2631066', '2566552', '1378499', '573116', '535391']\n",
      "Zoning: Not County Zoned\n"
     ]
    }
   ],
   "source": [
    "for key, value in property_details.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
