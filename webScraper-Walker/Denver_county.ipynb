{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2024.12.14)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\walker narog\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\walker narog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.denvergov.org/Property/\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_term = \"3932 S Wisteria Ct\"\n",
    "\n",
    "search_input = driver.find_element(By.ID, \"search\")\n",
    "search_input.send_keys(search_term)\n",
    "\n",
    "time.sleep(1)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the table to be visible\n",
    "results_table = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, \"results_table\"))\n",
    ")\n",
    "\n",
    "# Wait for the first link to be clickable\n",
    "search_result_link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CLASS_NAME, \"search-result-link\"))\n",
    ")\n",
    "search_result_link = driver.find_element(By.CLASS_NAME, \"search-result-link\")\n",
    "# results_table = driver.find_element(By.ID, \"results_table\")\n",
    "if search_result_link :\n",
    "    # search_result_link = results_table.find_element(By.CLASS_NAME, \"search-result-link\")\n",
    "    search_result_link.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "else:\n",
    "    print(\"No results found\")\n",
    "    \n",
    "html = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "property_details = {}\n",
    "\n",
    "\n",
    "\n",
    "# info_bar_table = soup.find(\"table\", id=\"property-info-bar\")\n",
    "\n",
    "# if info_bar_table:\n",
    "    \n",
    "#     info_bar_headers = info_bar_table.find(\"thead\").find_all(\"th\")\n",
    "    \n",
    "#     headers = {}\n",
    "    \n",
    "#     for header in info_bar_headers:\n",
    "#         header.text.strip()\n",
    "        \n",
    "#     row_data = []\n",
    "#     for row in info_bar_table.find(\"tbody\").find_all(\"tr\"):\n",
    "#         cells = row.find_all(\"td\")\n",
    "#         for cell in cells:\n",
    "#             row_data.append(cell.text.strip())\n",
    "            \n",
    "#             if len(row_data) == len(headers):\n",
    "#                 for key, value in zip(headers, row_data):\n",
    "#                     property_details[key] = value\n",
    "#             else:\n",
    "#                 print(\"lists not same length\")\n",
    "#                 print(row_data)\n",
    "#                 print(headers)\n",
    "# else:\n",
    "#     print(\"No info bar found\")\n",
    "\n",
    "property_table = soup1.find(\"table\", class_=\"table-striped\")\n",
    "property_rows = property_table.find_all(\"tr\")\n",
    " \n",
    "for p_row in property_rows:\n",
    "    cells = p_row.find_all(\"td\")  \n",
    "    for i in range(0, len(cells), 2):  \n",
    "        key_raw = cells[i].text.strip()\n",
    "        pkey = key_raw.replace(\":\", \"\") \n",
    "        \n",
    "        if i + 1 < len(cells):\n",
    "            # value = cells[i + 1].get_text(strip=True)\n",
    "            value = cells[i + 1].text.strip()\n",
    "        else:\n",
    "            value = \"Not Found\"\n",
    "        \n",
    "        \n",
    "        property_details[pkey] = value\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_link = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"li#property_map_link > a\"))\n",
    "    )\n",
    "\n",
    "href_link = map_link.get_attribute(\"href\")\n",
    "\n",
    "\n",
    "if href_link:\n",
    "    driver.get(href_link)\n",
    "    \n",
    "    # WebDriverWait(driver, 10).until(\n",
    "    #         EC.presence_of_element_located((By.ID, \"property_map\")) \n",
    "    #     )\n",
    "\n",
    "else:\n",
    "    print(\"No map link found\")\n",
    "\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"summary_map_div\")) \n",
    "        )\n",
    "time.sleep(2)\n",
    "html = driver.page_source\n",
    "\n",
    "soup2 = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_info_section = soup2.find(\"div\", class_=\"contentPanel contentContainer\")\n",
    "\n",
    "if map_info_section:\n",
    "    for item in map_info_section.find_all(\"div\", class_=\"item\"):\n",
    "        label = item.find(\"div\", class_=\"label\").text.strip()\n",
    "\n",
    "        value = item.find(\"div\", class_=\"value\")\n",
    "    \n",
    "        if value:\n",
    "            value_text = value.text.strip()\n",
    "        else:\n",
    "            value_text = \"No value found\"\n",
    "\n",
    "        property_details[label] = value_text\n",
    "else:\n",
    "    print(\"No map info section found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assessment_link = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"li#Assessment > a\"))\n",
    "    )\n",
    "\n",
    "href_link = assessment_link.get_attribute(\"href\")\n",
    "\n",
    "\n",
    "if href_link:\n",
    "    driver.get(href_link)\n",
    "else:\n",
    "    print(\"No map link found\")\n",
    "\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"assessment_data\")) \n",
    "        )\n",
    "time.sleep(2)\n",
    "html = driver.page_source\n",
    "\n",
    "soup3 = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: Current Year\n",
      "Type: Land\n",
      "Actual: $224,700\n",
      "Assessed: $11,370\n",
      "Exempt: $0\n",
      "--------------------\n",
      "Year: Current Year\n",
      "Type: Improvements\n",
      "Actual: $589,700\n",
      "Assessed: $39,510\n",
      "Exempt: \n",
      "--------------------\n",
      "Year: Current Year\n",
      "Type: Total\n",
      "Actual: $814,400\n",
      "Assessed: $50,880\n",
      "Exempt: \n",
      "--------------------\n",
      "Year: Prior Year\n",
      "Type: Land\n",
      "Actual: $224,700\n",
      "Assessed: $11,370\n",
      "Exempt: $0\n",
      "--------------------\n",
      "Year: Prior Year\n",
      "Type: Improvements\n",
      "Actual: $589,700\n",
      "Assessed: $39,510\n",
      "Exempt: \n",
      "--------------------\n",
      "Year: Prior Year\n",
      "Type: Total\n",
      "Actual: $814,400\n",
      "Assessed: $50,880\n",
      "Exempt: \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "assessment_details = []\n",
    "\n",
    "panels = soup3.find_all(\"div\", class_=\"panel panel-primary\")\n",
    "\n",
    "for panel in panels:\n",
    "    year = panel.find(\"h4\", class_=\"panel-title\").text.strip()\n",
    "    table = panel.find(\"table\", class_=\"table table-striped\")\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "    \n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        property_type = cells[0].text.strip()\n",
    "        actual = cells[1].text.strip()\n",
    "        assessed = cells[2].text.strip()\n",
    "        if len(cells) > 3:\n",
    "            exempt = cells[3].text.strip()\n",
    "        else:\n",
    "            exempt = \"Not Found\"\n",
    "\n",
    "        assessment_details.append({\n",
    "            \"Year\": year,\n",
    "            \"Type\": property_type,\n",
    "            \"Actual\": actual,\n",
    "            \"Assessed\": assessed,\n",
    "            \"Exempt\": exempt\n",
    "        })\n",
    "\n",
    "# print(assessment_details)\n",
    "for detail in assessment_details:\n",
    "    for key, value in detail.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"-\" * 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_title_link = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"li#Chain_of_Title > a\"))\n",
    "    )\n",
    "\n",
    "href_link = chain_of_title_link.get_attribute(\"href\")\n",
    "\n",
    "\n",
    "if href_link:\n",
    "    driver.get(href_link)\n",
    "else:\n",
    "    print(\"No map link found\")\n",
    "\n",
    "\n",
    "# WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.ID, \"assessment_data\")) \n",
    "#         )\n",
    "time.sleep(2)\n",
    "html = driver.page_source\n",
    "\n",
    "soup4 = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reception Number: 2024019567\n",
      "Reception Date: 3/8/2024\n",
      "Instrument: WD\n",
      "Sale Date: 3/4/2024\n",
      "Sale Price: $779,000\n",
      "Grantor: CARR,JOSHUA DANIEL\n",
      "Grantee: JENSEN,AMANDA\n",
      "--------------------\n",
      "Reception Number: 2012067259\n",
      "Reception Date: 5/23/2012\n",
      "Instrument: PR\n",
      "Sale Date: 5/21/2012\n",
      "Sale Price: $299,000\n",
      "Grantor: SWIEKATUN,JOHN\n",
      "Grantee: CARR,JOSHUA DANIEL\n",
      "--------------------\n",
      "Reception Number: 2004235773\n",
      "Reception Date: 11/15/2004\n",
      "Instrument: DC\n",
      "Sale Date: 10/2/2004\n",
      "Sale Price: $0\n",
      "Grantor: SWIEKATUN,JOHN  & ELAINE\n",
      "Grantee: SWIEKATUN,JOHN\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "chain_of_title_records = []\n",
    "\n",
    "table = soup4.find(\"table\", class_=\"table table-striped sortable tablesorter tablesorter-default\")\n",
    "rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    if len(cells) > 0:\n",
    "        reception_number = cells[0].text.strip()\n",
    "        reception_date = cells[1].text.strip()\n",
    "        instrument = cells[2].text.strip()\n",
    "        sale_date = cells[3].text.strip()\n",
    "        sale_price = cells[4].text.strip()\n",
    "        grantor = cells[5].text.strip()\n",
    "        grantee = cells[6].text.strip()\n",
    "        \n",
    "        chain_of_title_records.append({\n",
    "            \"Reception Number\": reception_number,\n",
    "            \"Reception Date\": reception_date,\n",
    "            \"Instrument\": instrument,\n",
    "            \"Sale Date\": sale_date,\n",
    "            \"Sale Price\": sale_price,\n",
    "            \"Grantor\": grantor,\n",
    "            \"Grantee\": grantee\n",
    "        })\n",
    "        \n",
    "for record in chain_of_title_records:\n",
    "    for key, value in record.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style: 04: TRI-LEVEL W/B\n",
      "Building Sqr. Foot: 2764\n",
      "Bedrooms: 5\n",
      "Baths Full/Half: 3/0\n",
      "Effective Year Built: 1971\n",
      "Basement/Finish: 853/423\n",
      "Lot Size: 14,600\n",
      "Zoned As: S-SU-F\n",
      "Mill Levy: 79..202\n",
      "Document Type: WD\n",
      "Zoning: Zone District:     S-SU-F       Code Version:       Zoning Map\n",
      "Neighborhood: Hampden South\n",
      "Subdivision: HUTCHINSON HILLS FILING NO. 7 WILLOW POINT\n",
      "Historic Landmark District: No\n",
      "Individual Historic Landmark: No\n",
      "Enterprise Zone: Not in enterprise zone.\n",
      "Floodplain Designation: No value found\n",
      "Downloadable Maps: Parcel Map Quarter Section Map #SE_143 Assessment Parcel Map Index  Quarter Section Map Index\n"
     ]
    }
   ],
   "source": [
    "for key, value in property_details.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
