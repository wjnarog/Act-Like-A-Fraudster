{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c894032d-ae3a-49fb-87e6-22cad7890e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\zach0\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zach0\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b47234-44b4-4bf7-9128-9551b5b851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://apps.douglas.co.us/assessor/web#/\")\n",
    "data_set = {}\n",
    "\n",
    "# Wait for the search box to be visible and locate it\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'app-input-debounce input[type=\"text\"]'))\n",
    ")\n",
    "\n",
    "# Send search query\n",
    "search_box.send_keys(\"2719 Castle Glen Dr\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load (you may need to adjust this depending on the page)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Wait until the table rows are loaded (anchor tags with 'table-row' class)\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.table-row'))\n",
    ")\n",
    "\n",
    "# Locate the first row (anchor tag with class 'table-row') and click it\n",
    "first_row = driver.find_element(By.CSS_SELECTOR, 'a.table-row')\n",
    "first_row.click()\n",
    "\n",
    "# Get page source to parse the HTML after clicking the first row\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup to parse the HTML for further scraping\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79dc6db9-8010-4d52-a07c-a1a258554f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the pop-up dialog to appear and then click the \"Close\" button\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Wait for the \"Close\" button to be clickable\n",
    "close_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button/span[text()='Close']\")))\n",
    "\n",
    "# Click the \"Close\" button to dismiss the pop-up\n",
    "close_button.click()\n",
    "\n",
    "# Wait for the account summary section to be loaded\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165077ef-5cc6-43e3-92ae-8182479fea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Summary:\n",
      "Account #:: R0396965\n",
      "State Parcel #:: 2351-163-01-115\n",
      "Account Type:: Residential\n",
      "Tax District:: 3473\n",
      "Neighborhood-Ext:: 410-I\n",
      "Building Count:: 1\n",
      "Building Permit Authority:: Douglas County (websiteÂ )\n",
      "Phone:: 303-660-7497\n",
      "Name:: CASTLE PINES\n",
      "Reception No:: 9607889\n",
      "\n",
      "Location Description: LOT 19A CASTLE PINES # 1A 16TH AMENDMENT    0.23 AM/L\n",
      "\n",
      "Owner Info:\n",
      "Owner Name: DENNIS R HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST & JENNIE M HENDRIX 2020 COLORADO PERSONAL RESIDENCE TRUST\n",
      "Owner Address: 2719 CASTLE GLEN DRCASTLE ROCK, CO 80108\n",
      "\n",
      "Public Land Survey System (PLSS) Location: \n",
      "Quarter: SW; \n",
      "Section: 16; \n",
      "Township: 7; \n",
      "Range: 67\n",
      "\n",
      "Section PDF Map Link: /realware/SectionMaps/TWP2351/DC_2351_16.pdf\n"
     ]
    }
   ],
   "source": [
    "# Extract Toggle Button and Links before Account Summary\n",
    "html_content = driver.page_source\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize a dictionary to store toggle button and links\n",
    "key_value_pairs = {}\n",
    "\n",
    "# Extract the toggle button text (key) and status (value)\n",
    "toggle_button = soup.find('span', class_='ui-button-text')\n",
    "if toggle_button:\n",
    "    key_value_pairs[\"Toggle Button\"] = toggle_button.text.strip()\n",
    "\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "links = soup.find_all('a', href=True)\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    key_value_pairs[link_text] = f'<a href=\"{link_url}\">{link_text}</a>'\n",
    "\n",
    "# Now proceed with the Account Summary logic\n",
    "# Target the dropdown for Account Summary by using its ID\n",
    "dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@id='SummaryAccountInfo']//span[@class='bar faux-button']\")))\n",
    "\n",
    "# Click the dropdown to expand it\n",
    "dropdown_button.click()\n",
    "\n",
    "# Wait for the Account Summary content to load\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@id='SummaryAccountInfo']//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content again after the dropdown is expanded\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the dropdown content specifically under the 'SummaryAccountInfo' ID\n",
    "dropdown_content = soup.find('div', id='SummaryAccountInfo').find('div', class_='dropdown-content')\n",
    "\n",
    "# Extract the key-value pairs from Account Summary\n",
    "account_summary_pairs = {}\n",
    "\n",
    "# Find all the rows with the class 'skinny-row' which contain the label and value pairs\n",
    "rows = dropdown_content.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in rows:\n",
    "    # Extract the label (key) and value (value)\n",
    "    label = row.find('div', class_='col-xs-4').text.strip() if row.find('div', class_='col-xs-4') else None\n",
    "    value = row.find('div', class_='col-xs-8').text.strip() if row.find('div', class_='col-xs-8') else None\n",
    "    \n",
    "    # Add to dictionary if both label and value exist\n",
    "    if label and value:\n",
    "        account_summary_pairs[label] = value\n",
    "\n",
    "# Print the Account Summary key-value pairs\n",
    "print(f\"Account Summary:\")\n",
    "for key, value in account_summary_pairs.items():\n",
    "    # Skip the \"Update Mailing Address\" entry\n",
    "    if key != 'Update Mailing Address':\n",
    "        print(f\"{key}: {value}\")\n",
    "        data_set[key] = value\n",
    "\n",
    "# Extract additional data (Location Description, Owner Info, PLSS Location)\n",
    "location_description = soup.find('div', string='Location Description').find_next('div').text.strip()\n",
    "\n",
    "# For Owner Info, we need to extract and clean it\n",
    "owner_info_div = soup.find('div', string='Owner Info').find_next('div')\n",
    "\n",
    "# Extract owner name and address\n",
    "owner_info_raw = owner_info_div.text.strip()\n",
    "\n",
    "# Split owner info into lines\n",
    "owner_info_parts = owner_info_raw.split(\"\\n\")\n",
    "\n",
    "# Clean up and extract the name and address properly\n",
    "owner_name = owner_info_parts[0].strip() \n",
    "owner_address = \" \".join(owner_info_parts[1:]).strip()  \n",
    "\n",
    "# If \"Update Mailing Address\" appears in the address, remove it\n",
    "if \"Update Mailing Address\" in owner_address:\n",
    "    owner_address = owner_address.split(\"Update Mailing Address\")[0].strip()\n",
    "\n",
    "# Extract PLSS Location\n",
    "plss_location = soup.find('div', string='Public Land Survey System (PLSS) Location').find_next('div').text.strip()\n",
    "\n",
    "# Clean the PLSS Location\n",
    "plss_location_cleaned = ' '.join(plss_location.split())\n",
    "\n",
    "# Optionally, reformat for better readability (if you want to format it neatly)\n",
    "plss_location_cleaned = plss_location_cleaned.replace(\"Quarter:\", \"\\nQuarter:\").replace(\"Section:\", \"\\nSection:\").replace(\"Township:\", \"\\nTownship:\").replace(\"Range:\", \"\\nRange:\")\n",
    "\n",
    "# Extract the Section PDF Map link (if it exists)\n",
    "section_pdf_map = None\n",
    "\n",
    "# Find all the div elements with class 'skinny-row'\n",
    "pdf_map_rows = soup.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in pdf_map_rows:\n",
    "    # Look for an anchor tag within the row\n",
    "    link = row.find('a', href=True)\n",
    "    if link and \"SectionMap\" in link['href']:  # Check if the href contains \"SectionMap\"\n",
    "        section_pdf_map = link['href']\n",
    "        break \n",
    "\n",
    "# Print other extracted information\n",
    "print(f\"\\nLocation Description: {location_description}\")\n",
    "data_set[\"Location Description\"] = location_description\n",
    "print(f\"\\nOwner Info:\")\n",
    "print(f\"Owner Name: {owner_name}\")\n",
    "data_set[\"Owner Name\"] = owner_name\n",
    "print(f\"Owner Address: {owner_address}\")\n",
    "data_set[\"Owner Address\"] = owner_address\n",
    "print(f\"\\nPublic Land Survey System (PLSS) Location: {plss_location_cleaned}\")\n",
    "data_set[\"PLSS Location\"] = {plss_location_cleaned}\n",
    "print(f\"\\nSection PDF Map Link: {section_pdf_map}\")\n",
    "data_set[\"PDF Map Link\"] = {section_pdf_map}\n",
    "\n",
    "print(data_set)\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5443d-0050-4cb8-b08d-aedc143fa5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
