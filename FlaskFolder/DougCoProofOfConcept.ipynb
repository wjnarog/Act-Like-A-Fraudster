{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c894032d-ae3a-49fb-87e6-22cad7890e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\zach0\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zach0\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b47234-44b4-4bf7-9128-9551b5b851bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m driver\u001b[38;5;241m.\u001b[39mimplicitly_wait(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Wait until the table rows are loaded (anchor tags with 'table-row' class)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     27\u001b[0m     EC\u001b[38;5;241m.\u001b[39mpresence_of_all_elements_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma.table-row\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Locate the first row (anchor tag with class 'table-row') and click it\u001b[39;00m\n\u001b[0;32m     31\u001b[0m first_row \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma.table-row\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://apps.douglas.co.us/assessor/web#/\")\n",
    "data_set = {}\n",
    "\n",
    "# Wait for the search box to be visible and locate it\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'app-input-debounce input[type=\"text\"]'))\n",
    ")\n",
    "\n",
    "# Send search query\n",
    "search_box.send_keys(\"1803 Lake Drive\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load (you may need to adjust this depending on the page)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Wait until the table rows are loaded (anchor tags with 'table-row' class)\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.table-row'))\n",
    ")\n",
    "\n",
    "# Locate the first row (anchor tag with class 'table-row') and click it\n",
    "first_row = driver.find_element(By.CSS_SELECTOR, 'a.table-row')\n",
    "first_row.click()\n",
    "\n",
    "# Get page source to parse the HTML after clicking the first row\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup to parse the HTML for further scraping\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dc6db9-8010-4d52-a07c-a1a258554f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the pop-up dialog to appear and then click the \"Close\" button\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Wait for the \"Close\" button to be clickable\n",
    "close_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button/span[text()='Close']\")))\n",
    "\n",
    "# Click the \"Close\" button to dismiss the pop-up\n",
    "close_button.click()\n",
    "\n",
    "# Wait for the account summary section to be loaded\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Use BeautifulSoup to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165077ef-5cc6-43e3-92ae-8182479fea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Summary:\n",
      "Account #:: R0396757\n",
      "State Parcel #:: 2607-202-03-017\n",
      "Account Type:: Residential\n",
      "Tax District:: 0169\n",
      "Neighborhood-Ext:: 605-B\n",
      "Building Count:: 1\n",
      "Building Permit Authority:: Douglas County (website )\n",
      "Phone:: 303-660-7497\n",
      "Name:: SAGE PORT\n",
      "Reception No:: 9612831\n",
      "\n",
      "Location Description: LOT 66 SAGE PORT FILING #4 FIRST AMENDMENT. 2.30 AM/L\n",
      "\n",
      "Owner Info:\n",
      "Owner Name: COOK FAMILY TRUST\n",
      "Owner Address: 1803 LAKE DRLARKSPUR, CO 80118\n",
      "\n",
      "Public Land Survey System (PLSS) Location: \n",
      "Quarter: NW; \n",
      "Section: 20; \n",
      "Township: 9; \n",
      "Range: 67\n",
      "\n",
      "Section PDF Map Link: /realware/SectionMaps/TWP2607/DC_2607_20.pdf\n",
      "{'Account #:': 'R0396757', 'State Parcel #:': '2607-202-03-017', 'Account Type:': 'Residential', 'Tax District:': '0169', 'Neighborhood-Ext:': '605-B', 'Building Count:': '1', 'Building Permit Authority:': 'Douglas County (website\\xa0)', 'Phone:': '303-660-7497', 'Name:': 'SAGE PORT', 'Reception No:': '9612831', 'Location Description': 'LOT 66 SAGE PORT FILING #4 FIRST AMENDMENT. 2.30 AM/L', 'Owner Name': 'COOK FAMILY TRUST', 'Owner Address': '1803 LAKE DRLARKSPUR, CO 80118'}\n"
     ]
    }
   ],
   "source": [
    "# Extract Toggle Button and Links before Account Summary\n",
    "html_content = driver.page_source\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize a dictionary to store toggle button and links\n",
    "key_value_pairs = {}\n",
    "\n",
    "# Extract the toggle button text (key) and status (value)\n",
    "toggle_button = soup.find('span', class_='ui-button-text')\n",
    "if toggle_button:\n",
    "    key_value_pairs[\"Toggle Button\"] = toggle_button.text.strip()\n",
    "\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "links = soup.find_all('a', href=True)\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    key_value_pairs[link_text] = f'<a href=\"{link_url}\">{link_text}</a>'\n",
    "\n",
    "# Now proceed with the Account Summary logic\n",
    "# Target the dropdown for Account Summary by using its ID\n",
    "dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@id='SummaryAccountInfo']//span[@class='bar faux-button']\")))\n",
    "\n",
    "# Click the dropdown to expand it\n",
    "dropdown_button.click()\n",
    "\n",
    "# Wait for the Account Summary content to load\n",
    "wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@id='SummaryAccountInfo']//div[@class='dropdown-content']\")))\n",
    "\n",
    "# Extract HTML content again after the dropdown is expanded\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the dropdown content specifically under the 'SummaryAccountInfo' ID\n",
    "dropdown_content = soup.find('div', id='SummaryAccountInfo').find('div', class_='dropdown-content')\n",
    "\n",
    "# Extract the key-value pairs from Account Summary\n",
    "account_summary_pairs = {}\n",
    "\n",
    "# Find all the rows with the class 'skinny-row' which contain the label and value pairs\n",
    "rows = dropdown_content.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in rows:\n",
    "    # Extract the label (key) and value (value)\n",
    "    label = row.find('div', class_='col-xs-4').text.strip() if row.find('div', class_='col-xs-4') else None\n",
    "    value = row.find('div', class_='col-xs-8').text.strip() if row.find('div', class_='col-xs-8') else None\n",
    "    \n",
    "    # Add to dictionary if both label and value exist\n",
    "    if label and value:\n",
    "        account_summary_pairs[label] = value\n",
    "\n",
    "# Print the Account Summary key-value pairs\n",
    "print(f\"Account Summary:\")\n",
    "for key, value in account_summary_pairs.items():\n",
    "    # Skip the \"Update Mailing Address\" entry\n",
    "    if key != 'Update Mailing Address':\n",
    "        print(f\"{key}: {value}\")\n",
    "        data_set[key] = value\n",
    "\n",
    "# Extract additional data (Location Description, Owner Info, PLSS Location)\n",
    "location_description = soup.find('div', string='Location Description').find_next('div').text.strip()\n",
    "\n",
    "# For Owner Info, we need to extract and clean it\n",
    "owner_info_div = soup.find('div', string='Owner Info').find_next('div')\n",
    "\n",
    "# Extract owner name and address\n",
    "owner_info_raw = owner_info_div.text.strip()\n",
    "\n",
    "# Split owner info into lines\n",
    "owner_info_parts = owner_info_raw.split(\"\\n\")\n",
    "\n",
    "# Clean up and extract the name and address properly\n",
    "owner_name = owner_info_parts[0].strip() \n",
    "owner_address = \" \".join(owner_info_parts[1:]).strip()  \n",
    "\n",
    "# If \"Update Mailing Address\" appears in the address, remove it\n",
    "if \"Update Mailing Address\" in owner_address:\n",
    "    owner_address = owner_address.split(\"Update Mailing Address\")[0].strip()\n",
    "\n",
    "# Extract PLSS Location\n",
    "plss_location = soup.find('div', string='Public Land Survey System (PLSS) Location').find_next('div').text.strip()\n",
    "\n",
    "# Clean the PLSS Location\n",
    "plss_location_cleaned = ' '.join(plss_location.split())\n",
    "\n",
    "# Optionally, reformat for better readability (if you want to format it neatly)\n",
    "plss_location_cleaned = plss_location_cleaned.replace(\"Quarter:\", \"\\nQuarter:\").replace(\"Section:\", \"\\nSection:\").replace(\"Township:\", \"\\nTownship:\").replace(\"Range:\", \"\\nRange:\")\n",
    "\n",
    "# Extract the Section PDF Map link (if it exists)\n",
    "section_pdf_map = None\n",
    "\n",
    "# Find all the div elements with class 'skinny-row'\n",
    "pdf_map_rows = soup.find_all('div', class_='skinny-row')\n",
    "\n",
    "for row in pdf_map_rows:\n",
    "    # Look for an anchor tag within the row\n",
    "    link = row.find('a', href=True)\n",
    "    if link and \"SectionMap\" in link['href']:  # Check if the href contains \"SectionMap\"\n",
    "        section_pdf_map = link['href']\n",
    "        break \n",
    "\n",
    "# Print other extracted information\n",
    "print(f\"\\nLocation Description: {location_description}\")\n",
    "data_set[\"Location Description\"] = location_description\n",
    "print(f\"\\nOwner Info:\")\n",
    "print(f\"Owner Name: {owner_name}\")\n",
    "data_set[\"Owner Name\"] = owner_name\n",
    "print(f\"Owner Address: {owner_address}\")\n",
    "data_set[\"Owner Address\"] = owner_address\n",
    "print(f\"\\nPublic Land Survey System (PLSS) Location: {plss_location_cleaned}\")\n",
    "#data_set[\"PLSS Location\"] = {plss_location_cleaned}\n",
    "print(f\"\\nSection PDF Map Link: {section_pdf_map}\")\n",
    "#data_set[\"PDF Map Link\"] = {section_pdf_map}\n",
    "\n",
    "print(data_set)\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f994a4bd-4c36-4c6c-ac44-86cfefde7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show graphs\n",
      "{'Account #:': 'R0396757', 'State Parcel #:': '2607-202-03-017', 'Account Type:': 'Residential', 'Tax District:': '0169', 'Neighborhood-Ext:': '605-B', 'Building Count:': '1', 'Building Permit Authority:': 'Douglas County (website\\xa0)', 'Phone:': '303-660-7497', 'Name:': 'SAGE PORT', 'Reception No:': '9612831', 'Location Description': 'LOT 66 SAGE PORT FILING #4 FIRST AMENDMENT. 2.30 AM/L', 'Owner Name': 'COOK FAMILY TRUST', 'Owner Address': '1803 LAKE DRLARKSPUR, CO 80118', 'Get Taxes Due': 'http://apps.douglas.co.us/treasurer/treasurerweb/account.jsp?account=R0396757&guest=true', 'Property Tax Calculation': 'https://www.douglas.co.us/assessor/residential-property-tax-calculations', 'sale0': {'Year': '2024', 'Actual Value': '$1,295,427', 'Assessed Value': '$86,790', 'Tax Rate': '9.7470%', 'Est. Tax Amount': 'Tax Calculation'}, 'sale1': {'Year': '2023', 'Actual Value': '$1,295,427', 'Assessed Value': '$86,790', 'Tax Rate': '9.8441%', 'Est. Tax Amount': 'Tax Calculation'}, 'sale2': {'Year': '2022', 'Actual Value': '$852,669', 'Assessed Value': '$59,260', 'Tax Rate': '9.4724%', 'Est. Tax Amount': '$5,613'}, 'sale3': {'Year': '2021', 'Actual Value': '$852,669', 'Assessed Value': '$60,970', 'Tax Rate': '9.5310%', 'Est. Tax Amount': '$5,811'}, 'sale4': {'Year': '2020', 'Actual Value': '$743,866', 'Assessed Value': '$53,190', 'Tax Rate': '9.6060%', 'Est. Tax Amount': '$5,109'}, 'sale5': {'Year': '2019', 'Actual Value': '$743,866', 'Assessed Value': '$53,190', 'Tax Rate': '9.6378%', 'Est. Tax Amount': '$5,126'}, 'sale6': {'Year': '2018', 'Actual Value': '$659,857', 'Assessed Value': '$47,510', 'Tax Rate': '9.8102%', 'Est. Tax Amount': '$4,661'}, 'sale7': {'Year': '2017', 'Actual Value': '$659,857', 'Assessed Value': '$47,510', 'Tax Rate': '9.2206%', 'Est. Tax Amount': '$4,381'}, 'sale8': {'Year': '2016', 'Actual Value': '$611,328', 'Assessed Value': '$48,670', 'Tax Rate': '9.3750%', 'Est. Tax Amount': '$4,563'}, 'sale9': {'Year': '2015', 'Actual Value': '$611,328', 'Assessed Value': '$48,670', 'Tax Rate': '9.1681%', 'Est. Tax Amount': '$4,462'}, 'sale10': {'Year': '2014', 'Actual Value': '$528,657', 'Assessed Value': '$42,080', 'Tax Rate': '9.7768%', 'Est. Tax Amount': '$4,114'}, 'sale11': {'Year': '2013', 'Actual Value': '$528,657', 'Assessed Value': '$42,080', 'Tax Rate': '9.7798%', 'Est. Tax Amount': '$4,115'}, 'sale12': {'Year': '2012', 'Actual Value': '$579,914', 'Assessed Value': '$46,160', 'Tax Rate': '9.8364%', 'Est. Tax Amount': '$4,540'}, 'sale13': {'Year': '2011', 'Actual Value': '$579,914', 'Assessed Value': '$46,160', 'Tax Rate': '9.8265%', 'Est. Tax Amount': '$4,536'}, 'sale14': {'Year': '2010', 'Actual Value': '$819,982', 'Assessed Value': '$65,270', 'Tax Rate': '9.4128%', 'Est. Tax Amount': '$6,144'}, 'sale15': {'Year': '2009', 'Actual Value': '$819,982', 'Assessed Value': '$65,270', 'Tax Rate': '9.3955%', 'Est. Tax Amount': '$6,132'}, 'sale16': {'Year': '2008', 'Actual Value': '$799,442', 'Assessed Value': '$63,640', 'Tax Rate': '9.4639%', 'Est. Tax Amount': '$6,023'}, 'sale17': {'Year': '2007', 'Actual Value': '$799,442', 'Assessed Value': '$63,640', 'Tax Rate': '9.6944%', 'Est. Tax Amount': '$6,170'}, 'sale18': {'Year': '2006', 'Actual Value': '$794,256', 'Assessed Value': '$63,230', 'Tax Rate': '9.8685%', 'Est. Tax Amount': '$6,240'}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store toggle button and links\n",
    "key_value_pairs = {}\n",
    "\n",
    "# Extract the toggle button text (Show Graphs)\n",
    "toggle_button = soup.find('span', class_='ui-button-text')\n",
    "if toggle_button:\n",
    "    print(toggle_button.text.strip())  # Print 'Show Graphs'\n",
    "\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "links = soup.find_all('a', href=True)\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    \n",
    "    # Print specific links that we are interested in\n",
    "    if link_text == \"Get Taxes Due\":\n",
    "        data_set[link_text] = link_url  # Hyperlink Get Taxes Due\n",
    "    elif link_text == \"Property Tax Calculation\":\n",
    "        data_set[link_text] = link_url  # Hyperlink Property Tax Calculation\n",
    "\n",
    "# Now continue with the part for finding and processing the table data\n",
    "# Find the table with class 'value-data-table'\n",
    "table = soup.find('table', class_='value-data-table')\n",
    "if table:\n",
    "    # print(\"Table found\")  \n",
    "\n",
    "    # Find all tbody elements inside the table with the 'sales-info' class, without specifying the dynamic part\n",
    "    rows = table.find_all('tbody', class_='value-row')  \n",
    "\n",
    "    # Check how many rows are found\n",
    "    # print(f\"Found {len(rows)} tbody elements.\")  \n",
    "\n",
    "    # Iterate over each row and extract data\n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract Year, Actual Value, Assessed Value, Tax Rate, Est. Tax Amount\n",
    "        year = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        actual_value = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        assesssed_value = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        tax_rate = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        est_tax_amount = row.find_all('td')[4].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "    \n",
    "        # Store row data in a table\n",
    "        sales_data.append({\n",
    "            'Year': year,\n",
    "            'Actual Value': actual_value,\n",
    "            'Assessed Value': assesssed_value,\n",
    "            'Tax Rate': tax_rate,\n",
    "            'Est. Tax Amount': est_tax_amount\n",
    "        })\n",
    "        \n",
    "    # Print extracted data\n",
    "    index = 0\n",
    "    for row in sales_data:\n",
    "        data_set[\"sale\"+str(index)] = row\n",
    "        index+=1\n",
    "\n",
    "    print(data_set)\n",
    "\n",
    "else:\n",
    "    print(\"Table not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd5f82c-4d49-448c-be04-1ff79de1dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table with class 'sales-data-table table'\n",
    "table = soup.find('table', class_='sales-data-table table')\n",
    "# Extract the anchor tags (links) and their href attributes\n",
    "\n",
    "links = soup.find_all('a', href=True)\n",
    "# Use a set to track printed links, avoid duplications\n",
    "printed_links = set()  \n",
    "\n",
    "for link in links:\n",
    "    link_text = link.get_text(strip=True)\n",
    "    link_url = link['href']\n",
    "    \n",
    "    # Print specific links that we are interested in, only if not already printed\n",
    "    if link_text == \"View Neighborhood Sales\" and link_url not in printed_links:\n",
    "        data_set[link_text] = link_url\n",
    "        printed_links.add(link_url)  # Mark this link as printed\n",
    "    elif link_text == \"Recorded Document Search\" and link_url not in printed_links:\n",
    "        data_set[link_text] = link_url\n",
    "        printed_links.add(link_url)\n",
    "\n",
    "        \n",
    "if table:\n",
    "    # print(\"Table found\")  \n",
    "    \n",
    "    # Find all tbody elements inside the table with the 'sales-info' class, without specifying the dynamic part\n",
    "    rows = table.find_all('tbody', class_='sales-info')  \n",
    "    # print(f\"Found {len(rows)} tbody elements.\")  \n",
    "    \n",
    "    # Iterate over each row and extract data\n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract Reception No, Sale Date, Sale Price, Deed Type, etc.\n",
    "        reception_no = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 0 else None\n",
    "        \n",
    "        sale_date = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        sale_price = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        deed_type = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 2 else None\n",
    "        \n",
    "        # Extract Grantor and Grantee\n",
    "        sales_details_row = row.find_next('tr', class_='sales-details')\n",
    "        if sales_details_row:\n",
    "            grantor_grantee_div = sales_details_row.find('div', class_='col-sm-9 col-xs-12')\n",
    "            if grantor_grantee_div:\n",
    "                grantor = grantor_grantee_div.find_all('span', class_='ng-star-inserted')[0].text.strip().replace('Grantor:', '').strip()\n",
    "                grantee = grantor_grantee_div.find_all('span', class_='ng-star-inserted')[1].text.strip().replace('Grantee:', '').strip()\n",
    "            else:\n",
    "                grantor, grantee = None, None\n",
    "        else:\n",
    "            grantor, grantee = None, None\n",
    "        \n",
    "        # Store row data in a dictionary\n",
    "        sales_data.append({\n",
    "            'Reception No': reception_no,\n",
    "            'Sale Date': sale_date,\n",
    "            'Sale Price': sale_price,\n",
    "            'Deed Type': deed_type,\n",
    "            'Grantor': grantor,\n",
    "            'Grantee': grantee\n",
    "        })\n",
    "        \n",
    "    # Print extracted data\n",
    "    index = 0\n",
    "    for row in sales_data:\n",
    "        data_set[\"sales_doc\"+ str(index)] = row\n",
    "        index += 1\n",
    "        \n",
    "\n",
    "else:\n",
    "    print(\"Table not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884ba1e6-8161-4783-959c-b1196711f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_data = {}\n",
    "# Find the building details section using its ID\n",
    "building_details = soup.find('div', {'id': 'BuildingDetails'})\n",
    "\n",
    "if building_details:\n",
    "    # Scrape building images\n",
    "    images = building_details.find_all('img', class_='bordered')\n",
    "    image_urls = [img['src'] for img in images if img.has_attr('src')]\n",
    "    building_data['Images'] = image_urls\n",
    "    \n",
    "    # Scrape building primary info (property type, year built, etc.)\n",
    "    building_info = building_details.find_all('div', class_='smart-table')\n",
    "    primary_info = {}\n",
    "\n",
    "    for info in building_info:\n",
    "        # Find the label and value pairs for each group\n",
    "        label_elements = info.find_all('div', recursive=False)\n",
    "        \n",
    "        # Ensure there are exactly two divs, one for the label and one for the value\n",
    "        if len(label_elements) == 2:\n",
    "            label = label_elements[0].text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            key, new_value = label.split(\": \")\n",
    "            data_set[key] = new_value.replace(' ', '')\n",
    "            value = label_elements[1].text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            key, new_value = value.split(\":\")\n",
    "            data_set[key] = new_value.replace(' ', '')\n",
    "\n",
    "            \n",
    "            \n",
    "            # Add the pair to the primary info dictionary\n",
    "            primary_info[label] = value\n",
    "\n",
    "    building_data['Primary Info'] = primary_info\n",
    "\n",
    "    \n",
    "    # Scrape additional features and fixtures\n",
    "    additional_features = []\n",
    "    more_details = building_details.find_all('div', class_='skinny-row')\n",
    "    for detail in more_details:\n",
    "        name = detail.find('span', class_='name')\n",
    "        value = detail.find('span', class_='value')\n",
    "        if name and value:\n",
    "            name_text = name.text.strip().replace('\\n', ' ').replace('\\r', '')\n",
    "            value_text = value.text.strip().replace('\\n', ' ').replace('\\r', '')\n",
    "            additional_features.append({name_text: value_text})\n",
    "    \n",
    "    building_data['Additional Features'] = additional_features\n",
    "\n",
    "else:\n",
    "    print(\"Building details section not found.\")\n",
    "\n",
    "index = 0\n",
    "for item in building_data['Images']:\n",
    "    data_set[\"image\"+str(index)] = item\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "for item in building_data['Additional Features']:\n",
    "    data_set[\"feature\"+str(index)] = item\n",
    "    index += 1\n",
    "\n",
    "\n",
    "# Print the scraped data, each key-value pair on its own line\n",
    "# for key, value in building_data.items():\n",
    "#     print(f\"{key}:\")\n",
    "#     if isinstance(value, list):\n",
    "#         for item in value:\n",
    "#             # If the value is a dictionary (for additional features)\n",
    "#             if isinstance(item, dict): \n",
    "#                 for sub_key, sub_value in item.items():\n",
    "#                     print(f\"  {sub_key} {sub_value}\")\n",
    "#             else:\n",
    "#                 print(f\"  {item}\")\n",
    "#     else:\n",
    "#         # For primary info, print each label-value pair on a new line\n",
    "#         if key == '\\nPrimary Info': \n",
    "#             for label, value in value.items():\n",
    "#                 print(f\"  {label} {value}\")\n",
    "#         else:\n",
    "#             print(f\"  {value}\")\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572e5460-f283-4057-a673-5ad9bf96a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_info = {}\n",
    "\n",
    "# Find the \"LandInfoAndValue\" section\n",
    "land_info_section = soup.find('div', {'id': 'LandInfoAndValue'})\n",
    "\n",
    "if land_info_section:\n",
    "    # Scrape Land Details (Land Type, Class Code, etc.)\n",
    "    land_details = land_info_section.find_all('div', class_='row')\n",
    "    \n",
    "    for detail in land_details:\n",
    "        label = detail.find('div', class_='col-xs-3')\n",
    "        value = detail.find('div', class_='col-xs-9')\n",
    "        \n",
    "        if label and value:\n",
    "            # Clean up label and value text\n",
    "            label_text = label.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            value_text = value.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "            \n",
    "            # Add label-value pair to the dictionary\n",
    "            land_info[label_text] = value_text\n",
    "    \n",
    "    # Scrape Land Valuation (Actual Value)\n",
    "    valuation_section = land_info_section.find('div', class_='header')\n",
    "    if valuation_section and 'Land Valuation' in valuation_section.text:\n",
    "        # Last row is the valuation row\n",
    "        valuation_row = land_info_section.find_all('div', class_='row')[-1]  \n",
    "        actual_value_label = valuation_row.find('div', class_='col-sm-3')\n",
    "        actual_value = valuation_row.find('div', class_='col-sm-9')\n",
    "        \n",
    "        if actual_value_label and actual_value:\n",
    "            land_info['Actual Value'] = actual_value.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "# Print the scraped land info\n",
    "for key, value in land_info.items():\n",
    "    data_set[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3da4ad-a4f5-4032-a2cb-cc86655457a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table with class 'tax-data-table table'\n",
    "table = soup.find('table', class_='tax-data-table table')\n",
    "\n",
    "if table:\n",
    "    # Find all tbody elements inside the table with the 'tax-info' class (except the last 'total-row')\n",
    "    rows = table.find_all('tbody', class_='tax-info')  \n",
    "    \n",
    "    sales_data = []\n",
    "    for row in rows:\n",
    "        # Extract data from the first row\n",
    "        tax_id = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 0 else None\n",
    "        authority_name = row.find_all('td')[1].text.strip() if len(row.find_all('td')) > 1 else None\n",
    "        mills = row.find_all('td')[2].text.strip() if len(row.find_all('td')) > 2 else None\n",
    "        tax_rate = row.find_all('td')[3].text.strip() if len(row.find_all('td')) > 3 else None\n",
    "        tax_amount = row.find_all('td')[4].text.strip() if len(row.find_all('td')) > 4 else None\n",
    "        \n",
    "        # Store row data in a dictionary\n",
    "        sales_data.append({\n",
    "            'ID': tax_id,\n",
    "            'Authority Name': authority_name,\n",
    "            'Mills': mills,\n",
    "            'Tax Rate': tax_rate,\n",
    "            'Est. Tax Amount': tax_amount\n",
    "        })\n",
    "\n",
    "    index = 0\n",
    "    # Print extracted data\n",
    "    for row in sales_data:\n",
    "        data_set[\"tax\"+str(index)] = row\n",
    "        index+=1\n",
    "        \n",
    "else:\n",
    "    print(\"Table not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb97017-c697-4e9d-805d-32d8e000bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_content = soup.find('div', id='Documents').find('div', class_='dropdown-content')\n",
    "\n",
    "# Find the list of documents inside the dropdown\n",
    "documents_list = dropdown_content.find_all('li', class_='ng-star-inserted') if dropdown_content else []\n",
    "\n",
    "if documents_list:\n",
    "    # Initialize an empty dictionary to store document data\n",
    "    document_data = {}\n",
    "\n",
    "    # Iterate through each document item and extract the desired data\n",
    "    for doc in documents_list:\n",
    "        # Get document name (PDF filename)\n",
    "        doc_name = doc.find('a').text.strip() if doc.find('a') else None\n",
    "        \n",
    "        # Get file size\n",
    "        size = doc.find('div', class_='col-sm-2')\n",
    "        size = size.text.strip().replace('Size:', '').strip() if size else None\n",
    "        \n",
    "        # Get last modified date\n",
    "        last_modified = doc.find('div', class_='col-sm-4')\n",
    "        last_modified = last_modified.text.strip().replace('Last Modified Date:', '').strip() if last_modified else None\n",
    "        \n",
    "        # Store the extracted data in the dictionary with document name as the key\n",
    "        document_data[doc_name] = {\n",
    "            'Name': doc_name,\n",
    "            'Size': size,\n",
    "            'Last Modified Date': last_modified\n",
    "        }\n",
    "\n",
    "    # Print the document data dictionary\n",
    "    index = 0\n",
    "    for doc_name, details in document_data.items():\n",
    "        data_set[\"document\"+str(index)] = details\n",
    "        index += 1\n",
    "        \n",
    "else:\n",
    "    print(\"No documents found \")\n",
    "\n",
    "# Close the browser\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c3ed3d-192d-4f47-bd35-1eb41017e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Account #:': 'R0396757', 'State Parcel #:': '2607-202-03-017', 'Account Type:': 'Residential', 'Tax District:': '0169', 'Neighborhood-Ext:': '605-B', 'Building Count:': '1', 'Building Permit Authority:': 'Douglas County (website\\xa0)', 'Phone:': '303-660-7497', 'Name:': 'SAGE PORT', 'Reception No:': '9612831', 'Location Description': 'LOT 66 SAGE PORT FILING #4 FIRST AMENDMENT. 2.30 AM/L', 'Owner Name': 'COOK FAMILY TRUST', 'Owner Address': '1803 LAKE DRLARKSPUR, CO 80118', 'Get Taxes Due': 'http://apps.douglas.co.us/treasurer/treasurerweb/account.jsp?account=R0396757&guest=true', 'Property Tax Calculation': 'https://www.douglas.co.us/assessor/residential-property-tax-calculations', 'sale0': {'Year': '2024', 'Actual Value': '$1,295,427', 'Assessed Value': '$86,790', 'Tax Rate': '9.7470%', 'Est. Tax Amount': 'Tax Calculation'}, 'sale1': {'Year': '2023', 'Actual Value': '$1,295,427', 'Assessed Value': '$86,790', 'Tax Rate': '9.8441%', 'Est. Tax Amount': 'Tax Calculation'}, 'sale2': {'Year': '2022', 'Actual Value': '$852,669', 'Assessed Value': '$59,260', 'Tax Rate': '9.4724%', 'Est. Tax Amount': '$5,613'}, 'sale3': {'Year': '2021', 'Actual Value': '$852,669', 'Assessed Value': '$60,970', 'Tax Rate': '9.5310%', 'Est. Tax Amount': '$5,811'}, 'sale4': {'Year': '2020', 'Actual Value': '$743,866', 'Assessed Value': '$53,190', 'Tax Rate': '9.6060%', 'Est. Tax Amount': '$5,109'}, 'sale5': {'Year': '2019', 'Actual Value': '$743,866', 'Assessed Value': '$53,190', 'Tax Rate': '9.6378%', 'Est. Tax Amount': '$5,126'}, 'sale6': {'Year': '2018', 'Actual Value': '$659,857', 'Assessed Value': '$47,510', 'Tax Rate': '9.8102%', 'Est. Tax Amount': '$4,661'}, 'sale7': {'Year': '2017', 'Actual Value': '$659,857', 'Assessed Value': '$47,510', 'Tax Rate': '9.2206%', 'Est. Tax Amount': '$4,381'}, 'sale8': {'Year': '2016', 'Actual Value': '$611,328', 'Assessed Value': '$48,670', 'Tax Rate': '9.3750%', 'Est. Tax Amount': '$4,563'}, 'sale9': {'Year': '2015', 'Actual Value': '$611,328', 'Assessed Value': '$48,670', 'Tax Rate': '9.1681%', 'Est. Tax Amount': '$4,462'}, 'sale10': {'Year': '2014', 'Actual Value': '$528,657', 'Assessed Value': '$42,080', 'Tax Rate': '9.7768%', 'Est. Tax Amount': '$4,114'}, 'sale11': {'Year': '2013', 'Actual Value': '$528,657', 'Assessed Value': '$42,080', 'Tax Rate': '9.7798%', 'Est. Tax Amount': '$4,115'}, 'sale12': {'Year': '2012', 'Actual Value': '$579,914', 'Assessed Value': '$46,160', 'Tax Rate': '9.8364%', 'Est. Tax Amount': '$4,540'}, 'sale13': {'Year': '2011', 'Actual Value': '$579,914', 'Assessed Value': '$46,160', 'Tax Rate': '9.8265%', 'Est. Tax Amount': '$4,536'}, 'sale14': {'Year': '2010', 'Actual Value': '$819,982', 'Assessed Value': '$65,270', 'Tax Rate': '9.4128%', 'Est. Tax Amount': '$6,144'}, 'sale15': {'Year': '2009', 'Actual Value': '$819,982', 'Assessed Value': '$65,270', 'Tax Rate': '9.3955%', 'Est. Tax Amount': '$6,132'}, 'sale16': {'Year': '2008', 'Actual Value': '$799,442', 'Assessed Value': '$63,640', 'Tax Rate': '9.4639%', 'Est. Tax Amount': '$6,023'}, 'sale17': {'Year': '2007', 'Actual Value': '$799,442', 'Assessed Value': '$63,640', 'Tax Rate': '9.6944%', 'Est. Tax Amount': '$6,170'}, 'sale18': {'Year': '2006', 'Actual Value': '$794,256', 'Assessed Value': '$63,230', 'Tax Rate': '9.8685%', 'Est. Tax Amount': '$6,240'}, 'View Neighborhood Sales': 'https://co-douglas-residential.comper.info/template.aspx?propertyID=R0396757', 'Recorded Document Search': 'https://apps.douglas.co.us/LandMarkWeb', 'sales_doc0': {'Reception No': '2024012469', 'Sale Date': '03/21/2024', 'Sale Price': '$0', 'Deed Type': 'Special Warranty Deed', 'Grantor': 'CHRISTOPHER COOK & PATRICIA A PAVIK COOK', 'Grantee': 'COOK FAMILY TRUST'}, 'sales_doc1': {'Reception No': '2023028894', 'Sale Date': '07/06/2023', 'Sale Price': '$1,388,849', 'Deed Type': 'Special Warranty Deed Joint', 'Grantor': 'JERYN L RICHARD & JEFF C RICHARD', 'Grantee': 'CHRISTOPHER COOK & PATRICIA A PAVIK COOK'}, 'sales_doc2': {'Reception No': '99054060', 'Sale Date': '06/03/1999', 'Sale Price': '$108,000', 'Deed Type': 'Warranty Deed', 'Grantor': 'MARK B BROWN', 'Grantee': 'JERYN L RICHARD & JEFF C RICHARD'}, 'sales_doc3': {'Reception No': '9652075', 'Sale Date': '09/18/1996', 'Sale Price': '$103,900', 'Deed Type': 'Warranty Deed', 'Grantor': 'STERLING POINTE DEVELOPMENT', 'Grantee': 'BROWN MARK B'}, 'Property Type': 'Residential', 'Year Built': '2000', 'Square Footage': '3,330sqft', 'Style': '2Story', 'image0': '/realware/PHOTOS/R0396757/2000_IMP_1_WEB.JPG', 'image1': '/realware/SKETCHES/R0396757/2025_IMP_1_Page 1 - Apex R0396757 Imp No - 1.00.JPG', 'feature0': {'Quality:': 'Very Good'}, 'feature1': {'Quality:': 'Very Good'}, 'feature2': {'% Complete:': '100%'}, 'feature3': {'Stories:': '2'}, 'feature4': {'Bedrooms (above ground):': '3'}, 'feature5': {'Bathrooms (above ground):': '4'}, 'feature6': {'Basement Area:': '1,922 sqft'}, 'feature7': {'Finished Bsmt. Area:': '1,620 sqft (84%)'}, 'feature8': {'Total Finished Area:': '4,950 sqft'}, 'feature9': {'Walkout:': 'Y'}, 'feature10': {'Fireplaces:': '2'}, 'feature11': {'Porch/Deck Area:': '1,127 sqft'}, 'feature12': {'Garage Type': 'Garage Area'}, 'feature13': {'Attached:': '1,061 sqft'}, 'feature14': {'Detached:': '0 sqft'}, 'feature15': {\"Assessor's Building ID:\": '1'}, 'Land Type:': 'Residential', 'Class Code:': '1112', 'Class Code Descr.:': 'IMPROVED RESIDENTIAL LAND', 'Acreage:': '2.300 acres', 'LEA Code:': '9C3', 'Actual Value': '$318,852', 'tax0': {'ID': '2001', 'Authority Name': 'Douglas County Re-1 School District', 'Mills': '40.324', 'Tax Rate': '4.0324%', 'Est. Tax Amount': '$3,500'}, 'tax1': {'ID': '4004', 'Authority Name': 'Larkspur Fire Protection District', 'Mills': '18.998', 'Tax Rate': '1.8998%', 'Est. Tax Amount': '$1,649'}, 'tax2': {'ID': '0001', 'Authority Name': 'Douglas County Government', 'Mills': '18.726', 'Tax Rate': '1.8726%', 'Est. Tax Amount': '$1,625'}, 'tax3': {'ID': '4003', 'Authority Name': 'Perry Park Water & Sanitation District', 'Mills': '5.614', 'Tax Rate': '0.5614%', 'Est. Tax Amount': '$487'}, 'tax4': {'ID': '2004', 'Authority Name': 'Douglas County Schools - Debt Service', 'Mills': '5.204', 'Tax Rate': '0.5204%', 'Est. Tax Amount': '$452'}, 'tax5': {'ID': '0002', 'Authority Name': 'Douglas County Law Enforcement', 'Mills': '4.500', 'Tax Rate': '0.4500%', 'Est. Tax Amount': '$391'}, 'tax6': {'ID': '4390', 'Authority Name': 'Douglas Public Library District', 'Mills': '4.000', 'Tax Rate': '0.4000%', 'Est. Tax Amount': '$347'}, 'tax7': {'ID': '4012', 'Authority Name': 'Cedar Hill Cemetery Association', 'Mills': '0.104', 'Tax Rate': '0.0104%', 'Est. Tax Amount': '$9'}, 'tax8': {'ID': '2002', 'Authority Name': 'Douglas County Schools - Cap Reserve', 'Mills': '0.000', 'Tax Rate': '0.0000%', 'Est. Tax Amount': '$0'}, 'tax9': {'ID': '2003', 'Authority Name': 'Douglas County Schools - Insurance Reserve', 'Mills': '0.000', 'Tax Rate': '0.0000%', 'Est. Tax Amount': '$0'}, 'tax10': {'ID': '4077', 'Authority Name': 'Douglas County Soil Conservation District', 'Mills': '0.000', 'Tax Rate': '0.0000%', 'Est. Tax Amount': '$0'}, 'document0': {'Name': 'R0396757_NOV_2024.pdf', 'Size': '138.9kb', 'Last Modified Date': 'Apr 23, 2024'}, 'document1': {'Name': 'R0396757_NOV_2023.pdf', 'Size': '129.7kb', 'Last Modified Date': 'May 1, 2023'}, 'document2': {'Name': 'R0396757_NOV_2022.pdf', 'Size': '120.2kb', 'Last Modified Date': 'Apr 21, 2022'}, 'document3': {'Name': 'R0396757_NOV_2021.pdf', 'Size': '323.8kb', 'Last Modified Date': 'Jul 7, 2021'}, 'document4': {'Name': 'R0396757_NOV_2020.pdf', 'Size': '324.7kb', 'Last Modified Date': 'Jun 11, 2020'}, 'document5': {'Name': 'R0396757_NOV_2019.pdf', 'Size': '325.1kb', 'Last Modified Date': 'Jun 15, 2020'}, 'document6': {'Name': 'R0396757_NOV_2018.pdf', 'Size': '324.8kb', 'Last Modified Date': 'Jun 17, 2020'}, 'document7': {'Name': 'R0396757_NOV_2017.pdf', 'Size': '323.6kb', 'Last Modified Date': 'Jun 18, 2020'}}\n"
     ]
    }
   ],
   "source": [
    "print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a5443d-0050-4cb8-b08d-aedc143fa5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:29] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:30] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:34] \"GET /option3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:34] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:53] \"OPTIONS /query HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option1():\n",
    "    house_info = []\n",
    "    returnval = {}\n",
    "    house_info.append({\n",
    "                    \"Year\": 2020,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    house_info.append({\n",
    "                    \"Year\": 2021,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    \n",
    "    index = 0\n",
    "    for item in house_info:\n",
    "        returnval[\"detail\"+str(index)] = item\n",
    "        index += 1\n",
    "    return jsonify(returnval)\n",
    "\n",
    "@app.route('/option2')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option2():\n",
    "    data_set = {}\n",
    "    data_set[\"Owner\"] = \"Zach\"\n",
    "    data_set[\"Address\"] = \"3135 Moorhead Ave\"\n",
    "    data_set[\"Price1\"] = \"$20,000\"\n",
    "    data_set[\"Year1\"] = 1960\n",
    "    data_set[\"Price2\"] = \"$500,000\"\n",
    "    data_set[\"Year2\"] = 2020\n",
    "    return data_set\n",
    "\n",
    "@app.route('/option3')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option3():\n",
    "    return jsonify(data_set)\n",
    "    \n",
    "# main driver function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # run() method of Flask class runs the application \n",
    "    # on the local development server.\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8193d5-7a92-487d-bbf9-a2a1acfc03a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78b284-33f5-4ded-b580-9a11a0cb96ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f70e97-22b1-417c-be85-e1c1150dc46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
