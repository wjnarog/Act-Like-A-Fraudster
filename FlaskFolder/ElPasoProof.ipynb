{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c894032d-ae3a-49fb-87e6-22cad7890e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\zach0\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zach0\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91b47234-44b4-4bf7-9128-9551b5b851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = {}\n",
    "address_to_search = \"2366 Mesa Crest Grv\"\n",
    "# Initialize the Chrome WebDriver and load the property search website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://property.spatialest.com/co/elpaso/#/\")\n",
    "\n",
    "# Wait for the search box to be visible and input the address\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.ID, \"primary_search\"))\n",
    ")\n",
    "\n",
    "# Input the address to search for and submit the search\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'primary_search'))\n",
    ")\n",
    "search_box.send_keys(address_to_search)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load on the page\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"data-list-section\"))\n",
    ")\n",
    "\n",
    "# Parse the page source with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# --------------------------------------------\n",
    "# Extracting General Property Information\n",
    "# --------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79dc6db9-8010-4d52-a07c-a1a258554f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 'data-list-section' that contains the relevant data\n",
    "data_list_section = soup.find('div', class_='data-list-section')\n",
    "\n",
    "# Find all the list items (li) within this section\n",
    "data_rows = data_list_section.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "property_details = {}\n",
    "\n",
    "# Iterate over each data row to extract the title and value\n",
    "for row in data_rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    # If the value is a dropdown (select), extract the selected option\n",
    "    if not value:\n",
    "        value = row.find('select')\n",
    "        if value:\n",
    "            value = value.find('option').text.strip()\n",
    "    else:\n",
    "        value = value.text.strip()\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        property_details[title_text] = value\n",
    "\n",
    "# Print out the extracted data\n",
    "for key, value in property_details.items():\n",
    "    data_set[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165077ef-5cc6-43e3-92ae-8182479fea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Value:\n",
      "\n",
      "Assessed Value:\n"
     ]
    }
   ],
   "source": [
    "# Find the \"Market & Assessment Details\" section\n",
    "assessment_section = soup.find('div', class_='assessment')\n",
    "\n",
    "# Find the data list containing market and assessed values\n",
    "data_list = assessment_section.find('ul', class_='data-list')\n",
    "\n",
    "# Extract the rows for the market and assessed values\n",
    "rows = data_list.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "market_value = {}\n",
    "assessed_value = {}\n",
    "\n",
    "for row in rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        value_text = value.text.strip()\n",
    "\n",
    "        # Checking if the title matches categories and storing the respective values\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            market_value[title_text] = value_text\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            assessed_value[title_text] = value_text\n",
    "\n",
    "# Print the results for Market and Assessed Values\n",
    "print(\"Market Value:\")\n",
    "for key, val in market_value.items():\n",
    "    data_set[\"Market Value \"+key] = val\n",
    "\n",
    "print(\"\\nAssessed Value:\")\n",
    "for key, val in assessed_value.items():\n",
    "    data_set[\"Assessed Key \"+key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f994a4bd-4c36-4c6c-ac44-86cfefde7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Number: 1\n",
      "Land Use: SINGLE FAMILY RESIDENTIAL\n",
      "Assessment Rate: 6.700\n",
      "Area: 7206 SQFT\n",
      "Market Value: $122,400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the table containing the land details\n",
    "table = soup.find('table', class_='table-striped')\n",
    "\n",
    "# Extract the headers (columns) from the table\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "# Extract the rows of the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each row\n",
    "data = []\n",
    "\n",
    "# Loop through each row (skipping the header row)\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if columns:\n",
    "        row_data = {}\n",
    "        for i, col in enumerate(columns):\n",
    "            # Assign the header as the key and the column value as the value\n",
    "            row_data[headers[i]] = col.text.strip()\n",
    "        data.append(row_data)\n",
    "\n",
    "# Now print the scraped land info in the format you requested\n",
    "for land_info in data:\n",
    "    for key, value in land_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd5f82c-4d49-448c-be04-1ff79de1dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANCH 1 STORY (1) Details:\n",
      "Assessment Rate: 6.700\n",
      "Above Grade Area: 1,921\n",
      "Bldg #: 1\n",
      "First Floor Area: 1,921\n",
      "Style Description: RANCH 1 STORY\n",
      "Above First Floor Area: 0\n",
      "Property Description: SINGLE FAMILY RESIDENTIAL\n",
      "Lower Level Living Area: 0\n",
      "Year Built: 2012\n",
      "Total Basement Area: 1,881\n",
      "Dwelling Units: 1\n",
      "Finished Basement Area: 1,800\n",
      "Number of Rooms: 10\n",
      "Garage Description: Attached\n",
      "Number of Bedrooms: 3\n",
      "Garage Area: 528\n",
      "Number of Baths: 2.50\n",
      "Carport Area: -\n",
      "Market Value: $570,567\n"
     ]
    }
   ],
   "source": [
    "sections = soup.find_all('div', class_='panel panel-default')\n",
    "\n",
    "# Loop through each section and extract the details\n",
    "for section in sections:\n",
    "    # Extract title for identification (either BI LEVEL 2 STORY or RESIDENTIAL OUTBUILDINGS)\n",
    "    section_title = section.find('h4', class_='panel-title').get_text(strip=True)\n",
    "\n",
    "    # Extract building details for each section\n",
    "    market_value = section.find('div', class_='building-value').find_all('span')[1].get_text(strip=True)\n",
    "    data_list = section.find('ul', class_='data-list')\n",
    "    building_details = {}\n",
    "\n",
    "    # Loop through each row and extract the title and value for each <p> tag\n",
    "    for item in data_list.find_all('li', class_='data-list-row'):\n",
    "        data_items = item.find_all('p', class_='data-list-item')\n",
    "        for data_item in data_items:\n",
    "            title_span = data_item.find('span', class_='title')\n",
    "            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "            if title_span:\n",
    "                title = title_span.get_text(strip=True)\n",
    "                value = value_span.get_text(strip=True) if value_span else \"-\"\n",
    "                building_details[title] = value\n",
    "    \n",
    "    # Add the market value to the building details dictionary\n",
    "    building_details['Market Value'] = market_value\n",
    "\n",
    "    # Print out the details for each section\n",
    "    print(f\"\\n{section_title} Details:\")\n",
    "    for key, value in building_details.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "884ba1e6-8161-4783-959c-b1196711f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sale Date: 01/22/2013\n",
      "Sale Price: $395,036\n",
      "Sale Type: Arms-Length Sale\n",
      "Reception: 213008369\n",
      "Schedule No: 7402104008\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: New\n",
      "Term: Month(s): 0\n",
      "Financing: New 0% Fixed\n",
      "Amt. Financed: $0\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: VANGUARD HOMES INC\n",
      "Grantee: COOK THOMAS J\n",
      "\n",
      "Sale Date: 06/29/2012\n",
      "Sale Price: $31,000\n",
      "Sale Type: Vacant Land; REO or Sale After Foreclosu\n",
      "Reception: 213008369\n",
      "Schedule No: 7402104008\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: New\n",
      "Term: Month(s): 0\n",
      "Financing: New 0% Fixed\n",
      "Amt. Financed: $0\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: VANGUARD HOMES INC\n",
      "Grantee: COOK THOMAS J\n",
      "\n",
      "Sale Date: 07/12/2011\n",
      "Sale Price: $0\n",
      "Sale Type: -\n",
      "Reception: 213008369\n",
      "Schedule No: 7402104008\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: New\n",
      "Term: Month(s): 0\n",
      "Financing: New 0% Fixed\n",
      "Amt. Financed: $0\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: VANGUARD HOMES INC\n",
      "Grantee: COOK THOMAS J\n",
      "\n",
      "Sale Date: 01/08/2007\n",
      "Sale Price: $105,760\n",
      "Sale Type: Vacant Land\n",
      "Reception: 213008369\n",
      "Schedule No: 7402104008\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: New\n",
      "Term: Month(s): 0\n",
      "Financing: New 0% Fixed\n",
      "Amt. Financed: $0\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: VANGUARD HOMES INC\n",
      "Grantee: COOK THOMAS J\n",
      "\n",
      "Sale Date: 04/20/2005\n",
      "Sale Price: $0\n",
      "Sale Type: -\n",
      "Reception: 213008369\n",
      "Schedule No: 7402104008\n",
      "Book: -\n",
      "Page: -\n",
      "Balloon: No\n",
      "PP/Good Will: $0\n",
      "Related Parties: N\n",
      "Trade/Exch: $0\n",
      "Condition: New\n",
      "Term: Month(s): 0\n",
      "Financing: New 0% Fixed\n",
      "Amt. Financed: $0\n",
      "Down Pmt: $0\n",
      "Doc Type: WARRANTY DEED\n",
      "Grantor: VANGUARD HOMES INC\n",
      "Grantee: COOK THOMAS J\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the sales table\n",
    "sales_history = soup.find('div', id='sales')\n",
    "sales_table = sales_history.find_all('tr')\n",
    "\n",
    "# Initialize a list to store the sales data\n",
    "sales_data = []\n",
    "\n",
    "# Loop through each row in the sales table\n",
    "for row in sales_table:\n",
    "    sale_info = {}\n",
    "    \n",
    "    # Extract the sale date, price, type, and reception from the main row\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 1:\n",
    "        sale_date = columns[1].get_text(strip=True)\n",
    "        sale_price = columns[2].get_text(strip=True)\n",
    "        sale_type = columns[3].get_text(strip=True)\n",
    "        reception = columns[4].get_text(strip=True)\n",
    "        \n",
    "        # Store the extracted information in the dictionary\n",
    "        sale_info['Sale Date'] = sale_date\n",
    "        sale_info['Sale Price'] = sale_price\n",
    "        sale_info['Sale Type'] = sale_type\n",
    "        sale_info['Reception'] = reception\n",
    "        \n",
    "        # Check for additional sale details if available (expand row button +)\n",
    "        expand_row = columns[0].find('button')\n",
    "        if expand_row:\n",
    "            # Simulate a click to reveal additional information\n",
    "            expand_button = driver.find_element(By.XPATH, f\"//button[text()='+']\")\n",
    "            expand_button.click()\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"table-row-subdata-content\"))\n",
    "            )\n",
    "            \n",
    "            # Refresh the page source after expanding\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Re-locate the expanded data in the DOM\n",
    "            expanded_row = soup.find_all('tr', class_='hide table-row-subdata')\n",
    "\n",
    "            # Extract subdata for each expanded row\n",
    "            if expanded_row:\n",
    "                subdata = expanded_row[0].find('ul', class_='data-list')\n",
    "                if subdata:\n",
    "                    for item in subdata.find_all('li', class_='data-list-row'):\n",
    "                        # Extract the title and value from each <p> tag\n",
    "                        data_items = item.find_all('p', class_='data-list-item')\n",
    "                        for data_item in data_items:\n",
    "                            title_span = data_item.find('span', class_='title')\n",
    "                            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "                            if title_span and value_span:\n",
    "                                title = title_span.get_text(strip=True)\n",
    "                                value = value_span.get_text(strip=True)\n",
    "                                sale_info[title] = value\n",
    "                    \n",
    "                    # Now, handle the Grantee field (dropdown)\n",
    "                    grantee_select = subdata.find('select', class_='value')\n",
    "                    if grantee_select:\n",
    "                        # Get the first option in the dropdown, which is visible\n",
    "                        selected_grantee = grantee_select.find('option')\n",
    "                        if selected_grantee:\n",
    "                            sale_info['Grantee'] = selected_grantee.get_text(strip=True)\n",
    "        \n",
    "        # Append the sale data to the list\n",
    "        sales_data.append(sale_info)\n",
    "\n",
    "# Print the sales data in a cleaner format\n",
    "for sale in sales_data:\n",
    "    for key, value in sale.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "572e5460-f283-4057-a673-5ad9bf96a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tax Information: \n",
      "   Tax Area Code:FBCLevy Year:2024Mill Levy:55.361 \n",
      "\n",
      "Taxing Entity: EL PASO COUNTY\n",
      "Levy: 6.985\n",
      "Contact Name/Organization: FINANCIAL SERVICES\n",
      "Contact Phone: (719)520-6400\n",
      "\n",
      "Taxing Entity: EPC ROAD & BRIDGE SHARE\n",
      "Levy: 0.165\n",
      "Contact Name/Organization: -\n",
      "Contact Phone: (719)520-6498\n",
      "\n",
      "Taxing Entity: CITY OF COLORADO SPRINGS\n",
      "Levy: 3.554\n",
      "Contact Name/Organization: CITY OF CS-CFO\n",
      "Contact Phone: (719)385-5224\n",
      "\n",
      "Taxing Entity: EPC-COLORADO SPGS ROAD & BRIDGE SHARE\n",
      "Levy: 0.165\n",
      "Contact Name/Organization: -\n",
      "Contact Phone: (719)520-6498\n",
      "\n",
      "Taxing Entity: COLO SPGS SCHOOL DISTRICT #11\n",
      "Levy: 40.605\n",
      "Contact Name/Organization: LAURA HRONIK\n",
      "Contact Phone: (719)520-2010\n",
      "\n",
      "Taxing Entity: PIKES PEAK LIBRARY DISTRICT\n",
      "Levy: 3.140\n",
      "Contact Name/Organization: RANDALL A GREEN\n",
      "Contact Phone: (719)531-6333\n",
      "\n",
      "Taxing Entity: SOUTHEASTERN COLO WATER CONSERVANCY DISTRICT\n",
      "Levy: 0.747\n",
      "Contact Name/Organization: JAMES BRODERICK\n",
      "Contact Phone: (719)948-2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the Tax Entity and Levy Information section\n",
    "tax_levy_section = soup.find('div', {'id': 'taxandlevytab'})\n",
    "\n",
    "# Extract the tax area code, levy year, and mill levy from the paragraph\n",
    "tax_info = tax_levy_section.find_all('p')[1].get_text(strip=True)\n",
    "print(f\"Tax Information: \\n   {tax_info} \\n\")\n",
    "\n",
    "# Extract all rows from the Taxing Entity table\n",
    "table_rows = tax_levy_section.find_all('tr')\n",
    "\n",
    "# Initialize a list to store sales data\n",
    "sales_data = []\n",
    "\n",
    "# Extract and store the table data for each row\n",
    "for row in table_rows:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) > 0:  # Skip empty rows\n",
    "        sale = {\n",
    "            \"Taxing Entity\": cols[0].get_text(strip=True),\n",
    "            \"Levy\": cols[1].get_text(strip=True),\n",
    "            \"Contact Name/Organization\": cols[2].get_text(strip=True),\n",
    "            \"Contact Phone\": cols[3].get_text(strip=True)\n",
    "        }\n",
    "        sales_data.append(sale)\n",
    "\n",
    "# Print the sales data in the requested format\n",
    "for sale in sales_data:\n",
    "    for key, value in sale.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d3da4ad-a4f5-4032-a2cb-cc86655457a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map URL: https://image-cdn.spatialest.com/file/view/co-elpaso-images/ASRMap/74021.tif?v=210621\n"
     ]
    }
   ],
   "source": [
    "# Find the MapSheet div\n",
    "map_sheet_div = soup.find('div', {'id': 'MapSheet'})\n",
    "\n",
    "# Find the <a> tag within the MapSheet div\n",
    "map_link = map_sheet_div.find('a')\n",
    "\n",
    "# Extract the href (link) and text from the <a> tag\n",
    "if map_link:\n",
    "    map_url = map_link.get('href')\n",
    "    map_text = map_link.get_text(strip=True)\n",
    "    print(f\"Map URL: {map_url}\")\n",
    "    # print(f\"Map Text: {map_text}\")\n",
    "else:\n",
    "    print(\"Map link not found.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb97017-c697-4e9d-805d-32d8e000bec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3ed3d-192d-4f47-bd35-1eb41017e3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a5443d-0050-4cb8-b08d-aedc143fa5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:29] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:30] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:34] \"GET /option3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:34] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Mar/2025 21:27:53] \"OPTIONS /query HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option1():\n",
    "    house_info = []\n",
    "    returnval = {}\n",
    "    house_info.append({\n",
    "                    \"Year\": 2020,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    house_info.append({\n",
    "                    \"Year\": 2021,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    \n",
    "    index = 0\n",
    "    for item in house_info:\n",
    "        returnval[\"detail\"+str(index)] = item\n",
    "        index += 1\n",
    "    return jsonify(returnval)\n",
    "\n",
    "@app.route('/option2')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option2():\n",
    "    data_set = {}\n",
    "    data_set[\"Owner\"] = \"Zach\"\n",
    "    data_set[\"Address\"] = \"3135 Moorhead Ave\"\n",
    "    data_set[\"Price1\"] = \"$20,000\"\n",
    "    data_set[\"Year1\"] = 1960\n",
    "    data_set[\"Price2\"] = \"$500,000\"\n",
    "    data_set[\"Year2\"] = 2020\n",
    "    return data_set\n",
    "\n",
    "@app.route('/option3')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option3():\n",
    "    return jsonify(data_set)\n",
    "    \n",
    "# main driver function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # run() method of Flask class runs the application \n",
    "    # on the local development server.\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8193d5-7a92-487d-bbf9-a2a1acfc03a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78b284-33f5-4ded-b580-9a11a0cb96ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f70e97-22b1-417c-be85-e1c1150dc46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
