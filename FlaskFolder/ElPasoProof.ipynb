{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c894032d-ae3a-49fb-87e6-22cad7890e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\zach0\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zach0\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zach0\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b47234-44b4-4bf7-9128-9551b5b851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data_set = {}\n",
    "address_to_search = \"2366 Mesa Crest Grv\"\n",
    "# Initialize the Chrome WebDriver and load the property search website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://property.spatialest.com/co/elpaso/#/\")\n",
    "\n",
    "# Wait for the search box to be visible and input the address\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.ID, \"primary_search\"))\n",
    ")\n",
    "\n",
    "# Input the address to search for and submit the search\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'primary_search'))\n",
    ")\n",
    "search_box.send_keys(address_to_search)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load on the page\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"data-list-section\"))\n",
    ")\n",
    "\n",
    "# Parse the page source with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# --------------------------------------------\n",
    "# Extracting General Property Information\n",
    "# --------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dc6db9-8010-4d52-a07c-a1a258554f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 'data-list-section' that contains the relevant data\n",
    "data_list_section = soup.find('div', class_='data-list-section')\n",
    "\n",
    "# Find all the list items (li) within this section\n",
    "data_rows = data_list_section.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "property_details = {}\n",
    "\n",
    "# Iterate over each data row to extract the title and value\n",
    "for row in data_rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    # If the value is a dropdown (select), extract the selected option\n",
    "    if not value:\n",
    "        value = row.find('select')\n",
    "        if value:\n",
    "            value = value.find('option').text.strip()\n",
    "    else:\n",
    "        value = value.text.strip()\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        property_details[title_text] = value\n",
    "\n",
    "# Print out the extracted data\n",
    "for key, value in property_details.items():\n",
    "    data_set[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165077ef-5cc6-43e3-92ae-8182479fea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Value:\n",
      "\n",
      "Assessed Value:\n"
     ]
    }
   ],
   "source": [
    "# Find the \"Market & Assessment Details\" section\n",
    "assessment_section = soup.find('div', class_='assessment')\n",
    "\n",
    "# Find the data list containing market and assessed values\n",
    "data_list = assessment_section.find('ul', class_='data-list')\n",
    "\n",
    "# Extract the rows for the market and assessed values\n",
    "rows = data_list.find_all('li', class_='clearfix data-list-row')\n",
    "\n",
    "market_value = {}\n",
    "assessed_value = {}\n",
    "\n",
    "for row in rows:\n",
    "    title = row.find('span', class_='title')\n",
    "    value = row.find('span', class_='value')\n",
    "    \n",
    "    if title and value:\n",
    "        title_text = title.text.strip()\n",
    "        value_text = value.text.strip()\n",
    "\n",
    "        # Checking if the title matches categories and storing the respective values\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            market_value[title_text] = value_text\n",
    "        if title_text in [\"Land\", \"Improvement\", \"Total\"]:\n",
    "            assessed_value[title_text] = value_text\n",
    "\n",
    "# Print the results for Market and Assessed Values\n",
    "print(\"Market Value:\")\n",
    "for key, val in market_value.items():\n",
    "    data_set[\"Market Value \"+key] = val\n",
    "\n",
    "print(\"\\nAssessed Value:\")\n",
    "for key, val in assessed_value.items():\n",
    "    data_set[\"Assessed Key \"+key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f994a4bd-4c36-4c6c-ac44-86cfefde7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Owner:': 'COOK THOMAS J', 'Mailing Address:': '2366 MESA CREST GRV COLORADO SPRINGS CO, 80904-1800', 'Location:': '2366 MESA CREST GRV', 'Tax Status:': 'Taxable', 'Zoning:': 'PUD HS', 'Plat No:': 'R11975', 'Legal Description:': 'LOT 1  INDIAN MESA SUB FIL NO 3', 'Market Value Land': '$122,400', 'Market Value Improvement': '$570,567', 'Market Value Total': '$692,967', 'Assessed Key Land': '$122,400', 'Assessed Key Improvement': '$570,567', 'Assessed Key Total': '$692,967', 'landinfo0': {'Sequence Number': '1', 'Land Use': 'SINGLE FAMILY RESIDENTIAL', 'Assessment Rate': '6.700', 'Area': '7206 SQFT', 'Market Value': '$122,400'}}\n"
     ]
    }
   ],
   "source": [
    "# Find the table containing the land details\n",
    "table = soup.find('table', class_='table-striped')\n",
    "\n",
    "# Extract the headers (columns) from the table\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "# Extract the rows of the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Initialize an empty list to store dictionaries for each row\n",
    "data = []\n",
    "\n",
    "# Loop through each row (skipping the header row)\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if columns:\n",
    "        row_data = {}\n",
    "        for i, col in enumerate(columns):\n",
    "            # Assign the header as the key and the column value as the value\n",
    "            row_data[headers[i]] = col.text.strip()\n",
    "        data.append(row_data)\n",
    "\n",
    "# Now print the scraped land info in the format you requested\n",
    "index=0\n",
    "for land_info in data:\n",
    "    data_set[\"landinfo\"+str(index)] = land_info\n",
    "    \n",
    "    print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd5f82c-4d49-448c-be04-1ff79de1dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = soup.find_all('div', class_='panel panel-default')\n",
    "\n",
    "# Loop through each section and extract the details\n",
    "index = 0\n",
    "for section in sections:\n",
    "    # Extract title for identification (either BI LEVEL 2 STORY or RESIDENTIAL OUTBUILDINGS)\n",
    "    section_title = section.find('h4', class_='panel-title').get_text(strip=True)\n",
    "\n",
    "    # Extract building details for each section\n",
    "    market_value = section.find('div', class_='building-value').find_all('span')[1].get_text(strip=True)\n",
    "    data_list = section.find('ul', class_='data-list')\n",
    "    building_details = {}\n",
    "\n",
    "    # Loop through each row and extract the title and value for each <p> tag\n",
    "    for item in data_list.find_all('li', class_='data-list-row'):\n",
    "        data_items = item.find_all('p', class_='data-list-item')\n",
    "        for data_item in data_items:\n",
    "            title_span = data_item.find('span', class_='title')\n",
    "            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "            if title_span:\n",
    "                title = title_span.get_text(strip=True)\n",
    "                value = value_span.get_text(strip=True) if value_span else \"-\"\n",
    "                building_details[title] = value\n",
    "    \n",
    "    # Add the market value to the building details dictionary\n",
    "    building_details['Market Value'] = market_value\n",
    "\n",
    "    # Print out the details for each section\n",
    "    # print(f\"\\n{section_title} Details:\")\n",
    "    # for key, value in building_details.items():\n",
    "    #     print(f\"{key}: {value}\")\n",
    "    data_set[\"Section\"+str(index)] = building_details\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884ba1e6-8161-4783-959c-b1196711f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sales table\n",
    "sales_history = soup.find('div', id='sales')\n",
    "sales_table = sales_history.find_all('tr')\n",
    "\n",
    "# Initialize a list to store the sales data\n",
    "sales_data = []\n",
    "\n",
    "# Loop through each row in the sales table\n",
    "index = 0\n",
    "for row in sales_table:\n",
    "    sale_info = {}\n",
    "    \n",
    "    # Extract the sale date, price, type, and reception from the main row\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 1:\n",
    "        sale_date = columns[1].get_text(strip=True)\n",
    "        sale_price = columns[2].get_text(strip=True)\n",
    "        sale_type = columns[3].get_text(strip=True)\n",
    "        reception = columns[4].get_text(strip=True)\n",
    "        \n",
    "        # Store the extracted information in the dictionary\n",
    "        sale_info['Sale Date'] = sale_date\n",
    "        sale_info['Sale Price'] = sale_price\n",
    "        sale_info['Sale Type'] = sale_type\n",
    "        sale_info['Reception'] = reception\n",
    "        \n",
    "        # Check for additional sale details if available (expand row button +)\n",
    "        expand_row = columns[0].find('button')\n",
    "        if expand_row:\n",
    "            # Simulate a click to reveal additional information\n",
    "            expand_button = driver.find_element(By.XPATH, f\"//button[text()='+']\")\n",
    "            expand_button.click()\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"table-row-subdata-content\"))\n",
    "            )\n",
    "            \n",
    "            # Refresh the page source after expanding\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Re-locate the expanded data in the DOM\n",
    "            expanded_row = soup.find_all('tr', class_='hide table-row-subdata')\n",
    "\n",
    "            # Extract subdata for each expanded row\n",
    "            if expanded_row:\n",
    "                subdata = expanded_row[0].find('ul', class_='data-list')\n",
    "                if subdata:\n",
    "                    for item in subdata.find_all('li', class_='data-list-row'):\n",
    "                        # Extract the title and value from each <p> tag\n",
    "                        data_items = item.find_all('p', class_='data-list-item')\n",
    "                        for data_item in data_items:\n",
    "                            title_span = data_item.find('span', class_='title')\n",
    "                            value_span = data_item.find('span', class_='value')\n",
    "\n",
    "                            if title_span and value_span:\n",
    "                                title = title_span.get_text(strip=True)\n",
    "                                value = value_span.get_text(strip=True)\n",
    "                                sale_info[title] = value\n",
    "                    \n",
    "                    # Now, handle the Grantee field (dropdown)\n",
    "                    grantee_select = subdata.find('select', class_='value')\n",
    "                    if grantee_select:\n",
    "                        # Get the first option in the dropdown, which is visible\n",
    "                        selected_grantee = grantee_select.find('option')\n",
    "                        if selected_grantee:\n",
    "                            sale_info['Grantee'] = selected_grantee.get_text(strip=True)\n",
    "        \n",
    "        # Append the sale data to the list\n",
    "        sales_data.append(sale_info)\n",
    "\n",
    "# Print the sales data in a cleaner format\n",
    "for sale in sales_data:\n",
    "    data_set[\"Sale\"+str(index)] = sale\n",
    "    index += 1\n",
    "    # for key, value in sale.items():\n",
    "    #     print(f\"{key}: {value}\")\n",
    "    # print()\n",
    "\n",
    "# Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572e5460-f283-4057-a673-5ad9bf96a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Tax Entity and Levy Information section\n",
    "tax_levy_section = soup.find('div', {'id': 'taxandlevytab'})\n",
    "\n",
    "# Extract the tax area code, levy year, and mill levy from the paragraph\n",
    "tax_info = tax_levy_section.find_all('p')[1].get_text(strip=True)\n",
    "data_set[\"TaxInfo\"] = tax_info\n",
    "\n",
    "# Extract all rows from the Taxing Entity table\n",
    "table_rows = tax_levy_section.find_all('tr')\n",
    "\n",
    "# Initialize a list to store sales data\n",
    "sales_data = []\n",
    "\n",
    "# Extract and store the table data for each row\n",
    "for row in table_rows:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) > 0:  # Skip empty rows\n",
    "        sale = {\n",
    "            \"Taxing Entity\": cols[0].get_text(strip=True),\n",
    "            \"Levy\": cols[1].get_text(strip=True),\n",
    "            \"Contact Name/Organization\": cols[2].get_text(strip=True),\n",
    "            \"Contact Phone\": cols[3].get_text(strip=True)\n",
    "        }\n",
    "        sales_data.append(sale)\n",
    "\n",
    "# Print the sales data in the requested format\n",
    "index = 0\n",
    "for sale in sales_data:\n",
    "    data_set[\"Tax\"+str(index)] = sale\n",
    "    # for key, value in sale.items():\n",
    "    #     print(f\"{key}: {value}\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3da4ad-a4f5-4032-a2cb-cc86655457a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the MapSheet div\n",
    "map_sheet_div = soup.find('div', {'id': 'MapSheet'})\n",
    "\n",
    "# Find the <a> tag within the MapSheet div\n",
    "map_link = map_sheet_div.find('a')\n",
    "\n",
    "# Extract the href (link) and text from the <a> tag\n",
    "if map_link:\n",
    "    map_url = map_link.get('href')\n",
    "    map_text = map_link.get_text(strip=True)\n",
    "    data_set[\"MapURL\"] = map_url\n",
    "    # print(f\"Map Text: {map_text}\")\n",
    "else:\n",
    "    print(\"Map link not found.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66c20e2-747a-4377-b765-d6c622b805b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Owner:': 'COOK THOMAS J', 'Mailing Address:': '2366 MESA CREST GRV COLORADO SPRINGS CO, 80904-1800', 'Location:': '2366 MESA CREST GRV', 'Tax Status:': 'Taxable', 'Zoning:': 'PUD HS', 'Plat No:': 'R11975', 'Legal Description:': 'LOT 1  INDIAN MESA SUB FIL NO 3', 'Market Value Land': '$122,400', 'Market Value Improvement': '$570,567', 'Market Value Total': '$692,967', 'Assessed Key Land': '$122,400', 'Assessed Key Improvement': '$570,567', 'Assessed Key Total': '$692,967', 'landinfo0': {'Sequence Number': '1', 'Land Use': 'SINGLE FAMILY RESIDENTIAL', 'Assessment Rate': '6.700', 'Area': '7206 SQFT', 'Market Value': '$122,400'}, 'Section0': {'Assessment Rate': '6.700', 'Above Grade Area': '1,921', 'Bldg #': '1', 'First Floor Area': '1,921', 'Style Description': 'RANCH 1 STORY', 'Above First Floor Area': '0', 'Property Description': 'SINGLE FAMILY RESIDENTIAL', 'Lower Level Living Area': '0', 'Year Built': '2012', 'Total Basement Area': '1,881', 'Dwelling Units': '1', 'Finished Basement Area': '1,800', 'Number of Rooms': '10', 'Garage Description': 'Attached', 'Number of Bedrooms': '3', 'Garage Area': '528', 'Number of Baths': '2.50', 'Carport Area': '-', 'Market Value': '$570,567'}, 'Sale0': {'Sale Date': '01/22/2013', 'Sale Price': '$395,036', 'Sale Type': 'Arms-Length Sale', 'Reception': '213008369', 'Schedule No': '7402104008', 'Book': '-', 'Page': '-', 'Balloon': 'No', 'PP/Good Will': '$0', 'Related Parties': 'N', 'Trade/Exch': '$0', 'Condition': 'New', 'Term': 'Month(s): 0', 'Financing': 'New 0% Fixed', 'Amt. Financed': '$0', 'Down Pmt': '$0', 'Doc Type': 'WARRANTY DEED', 'Grantor': 'VANGUARD HOMES INC', 'Grantee': 'COOK THOMAS J'}, 'Sale1': {'Sale Date': '06/29/2012', 'Sale Price': '$31,000', 'Sale Type': 'Vacant Land; REO or Sale After Foreclosu', 'Reception': '213008369', 'Schedule No': '7402104008', 'Book': '-', 'Page': '-', 'Balloon': 'No', 'PP/Good Will': '$0', 'Related Parties': 'N', 'Trade/Exch': '$0', 'Condition': 'New', 'Term': 'Month(s): 0', 'Financing': 'New 0% Fixed', 'Amt. Financed': '$0', 'Down Pmt': '$0', 'Doc Type': 'WARRANTY DEED', 'Grantor': 'VANGUARD HOMES INC', 'Grantee': 'COOK THOMAS J'}, 'Sale2': {'Sale Date': '07/12/2011', 'Sale Price': '$0', 'Sale Type': '-', 'Reception': '213008369', 'Schedule No': '7402104008', 'Book': '-', 'Page': '-', 'Balloon': 'No', 'PP/Good Will': '$0', 'Related Parties': 'N', 'Trade/Exch': '$0', 'Condition': 'New', 'Term': 'Month(s): 0', 'Financing': 'New 0% Fixed', 'Amt. Financed': '$0', 'Down Pmt': '$0', 'Doc Type': 'WARRANTY DEED', 'Grantor': 'VANGUARD HOMES INC', 'Grantee': 'COOK THOMAS J'}, 'Sale3': {'Sale Date': '01/08/2007', 'Sale Price': '$105,760', 'Sale Type': 'Vacant Land', 'Reception': '213008369', 'Schedule No': '7402104008', 'Book': '-', 'Page': '-', 'Balloon': 'No', 'PP/Good Will': '$0', 'Related Parties': 'N', 'Trade/Exch': '$0', 'Condition': 'New', 'Term': 'Month(s): 0', 'Financing': 'New 0% Fixed', 'Amt. Financed': '$0', 'Down Pmt': '$0', 'Doc Type': 'WARRANTY DEED', 'Grantor': 'VANGUARD HOMES INC', 'Grantee': 'COOK THOMAS J'}, 'Sale4': {'Sale Date': '04/20/2005', 'Sale Price': '$0', 'Sale Type': '-', 'Reception': '213008369', 'Schedule No': '7402104008', 'Book': '-', 'Page': '-', 'Balloon': 'No', 'PP/Good Will': '$0', 'Related Parties': 'N', 'Trade/Exch': '$0', 'Condition': 'New', 'Term': 'Month(s): 0', 'Financing': 'New 0% Fixed', 'Amt. Financed': '$0', 'Down Pmt': '$0', 'Doc Type': 'WARRANTY DEED', 'Grantor': 'VANGUARD HOMES INC', 'Grantee': 'COOK THOMAS J'}, 'TaxInfo': 'Tax Area Code:FBCLevy Year:2024Mill Levy:55.361', 'Tax0': {'Taxing Entity': 'SOUTHEASTERN COLO WATER CONSERVANCY DISTRICT', 'Levy': '0.747', 'Contact Name/Organization': 'JAMES BRODERICK', 'Contact Phone': '(719)948-2400'}, 'MapURL': 'https://image-cdn.spatialest.com/file/view/co-elpaso-images/ASRMap/74021.tif?v=210621'}\n"
     ]
    }
   ],
   "source": [
    "print(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3ed3d-192d-4f47-bd35-1eb41017e3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5443d-0050-4cb8-b08d-aedc143fa5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Mar/2025 12:07:50] \"GET /option3 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Mar/2025 12:07:50] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option1():\n",
    "    house_info = []\n",
    "    returnval = {}\n",
    "    house_info.append({\n",
    "                    \"Year\": 2020,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    house_info.append({\n",
    "                    \"Year\": 2021,\n",
    "                    \"Type\": \"property_type\",\n",
    "                    \"Actual\": \"actual\",\n",
    "                    \"Assessed\": \"assessed\",\n",
    "                    \"Exempt\": \"exempt\"\n",
    "                })\n",
    "    \n",
    "    index = 0\n",
    "    for item in house_info:\n",
    "        returnval[\"detail\"+str(index)] = item\n",
    "        index += 1\n",
    "    return jsonify(returnval)\n",
    "\n",
    "@app.route('/option2')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option2():\n",
    "    data_set = {}\n",
    "    data_set[\"Owner\"] = \"Zach\"\n",
    "    data_set[\"Address\"] = \"3135 Moorhead Ave\"\n",
    "    data_set[\"Price1\"] = \"$20,000\"\n",
    "    data_set[\"Year1\"] = 1960\n",
    "    data_set[\"Price2\"] = \"$500,000\"\n",
    "    data_set[\"Year2\"] = 2020\n",
    "    return data_set\n",
    "\n",
    "@app.route('/option3')\n",
    "# ‘/’ URL is bound with hello_world() function.\n",
    "def option3():\n",
    "    return jsonify(data_set)\n",
    "    \n",
    "# main driver function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # run() method of Flask class runs the application \n",
    "    # on the local development server.\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8193d5-7a92-487d-bbf9-a2a1acfc03a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78b284-33f5-4ded-b580-9a11a0cb96ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f70e97-22b1-417c-be85-e1c1150dc46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
